codesample,labels,id
"    public JsonGenerator(LogIterator iter) {
	servers = new HashSet<Integer>();


	Pattern stateChangeP = Pattern.compile(""- (LOOKING|FOLLOWING|LEADING)"");
	Pattern newElectionP = Pattern.compile(""New election. My id =  (\\d+), Proposed zxid = (\\d+)"");
	Pattern receivedProposalP = Pattern.compile(""Notification: (\\d+) \\(n.leader\\), (\\d+) \\(n.zxid\\), (\\d+) \\(n.round\\), .+ \\(n.state\\), (\\d+) \\(n.sid\\), .+ \\(my state\\)"");
	Pattern exceptionP = Pattern.compile(""xception"");
	
	root = new JSONObject();
	Matcher m = null;
	JSONArray events = new JSONArray();
	root.put(""events"", events);
	
	long starttime = Long.MAX_VALUE;
	long endtime = 0;


	int leader = 0;
	long curEpoch = 0;
	boolean newEpoch = false;


	while (iter.hasNext()) {
	    LogEntry ent = iter.next();
	    
	    if (ent.getTimestamp() < starttime) {
		starttime = ent.getTimestamp();
	    }
	    if (ent.getTimestamp() > endtime) {
		endtime = ent.getTimestamp();
	    }
	    
	    if (ent.getType() == LogEntry.Type.TXN) {
		events.add(txnEntry((TransactionEntry)ent));
	    } else {
		Log4JEntry e = (Log4JEntry)ent;
		servers.add(e.getNode());
		
		if ((m = stateChangeP.matcher(e.getEntry())).find()) {
		    JSONObject stateChange = new JSONObject();
		    stateChange.put(""type"", ""stateChange"");
		    stateChange.put(""time"", e.getTimestamp());
		    stateChange.put(""server"", e.getNode());
		    stateChange.put(""state"", m.group(1));
		    events.add(stateChange);
		    
		    if (m.group(1).equals(""LEADING"")) {
			leader = e.getNode();
		    }
		} else if ((m = newElectionP.matcher(e.getEntry())).find()) {
		    Iterator<Integer> iterator = servers.iterator();
		    long zxid = Long.valueOf(m.group(2));
		    int count = (int)zxid;// & 0xFFFFFFFFL;
		    int epoch = (int)Long.rotateRight(zxid, 32);// >> 32;
		    
		    if (leader != 0 && epoch > curEpoch) {
			JSONObject stateChange = new JSONObject();
			stateChange.put(""type"", ""stateChange"");
			stateChange.put(""time"", e.getTimestamp());
			stateChange.put(""server"", leader);
			stateChange.put(""state"", ""INIT"");
			events.add(stateChange);
			leader = 0;
		    }
		    
		    while (iterator.hasNext()) {
			int dst = iterator.next();
			if (dst != e.getNode()) {
			    JSONObject msg = new JSONObject();
			    msg.put(""type"", ""postmessage"");
			    msg.put(""src"", e.getNode());
			    msg.put(""dst"", dst);
			    msg.put(""time"", e.getTimestamp());
			    msg.put(""zxid"", m.group(2));
			    msg.put(""count"", count);
			    msg.put(""epoch"", epoch);
			    
			    events.add(msg);
			}
		    }
		} else if ((m = receivedProposalP.matcher(e.getEntry())).find()) {
		    // Pattern.compile(""Notification: \\d+, (\\d+), (\\d+), \\d+, [^,]*, [^,]*, (\\d+)"");//, LOOKING, LOOKING, 2
		    int src = Integer.valueOf(m.group(4));
		    long zxid = Long.valueOf(m.group(2));
		    int dst = e.getNode();
		    long epoch2 = Long.valueOf(m.group(3));
		    
		    int count = (int)zxid;// & 0xFFFFFFFFL;
		    int epoch = (int)Long.rotateRight(zxid, 32);// >> 32;
		    
		    if (leader != 0 && epoch > curEpoch) {
			JSONObject stateChange = new JSONObject();
			stateChange.put(""type"", ""stateChange"");
			stateChange.put(""time"", e.getTimestamp());
			stateChange.put(""server"", leader);
			stateChange.put(""state"", ""INIT"");
			events.add(stateChange);
			leader = 0;
		    }
		    
		    if (src != dst) {
			JSONObject msg = new JSONObject();
			msg.put(""type"", ""delivermessage"");
			msg.put(""src"", src);
			msg.put(""dst"", dst);
			msg.put(""time"", e.getTimestamp());
			msg.put(""zxid"", zxid);
			msg.put(""epoch"", epoch);
			msg.put(""count"", count);
			msg.put(""epoch2"", epoch2);
			
			events.add(msg);
		    }
		} else if ((m = exceptionP.matcher(e.getEntry())).find()) {
		    JSONObject ex = new JSONObject();
		    ex.put(""type"", ""exception"");
		    ex.put(""server"", e.getNode());
		    ex.put(""time"", e.getTimestamp());
		    ex.put(""text"", e.getEntry());
		    events.add(ex);
		} 
	    }
	    JSONObject ex = new JSONObject();
	    ex.put(""type"", ""text"");
	    ex.put(""time"", ent.getTimestamp());
	    String txt = ent.toString();
	    ex.put(""text"", txt);
	    events.add(ex);
	}
	//	System.out.println(""pending messages: ""+pendingMessages.size());
	root.put(""starttime"", starttime);
	root.put(""endtime"", endtime);


	JSONArray serversarray = new JSONArray();
	root.put(""servers"", serversarray);
	
	Iterator<Integer> iterator = servers.iterator();
	while (iterator.hasNext()) {
	    serversarray.add(iterator.next());
	}
    }",1,623
"	private void createMenuEntries(Menu menu, DisplayItem parent,
			boolean trackDynamics) {
		if (menu == null)
			return;
		MenuItem[] menuItems = menu.getItems();


		Map findDynamics = new HashMap();
		DynamicContributionItem dynamicEntry = null;


		if (trackDynamics && menu.getParentItem() != null) {
			//Search for any dynamic menu entries which will be handled later
			Object data = menu.getParentItem().getData();
			if (data instanceof IContributionManager) {
				IContributionManager manager = (IContributionManager) data;
				IContributionItem[] items = manager.getItems();
				for (int i = 0; i < items.length; i++) {
					if (items[i].isDynamic()) {
						findDynamics.put(i > 0 ? items[i - 1] : null, items[i]);
					}
				}


				//If there is an item with no preceeding item, set it up to be
				//added first.
				if (findDynamics.containsKey(null)) {
					IContributionItem item = (IContributionItem) findDynamics
							.get(null);
					dynamicEntry = new DynamicContributionItem(item);
					parent.addChild(dynamicEntry);
				}
			}
		}


		for (int i = 0; i < menuItems.length; i++) {
			if (!menuItems[i].getText().equals("""")) { //$NON-NLS-1$
				IContributionItem contributionItem =
						(IContributionItem) menuItems[i].getData();
				if (dynamicEntry != null
						&& contributionItem.equals(dynamicEntry
								.getIContributionItem())) {
					//If the last item added is the item meant to go before the
					//given dynamic entry, add the dynamic entry so it is in the
					//correct order.
					dynamicEntry.addCurrentItem(menuItems[i]);
				} else {
					DisplayItem menuEntry = new DisplayItem(
							menuItems[i].getText(), contributionItem);


					Image image = menuItems[i].getImage();
					if (image != null) {
						menuEntry.setImageDescriptor(ImageDescriptor
								.createFromImage(image));
					}
					menuEntry.setActionSet((ActionSet) idToActionSet
							.get(getActionSetID(contributionItem)));
					parent.addChild(menuEntry);


					if (ActionFactory.NEW.getId()
							.equals(((IContributionItem) menuItems[i].getData())
									.getId())) {
						initializeNewWizardsMenu(menuEntry);
						wizards = menuEntry;
					} else if (SHORTCUT_CONTRIBUTION_ITEM_ID_OPEN_PERSPECTIVE
							.equals(((IContributionItem) menuItems[i].getData())
									.getId())) {
						initializePerspectivesMenu(menuEntry);
						perspectives = menuEntry;
					} else if (SHORTCUT_CONTRIBUTION_ITEM_ID_SHOW_VIEW
							.equals(((IContributionItem) menuItems[i].getData())
									.getId())) {
						initializeViewsMenu(menuEntry);
						views = menuEntry;
					} else {
						createMenuEntries(menuItems[i].getMenu(), menuEntry,
								trackDynamics);
					}


					if (menuEntry.getChildren().isEmpty()) {
						menuEntry
								.setCheckState(getMenuItemIsVisible(menuEntry));
					}


					if (image == null) {
						if (parent != null && parent.getParent() == null) {
							menuEntry.setImageDescriptor(menuImageDescriptor);
						} else if (menuEntry.getChildren().size() > 0) {
							menuEntry
									.setImageDescriptor(submenuImageDescriptor);
						}
					}
				}
				if (trackDynamics
						&& findDynamics.containsKey(menuItems[i].getData())) {
					IContributionItem item = (IContributionItem) findDynamics
							.get(menuItems[i].getData());
					dynamicEntry = new DynamicContributionItem(item);
					dynamicEntry
							.setCheckState(getMenuItemIsVisible(dynamicEntry));
					parent.addChild(dynamicEntry);
				}
			}
		}
	}",1,982
"                private boolean r_prelude() {
            int among_var;
            int v_1;
            int v_2;
            int v_3;
            int v_4;
            int v_5;
                    // (, line 34
                    // test, line 35
                    v_1 = cursor;
                    // repeat, line 35
                    replab0: while(true)
                    {
                        v_2 = cursor;
                        lab1: do {
                            // (, line 35
                            // [, line 36
                            bra = cursor;
                            // substring, line 36
                            among_var = find_among(a_0, 7);
                            if (among_var == 0)
                            {
                                break lab1;
                            }
                            // ], line 36
                            ket = cursor;
                            switch(among_var) {
                                case 0:
                                    break lab1;
                                case 1:
                                    // (, line 37
                                    // <-, line 37
                                    slice_from(""\u00E0"");
                                    break;
                                case 2:
                                    // (, line 38
                                    // <-, line 38
                                    slice_from(""\u00E8"");
                                    break;
                                case 3:
                                    // (, line 39
                                    // <-, line 39
                                    slice_from(""\u00EC"");
                                    break;
                                case 4:
                                    // (, line 40
                                    // <-, line 40
                                    slice_from(""\u00F2"");
                                    break;
                                case 5:
                                    // (, line 41
                                    // <-, line 41
                                    slice_from(""\u00F9"");
                                    break;
                                case 6:
                                    // (, line 42
                                    // <-, line 42
                                    slice_from(""qU"");
                                    break;
                                case 7:
                                    // (, line 43
                                    // next, line 43
                                    if (cursor >= limit)
                                    {
                                        break lab1;
                                    }
                                    cursor++;
                                    break;
                            }
                            continue replab0;
                        } while (false);
                        cursor = v_2;
                        break replab0;
                    }
                    cursor = v_1;
                    // repeat, line 46
                    replab2: while(true)
                    {
                        v_3 = cursor;
                        lab3: do {
                            // goto, line 46
                            golab4: while(true)
                            {
                                v_4 = cursor;
                                lab5: do {
                                    // (, line 46
                                    if (!(in_grouping(g_v, 97, 249)))
                                    {
                                        break lab5;
                                    }
                                    // [, line 47
                                    bra = cursor;
                                    // or, line 47
                                    lab6: do {
                                        v_5 = cursor;
                                        lab7: do {
                                            // (, line 47
                                            // literal, line 47
                                            if (!(eq_s(1, ""u"")))
                                            {
                                                break lab7;
                                            }
                                            // ], line 47
                                            ket = cursor;
                                            if (!(in_grouping(g_v, 97, 249)))
                                            {
                                                break lab7;
                                            }
                                            // <-, line 47
                                            slice_from(""U"");
                                            break lab6;
                                        } while (false);
                                        cursor = v_5;
                                        // (, line 48
                                        // literal, line 48
                                        if (!(eq_s(1, ""i"")))
                                        {
                                            break lab5;
                                        }
                                        // ], line 48
                                        ket = cursor;
                                        if (!(in_grouping(g_v, 97, 249)))
                                        {
                                            break lab5;
                                        }
                                        // <-, line 48
                                        slice_from(""I"");
                                    } while (false);
                                    cursor = v_4;
                                    break golab4;
                                } while (false);
                                cursor = v_4;
                                if (cursor >= limit)
                                {
                                    break lab3;
                                }
                                cursor++;
                            }
                            continue replab2;
                        } while (false);
                        cursor = v_3;
                        break replab2;
                    }
                    return true;
                }",1,2241
"  public List<Feature> extract(JCas jCas, CollectionTextRelation cluster,
      IdentifiedAnnotation mention) throws AnalysisEngineProcessException {
    if(cache == null){
      throw new RuntimeException(""This extractor requires a cached Markable->ConllDependencyNode map to be set with setCache()"");
    }
    List<Feature> feats = new ArrayList<>();
    CounterMap<String> featCounts = new CounterMap<>();
    
    if(StringMatchingFeatureExtractor.isPronoun(mention)) return feats;
    
    String m = mention.getCoveredText();
    Set<String> mentionWords = contentWords(mention);
    Set<String> nonHeadMentionWords = new HashSet<>(mentionWords);
    ConllDependencyNode mentionHead = cache.get(mention);
    
    String mentionHeadString = null;
    if(mentionHead != null){
      mentionHeadString = mentionHead.getCoveredText().toLowerCase();
      nonHeadMentionWords.remove(mentionHeadString);


      int maxNonoverlap = 0;


      for(IdentifiedAnnotation member : new ListIterable<IdentifiedAnnotation>(cluster.getMembers())){
        if(member == null){
          System.err.println(""Something that shouldn't happen has happened"");
          continue;
        }else if(mention.getBegin() < member.getEnd()){
          // during training this might happen -- see a member of a cluster that
          // is actually subsequent to the candidate mention
          continue;
        }else if(StringMatchingFeatureExtractor.isPronoun(member)){
          continue;
        }


        String s = member.getCoveredText();
        Set<String> memberWords = contentWords(member);
        Set<String> nonHeadMemberWords = new HashSet<>(memberWords);
        ConllDependencyNode memberHead = cache.get(member);
        String memberHeadString = null;
        if(memberHead != null){
          memberHeadString = memberHead.getCoveredText().toLowerCase();
          nonHeadMemberWords.remove(memberHeadString);


          if(mentionHeadString.equals(memberHeadString)){


            if(m.equalsIgnoreCase(s)) featCounts.add(""MC_STRING_EXACT"");
            if(startMatch(m,s)) featCounts.add(""MC_STRING_START"");
            if(endMatch(m,s)) featCounts.add(""MC_STRING_END"");
            if(soonMatch(m,s)) featCounts.add(""MC_STRING_SOON"");
            if(wordOverlap(mentionWords, memberWords)) featCounts.add(""MC_OVERLAP"");
            if(wordSubstring(mentionWords, memberWords)) featCounts.add(""MC_SUB"");


            int nonHeadOverlap = wordNonOverlapCount(nonHeadMemberWords, nonHeadMentionWords);
            if(nonHeadOverlap > maxNonoverlap){
              maxNonoverlap = nonHeadOverlap;
            }
          }
        }
      }
      feats.add(new Feature(""MC_MAX_NONOVERLAP"", maxNonoverlap));
    }
    
    
    for(String featKey : featCounts.keySet()){
      // normalized
//      feats.add(new Feature(featKey, (double) featCounts.get(featKey) / clusterSize));
      // boolean
      feats.add(new Feature(featKey, true));
    }
    return feats;
  }",1,2624
"    public List<Long> getOrderedLogFileIds() {
        File fileLogDir = new File(logDir);
        String[] logFileNames = null;
        List<Long> logFileIds = null;
        if (!fileLogDir.exists()) {
            LOGGER.log(Level.INFO, ""log dir "" + logDir + "" doesn't exist.  returning empty list"");
            return Collections.emptyList();
        }
        if (!fileLogDir.isDirectory()) {
            throw new IllegalStateException(""log dir "" + logDir + "" exists but it is not a directory"");
        }
        logFileNames = fileLogDir.list((dir, name) -> name.startsWith(logFilePrefix));
        if (logFileNames == null) {
            throw new IllegalStateException(""listing of log dir ("" + logDir + "") files returned null. ""
                    + ""Either an IO error occurred or the dir was just deleted by another process/thread"");
        }
        if (logFileNames.length == 0) {
            LOGGER.log(Level.INFO, ""the log dir ("" + logDir + "") is empty. returning empty list"");
            return Collections.emptyList();
        }
        logFileIds = new ArrayList<>();
        for (String fileName : logFileNames) {
            logFileIds.add(Long.parseLong(fileName.substring(logFilePrefix.length() + 1)));
        }
        logFileIds.sort(Long::compareTo);
        return logFileIds;
    }",1,2738
"   @Override
   public String sendMessage(final Map<String, String> headers,
                             final int type,
                             final String body,
                             boolean durable,
                             final String user,
                             final String password) throws Exception {
      if (AuditLogger.isEnabled()) {
         AuditLogger.sendMessage(this, null, headers, type, body, durable, user, ""****"");
      }
      try {
         return sendMessage(addressInfo.getName(), server, headers, type, body, durable, user, password);
      } catch (Exception e) {
         e.printStackTrace();
         throw new IllegalStateException(e.getMessage());
      }
   }",1,3000
"  private static String normalizePath(String path) {
    // count the number of '/'s, to determine number of segments
    int index = -1;
    int pathlen = path.length();
    int size = 0;
    if (pathlen > 0 && path.charAt(0) != '/') {
      size++;
    }
    while ((index = path.indexOf('/', index + 1)) != -1) {
      if (index + 1 < pathlen && path.charAt(index + 1) != '/') {
        size++;
      }
    }


    String[] seglist = new String[size];
    boolean[] include = new boolean[size];


    // break the path into segments and store in the list
    int current = 0;
    int index2 = 0;
    index = (pathlen > 0 && path.charAt(0) == '/') ? 1 : 0;
    while ((index2 = path.indexOf('/', index + 1)) != -1) {
      seglist[current++] = path.substring(index, index2);
      index = index2 + 1;
    }


    // if current==size, then the last character was a slash
    // and there are no more segments
    if (current < size) {
      seglist[current] = path.substring(index);
    }


    // determine which segments get included in the normalized path
    for (int i = 0; i < size; i++) {
      include[i] = true;
      if (seglist[i].equals("".."")) { //$NON-NLS-1$
        int remove = i - 1;
        // search back to find a segment to remove, if possible
        while (remove > -1 && !include[remove]) {
          remove--;
        }
        // if we find a segment to remove, remove it and the ""..""
        // segment
        if (remove > -1 && !seglist[remove].equals("".."")) { //$NON-NLS-1$
          include[remove] = false;
          include[i] = false;
        }
      } else if (seglist[i].equals(""."")) { //$NON-NLS-1$
        include[i] = false;
      }
    }


    // put the path back together
    StringBuilder newpath = new StringBuilder();
    if (path.startsWith(""/"")) { //$NON-NLS-1$
      newpath.append('/');
    }


    for (int i = 0; i < seglist.length; i++) {
      if (include[i]) {
        newpath.append(seglist[i]);
        newpath.append('/');
      }
    }


    // if we used at least one segment and the path previously ended with
    // a slash and the last segment is still used, then delete the extra
    // trailing '/'
    if (!path.endsWith(""/"") && seglist.length > 0 //$NON-NLS-1$
        && include[seglist.length - 1]) {
      newpath.deleteCharAt(newpath.length() - 1);
    }


    String result = newpath.toString();


    // check for a ':' in the first segment if one exists,
    // prepend ""./"" to normalize
    index = result.indexOf(':');
    index2 = result.indexOf('/');
    if (index != -1 && (index < index2 || index2 == -1)) {
      newpath.insert(0, ""./""); //$NON-NLS-1$
      result = newpath.toString();
    }
    return result;
  }",1,3262
"        @Override
        public void addOptionValues(List<OptionValue> optionValues, Map<String, Object> context, Delegator delegator) {
            // first expand any conditions that need expanding based on the current context
            EntityCondition findCondition = null;
            if (UtilValidate.isNotEmpty(this.constraintList)) {
                List<EntityCondition> expandedConditionList = new LinkedList<>();
                for (EntityFinderUtil.Condition condition : constraintList) {
                    ModelEntity modelEntity = delegator.getModelEntity(this.entityName);
                    if (modelEntity == null) {
                        throw new IllegalArgumentException(""Error in entity-options: could not find entity ["" + this.entityName
                                + ""]"");
                    }
                    EntityCondition createdCondition = condition.createCondition(context, modelEntity,
                            delegator.getModelFieldTypeReader(modelEntity));
                    if (createdCondition != null) {
                        expandedConditionList.add(createdCondition);
                    }
                }
                findCondition = EntityCondition.makeCondition(expandedConditionList);
            }


            try {
                Locale locale = UtilMisc.ensureLocale(context.get(""locale""));
                ModelEntity modelEntity = delegator.getModelEntity(this.entityName);
                Boolean localizedOrderBy = UtilValidate.isNotEmpty(this.orderByList)
                        && ModelUtil.isPotentialLocalizedFields(modelEntity, this.orderByList);


                List<GenericValue> values = null;
                if (!localizedOrderBy) {
                    values = delegator.findList(this.entityName, findCondition, null, this.orderByList, null, this.cache);
                } else {
                    //if entity has localized label
                    values = delegator.findList(this.entityName, findCondition, null, null, null, this.cache);
                    values = EntityUtil.localizedOrderBy(values, this.orderByList, locale);
                }


                // filter-by-date if requested
                if (""true"".equals(this.filterByDate)) {
                    values = EntityUtil.filterByDate(values, true);
                } else if (!""false"".equals(this.filterByDate)) {
                    // not explicitly true or false, check to see if has fromDate and thruDate, if so do the filter
                    if (modelEntity != null && modelEntity.isField(""fromDate"") && modelEntity.isField(""thruDate"")) {
                        values = EntityUtil.filterByDate(values, true);
                    }
                }


                for (GenericValue value : values) {
                    // add key and description with string expansion, ie expanding ${} stuff, passing locale explicitly to expand value string because it won't be found in the Entity
                    MapStack<String> localContext = MapStack.create(context);
                    // Rendering code might try to modify the GenericEntity instance,
                    // so we make a copy of it.
                    Map<String, Object> genericEntityClone = UtilGenerics.cast(value.clone());
                    localContext.push(genericEntityClone);


                    // expand with the new localContext, which is locale aware
                    String optionDesc = this.description.expandString(localContext, locale);


                    Object keyFieldObject = value.get(this.getKeyFieldName());
                    if (keyFieldObject == null) {
                        throw new IllegalArgumentException(
                                ""The entity-options identifier (from key-name attribute, or default to the field name) [""
                                        + this.getKeyFieldName() + ""], may not be a valid key field name for the entity [""
                                        + this.entityName + ""]."");
                    }
                    String keyFieldValue = keyFieldObject.toString();
                    optionValues.add(new OptionValue(keyFieldValue, optionDesc));
                }
            } catch (GenericEntityException e) {
                Debug.logError(e, ""Error getting entity options in form"", module);
            }
        }",1,3711
"	public static Control createCustomAreaWithLink(final Composite parent, final Dialog dialog, final Binary binary) {
		final String binaryLabel = binary.getLabel();
		final String prefix = ""The requested operation cannot be performed due to invalid '"" + binaryLabel
				+ ""' settings. Check your '"" + binaryLabel
				+ ""' configuration and preferences under the corresponding "";
		final String link = ""preference page"";
		final String suffix = ""."";
		final String text = prefix + link + suffix;


		final Composite control = new Composite(parent, NONE);
		control.setLayout(GridLayoutFactory.fillDefaults().create());
		final GridData gridData = GridDataFactory.fillDefaults().align(LEFT, TOP).grab(true, true).create();
		control.setLayoutData(gridData);


		final StyleRange style = new StyleRange();
		style.underline = true;
		style.underlineStyle = UNDERLINE_LINK;


		final StyledText styledText = new StyledText(control, MULTI | READ_ONLY | WRAP);
		styledText.setWordWrap(true);
		styledText.setJustify(true);
		styledText.setText(text);
		final GridData textGridData = GridDataFactory.fillDefaults().align(FILL, FILL).grab(true, true).create();
		textGridData.widthHint = TEXT_WIDTH_HINT;
		textGridData.heightHint = TEXT_HEIGHT_HINT;
		styledText.setLayoutData(textGridData);


		styledText.setEditable(false);
		styledText.setBackground(UIUtils.getSystemColor(COLOR_WIDGET_BACKGROUND));
		final int[] ranges = { text.indexOf(link), link.length() };
		final StyleRange[] styles = { style };
		styledText.setStyleRanges(ranges, styles);


		styledText.addMouseListener(new MouseAdapter() {


			@Override
			public void mouseDown(final MouseEvent event) {
				try {
					final int offset = styledText.getOffsetAtPoint(new Point(event.x, event.y));
					final StyleRange actualStyle = offset >= 0 ? styledText.getStyleRangeAtOffset(offset) : null;
					if (null != actualStyle && actualStyle.underline
							&& UNDERLINE_LINK == actualStyle.underlineStyle) {


						dialog.close();
						final PreferenceDialog preferenceDialog = createPreferenceDialogOn(
								UIUtils.getShell(),
								BinariesPreferencePage.ID,
								FILTER_IDS,
								null);


						if (null != preferenceDialog) {
							preferenceDialog.open();
						}


					}
				} catch (final IllegalArgumentException e) {
					// We are not over the actual text.
				}
			}


		});


		return control;
	}",1,3944
"/* HelloWorld.java
 */

public class HelloWorld
{
	public static void main(String[] args) {
		System.out.println(""Hello World!"");
	}
}",0,
"public static void go()
	{	Rectangle r1 = new Rectangle(0,0,5,5);
		System.out.println(""In method go. r1 "" + r1 + ""\n"");
		// could have been 
		//System.out.prinltn(""r1"" + r1.toString());
		r1.setSize(10, 15);
		System.out.println(""In method go. r1 "" + r1 + ""\n"");
		alterPointee(r1);
		System.out.println(""In method go. r1 "" + r1 + ""\n"");
		
		alterPointer(r1);
		System.out.println(""In method go. r1 "" + r1 + ""\n"");
	}
	",0,
"public static void main(String[] args) {
        
        int first = 10;
        int second = 20;

        System.out.println(""Enter two numbers: "" + first + "" "" + second);
        int sum = first + second;

        System.out.println(""The sum is: "" + sum);
    }",0,
"public static boolean[] getPrimes(int max) {
		boolean[] result = new boolean[max + 1];
		for(int i = 2; i < result.length; i++)
			result[i] = true;
		final double LIMIT = Math.sqrt(max);
		for(int i = 2; i <= LIMIT; i++) {
			if(result[i]) {
				// cross out all multiples;
				int index = 2 * i;
				while(index < result.length){
					result[index] = false;
					 index += i;
				}
			}
		}
		return result;
	}",0,
"public static void printTest(int num, int expectedFactors) {
		Stopwatch st = new Stopwatch();
		st.start();
		int actualFactors = numFactors(num);
		st.stop();
		System.out.println(""Testing "" + num + "" expect "" + expectedFactors + "", "" +
				""actual "" + actualFactors);
		if(actualFactors == expectedFactors)
			System.out.println(""PASSED"");
		else
			System.out.println(""FAILED"");
		System.out.println(st.time());
	}",0,
"public static boolean isPrime(int num) {
		assert num >= 2 : ""failed precondition. num must be >= 2. num: "" + num;
		final double LIMIT = Math.sqrt(num);
		boolean isPrime = (num == 2) ? true : num % 2 != 0;
		int div = 3;
		while(div <= LIMIT && isPrime) {
			isPrime = num % div != 0;
			div += 2;
		}
		return isPrime;
	}",0,
"private long getMessageCount(final DurabilityType durability) {
      List<QueueControl> queues = getQueues(durability);
      long count = 0;
      for (QueueControl queue : queues) {
         count += queue.getMessageCount();
      }
      return count;
   }",0,
"public String[] getRoutingTypes() {
      if (AuditLogger.isEnabled()) {
         AuditLogger.getRoutingTypes(this.addressInfo);
      }
      EnumSet<RoutingType> routingTypes = addressInfo.getRoutingTypes();
      String[] result = new String[routingTypes.size()];
      int i = 0;
      for (RoutingType routingType : routingTypes) {
         result[i++] = routingType.toString();
      }
      return result;
   }",0,
"public static void main(String[]args)
    {
    	//For capturing user input
        Scanner scanner = new Scanner(System.in);
        System.out.println(""Enter the String for check:"");
        String string = scanner.nextLine();
        /* If function returns true then the string is
         * palindrome else not
         */
        if(isPal(string))
            System.out.println(string + "" is a palindrome"");
        else
            System.out.println(string + "" is not a palindrome"");
    }",0,
"public static void main(String a[]){
    Details obj = new Details();
    System.out.println(""String: BeginnersBook.com"");
    System.out.println(""-------------------------"");
    obj.countDupChars(""BeginnersBook.com"");
  
    System.out.println(""\nString: ChaitanyaSingh"");
    System.out.println(""-------------------------"");
    obj.countDupChars(""ChaitanyaSingh"");
 
    System.out.println(""\nString: #@$@!#$%!!%@"");
    System.out.println(""-------------------------"");
    obj.countDupChars(""#@$@!#$%!!%@"");
  }",0,
"    @SuppressWarnings(""try"")
    private void doRun(Map<Method, CEntryPointData> entryPoints, Method mainEntryPoint,
                    JavaMainSupport javaMainSupport, String imageName, AbstractBootImage.NativeImageKind k,
                    SubstitutionProcessor harnessSubstitutions,
                    ForkJoinPool compilationExecutor, ForkJoinPool analysisExecutor) {
        List<HostedMethod> hostedEntryPoints = new ArrayList<>();


        OptionValues options = HostedOptionValues.singleton();
        SnippetReflectionProvider originalSnippetReflection = GraalAccess.getOriginalSnippetReflection();
        try (DebugContext debug = DebugContext.create(options, new GraalDebugHandlersFactory(originalSnippetReflection))) {
            setupNativeImage(imageName, options, entryPoints, javaMainSupport, harnessSubstitutions, analysisExecutor, originalSnippetReflection, debug);


            boolean returnAfterAnalysis = runPointsToAnalysis(imageName, options, debug);
            if (returnAfterAnalysis) {
                return;
            }


            NativeImageHeap heap;
            HostedMethod mainEntryPointHostedStub;
            HostedMetaAccess hMetaAccess;
            SharedRuntimeConfigurationBuilder runtime;
            try (StopTimer t = new Timer(imageName, ""universe"").start()) {
                hUniverse = new HostedUniverse(bigbang);
                hMetaAccess = new HostedMetaAccess(hUniverse, bigbang.getMetaAccess());


                new UniverseBuilder(aUniverse, bigbang.getMetaAccess(), hUniverse, hMetaAccess, HostedConfiguration.instance().createStaticAnalysisResultsBuilder(bigbang, hUniverse),
                                bigbang.getUnsupportedFeatures()).build(debug);


                runtime = new HostedRuntimeConfigurationBuilder(options, bigbang.getHostVM(), hUniverse, hMetaAccess, bigbang.getProviders()).build();
                registerGraphBuilderPlugins(featureHandler, runtime.getRuntimeConfig(), (HostedProviders) runtime.getRuntimeConfig().getProviders(), bigbang.getMetaAccess(), aUniverse,
                                hMetaAccess, hUniverse,
                                nativeLibraries, loader, false, true, bigbang.getAnnotationSubstitutionProcessor(), new SubstrateClassInitializationPlugin((SVMHost) aUniverse.hostVM()),
                                bigbang.getHostVM().getClassInitializationSupport());


                if (NativeImageOptions.PrintUniverse.getValue()) {
                    printTypes();
                }


                /* Find the entry point methods in the hosted world. */
                for (AnalysisMethod m : aUniverse.getMethods()) {
                    if (m.isEntryPoint()) {
                        HostedMethod found = hUniverse.lookup(m);
                        assert found != null;
                        hostedEntryPoints.add(found);
                    }
                }
                /* Find main entry point */
                if (mainEntryPoint != null) {
                    AnalysisMethod analysisStub = CEntryPointCallStubSupport.singleton().getStubForMethod(mainEntryPoint);
                    mainEntryPointHostedStub = (HostedMethod) hMetaAccess.getUniverse().lookup(analysisStub);
                    assert hostedEntryPoints.contains(mainEntryPointHostedStub);
                } else {
                    mainEntryPointHostedStub = null;
                }
                if (hostedEntryPoints.size() == 0) {
                    throw UserError.abort(""Warning: no entry points found, i.e., no method annotated with @"" + CEntryPoint.class.getSimpleName());
                }


                heap = new NativeImageHeap(aUniverse, hUniverse, hMetaAccess);


                BeforeCompilationAccessImpl config = new BeforeCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.beforeCompilation(config));


                bigbang.getUnsupportedFeatures().report(bigbang);
            } catch (UnsupportedFeatureException ufe) {
                throw UserError.abort(ufe.getMessage());
            }


            recordMethodsWithStackValues();
            recordRestrictHeapAccessCallees(aUniverse.getMethods());


            /*
             * After this point, all TypeFlow (and therefore also TypeState) objects are unreachable
             * and can be garbage collected. This is important to keep the overall memory footprint
             * low. However, this also means we no longer have complete call chain information. Only
             * the summarized information stored in the StaticAnalysisResult objects is available
             * after this point.
             */
            bigbang.cleanupAfterAnalysis();


            NativeImageCodeCache codeCache;
            CompileQueue compileQueue;
            try (StopTimer t = new Timer(imageName, ""compile"").start()) {
                compileQueue = HostedConfiguration.instance().createCompileQueue(debug, featureHandler, hUniverse, runtime, DeoptTester.enabled(), bigbang.getProviders().getSnippetReflection(),
                                compilationExecutor);
                compileQueue.finish(debug);


                /* release memory taken by graphs for the image writing */
                hUniverse.getMethods().forEach(HostedMethod::clear);


                codeCache = NativeImageCodeCacheFactory.get().newCodeCache(compileQueue, heap);
                codeCache.layoutConstants();
                codeCache.layoutMethods(debug, imageName);


                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.afterCompilation(config));
            }


            try (Indent indent = debug.logAndIndent(""create native image"")) {
                try (DebugContext.Scope buildScope = debug.scope(""CreateBootImage"")) {
                    try (StopTimer t = new Timer(imageName, ""image"").start()) {


                        // Start building the model of the native image heap.
                        heap.addInitialObjects();
                        // Then build the model of the code cache, which can
                        // add objects to the native image heap.
                        codeCache.addConstantsToHeap();
                        // Finish building the model of the native image heap.
                        heap.addTrailingObjects();


                        AfterHeapLayoutAccessImpl config = new AfterHeapLayoutAccessImpl(featureHandler, loader, hMetaAccess, debug);
                        featureHandler.forEachFeature(feature -> feature.afterHeapLayout(config));


                        this.image = AbstractBootImage.create(k, hUniverse, hMetaAccess, nativeLibraries, heap, codeCache, hostedEntryPoints, mainEntryPointHostedStub, loader.getClassLoader());
                        image.build(debug);
                        if (NativeImageOptions.PrintUniverse.getValue()) {
                            /*
                             * This debug output must be printed _after_ and not _during_ image
                             * building, because it adds some PrintStream objects to static fields,
                             * which disrupts the heap.
                             */
                            codeCache.printCompilationResults();
                        }
                    }
                }
            }


            BeforeImageWriteAccessImpl beforeConfig = new BeforeImageWriteAccessImpl(featureHandler, loader, imageName, image,
                            runtime.getRuntimeConfig(), aUniverse, hUniverse, optionProvider, hMetaAccess, debug);
            featureHandler.forEachFeature(feature -> feature.beforeImageWrite(beforeConfig));


            try (StopTimer t = new Timer(imageName, ""write"").start()) {
                /*
                 * This will write the debug info too -- i.e. we may be writing more than one file,
                 * if the debug info is in a separate file. We need to push writing the file to the
                 * image implementation, because whether the debug info and image share a file or
                 * not is an implementation detail of the image.
                 */
                Path tmpDir = tempDirectory();
                Path imagePath = image.write(debug, generatedFiles(HostedOptionValues.singleton()), tmpDir, imageName, beforeConfig).getOutputFile();


                AfterImageWriteAccessImpl afterConfig = new AfterImageWriteAccessImpl(featureHandler, loader, hUniverse, imagePath, tmpDir, image.getBootImageKind(), debug);
                featureHandler.forEachFeature(feature -> feature.afterImageWrite(afterConfig));
            }
        }
    }",1,4260
"private static void clearSystemPropertiesForImage() {
        System.clearProperty(ImageInfo.PROPERTY_IMAGE_CODE_KEY);
        System.clearProperty(ImageInfo.PROPERTY_IMAGE_KIND_KEY);
    }",0,
"private static void setSystemPropertiesForImage(NativeImageKind imageKind) {
        System.setProperty(ImageInfo.PROPERTY_IMAGE_CODE_KEY, ImageInfo.PROPERTY_IMAGE_CODE_VALUE_BUILDTIME);
        if (imageKind.executable) {
            System.setProperty(ImageInfo.PROPERTY_IMAGE_KIND_KEY, ImageInfo.PROPERTY_IMAGE_KIND_VALUE_EXECUTABLE);
        } else {
            System.setProperty(ImageInfo.PROPERTY_IMAGE_KIND_KEY, ImageInfo.PROPERTY_IMAGE_KIND_VALUE_SHARED_LIBRARY);
        }
    }",0,
"private void recordMethodsWithStackValues() {
        bigbang.getUniverse().getMethods().parallelStream().forEach(analysisMethod -> {
            if (analysisMethod.getTypeFlow() != null && analysisMethod.getTypeFlow().getGraph() != null && analysisMethod.getTypeFlow().getGraph().getNodes(StackValueNode.TYPE).isNotEmpty()) {
                hUniverse.recordMethodWithStackValues(analysisMethod);
            }
        });
    }",0,
"private static boolean addAssertionLIRPhases(LIRSuites lirSuites, boolean hosted) {
        if (hosted) {
            lirSuites.getPostAllocationOptimizationStage().appendPhase(new VerifyDeoptFrameStatesLIRPhase());
        }
        return true;
    }",0,
"private static <T extends Enum<T>> Set<T> parseCSVtoEnum(Class<T> enumType, String[] csvEnumValues) {
        EnumSet<T> result = EnumSet.noneOf(enumType);
        for (String enumValue : OptionUtils.flatten("","", csvEnumValues)) {
            try {
                result.add(Enum.valueOf(enumType, enumValue));
            } catch (IllegalArgumentException iae) {
                throw VMError.shouldNotReachHere(""Value '"" + enumValue + ""' does not exist. Available values are:\n"" + Arrays.toString(AMD64.CPUFeature.values()));
            }
        }
        return result;
    }",0,
"    @Override
    public ListenableFuture<Void> recover(QueueManagingVirtualHost<?> virtualHost)
    {
        EventLogger eventLogger = virtualHost.getEventLogger();
        MessageStore store = virtualHost.getMessageStore();
        MessageStore.MessageStoreReader storeReader = store.newMessageStoreReader();
        MessageStoreLogSubject logSubject = new MessageStoreLogSubject(virtualHost.getName(), store.getClass().getSimpleName());


        Map<Queue<?>, Integer> queueRecoveries = new TreeMap<>();
        Map<Long, ServerMessage<?>> recoveredMessages = new HashMap<>();
        Map<Long, StoredMessage<?>> unusedMessages = new TreeMap<>();
        Map<UUID, Integer> unknownQueuesWithMessages = new HashMap<>();
        Map<Queue<?>, Integer> queuesWithUnknownMessages = new HashMap<>();


        eventLogger.message(logSubject, MessageStoreMessages.RECOVERY_START());


        storeReader.visitMessages(new MessageVisitor(recoveredMessages, unusedMessages));


        eventLogger.message(logSubject, TransactionLogMessages.RECOVERY_START(null, false));
        try
        {
            storeReader.visitMessageInstances(new MessageInstanceVisitor(virtualHost,
                                                                         store,
                                                                         queueRecoveries,
                                                                         recoveredMessages,
                                                                         unusedMessages,
                                                                         unknownQueuesWithMessages,
                                                                         queuesWithUnknownMessages));
        }
        finally
        {
            if (!unknownQueuesWithMessages.isEmpty())
            {
                unknownQueuesWithMessages.forEach((queueId, count) -> {
                    LOGGER.info(""Discarded {} entry(s) associated with queue id '{}' as a queue with this ""
                                 + ""id does not appear in the configuration."",
                                 count, queueId);
                });
            }
            if (!queuesWithUnknownMessages.isEmpty())
            {
                queuesWithUnknownMessages.forEach((queue, count) -> {
                    LOGGER.info(""Discarded {} entry(s) associated with queue '{}' as the referenced message ""
                                 + ""does not exist."",
                                 count, queue.getName());
                });
            }
        }


        for(Map.Entry<Queue<?>, Integer> entry : queueRecoveries.entrySet())
        {
            Queue<?> queue = entry.getKey();
            Integer deliveredCount = entry.getValue();
            eventLogger.message(logSubject, TransactionLogMessages.RECOVERED(deliveredCount, queue.getName()));
            eventLogger.message(logSubject, TransactionLogMessages.RECOVERY_COMPLETE(queue.getName(), true));
            queue.completeRecovery();
        }


        for (Queue<?> q : virtualHost.getChildren(Queue.class))
        {
            if (!queueRecoveries.containsKey(q))
            {
                q.completeRecovery();
            }
        }


        storeReader.visitDistributedTransactions(new DistributedTransactionVisitor(virtualHost,
                                                                                   eventLogger,
                                                                                   logSubject, recoveredMessages, unusedMessages));


        for(StoredMessage<?> m : unusedMessages.values())
        {
            LOGGER.debug(""Message id '{}' is orphaned, removing"", m.getMessageNumber());
            m.remove();
        }


        if (unusedMessages.size() > 0)
        {
            LOGGER.info(""Discarded {} orphaned message(s)."", unusedMessages.size());
        }


        eventLogger.message(logSubject, TransactionLogMessages.RECOVERY_COMPLETE(null, false));


        eventLogger.message(logSubject,
                             MessageStoreMessages.RECOVERED(recoveredMessages.size() - unusedMessages.size()));
        eventLogger.message(logSubject, MessageStoreMessages.RECOVERY_COMPLETE());


        return Futures.immediateFuture(null);
    }",1,4276
"    private NameRegion[] findLinkComponentsInClosure(ClosureExpression firstArg,
            int offset) {
        if (! (firstArg.getCode() instanceof BlockStatement)) {
            return null;
        }
        
        BlockStatement code = (BlockStatement) firstArg.getCode();
        if (code.getStatements() == null) {
            return null;
        }
        NameRegion controllerName = null;
        NameRegion actionName = null;
        NameRegion viewName = null;


        for (Statement state : code.getStatements()) {
            if (state instanceof ExpressionStatement) {
                if (((ExpressionStatement) state).getExpression() instanceof BinaryExpression) {
                    BinaryExpression bexpr = (BinaryExpression) ((ExpressionStatement) state).getExpression();
                    Expression left = bexpr.getLeftExpression();
                    if (bexpr.getOperation().getText().equals(""="") && left instanceof VariableExpression) {
                        Expression right = bexpr.getRightExpression();
                        Region region;
                        if (right.getStart() <= offset && right.getEnd() >= offset) {
                            region = new Region(right.getStart(), right.getLength());
                        } else {
                            region = null;
                        }


                        String name = left.getText();
                        if (name.equals(""controller"")) {
                            controllerName = new NameRegion(right.getText(), region);
                        } else if (name.equals(""action"")) {
                            actionName = new NameRegion(right.getText(), region);
                        } else if (name.equals(""view"")) {
                            viewName = new NameRegion(right.getText(), region);
                        }
                    }
                }
            }
        }
        return new NameRegion[] { controllerName, actionName, viewName };
    }",1,4428
"private IType findController(String controllerName, IJavaProject project) {
        try {
            return GrailsWorkspaceCore.get().create(project).findControllerFromSimpleName(controllerName);
        } catch (JavaModelException e) {
            GrailsCoreActivator.log(e);
        }
        return null;
    }",0,
"  private EntityCollection createETStreamOnComplexProp(Edm edm, OData odata) {
    EntityCollection entityCollection = new EntityCollection();


    Link readLink = new Link();
    readLink.setRel(Constants.NS_MEDIA_READ_LINK_REL);
    readLink.setHref(""readLink"");
    Entity entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyStream"", createImage(""darkturquoise"")));
    readLink.setInlineEntity(entity);
    
    Link readLink1 = new Link();
    readLink1.setRel(Constants.NS_MEDIA_READ_LINK_REL);
    readLink1.setHref(""readLink"");
    entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyEntityStream"", createImage(""darkturquoise"")));
    readLink1.setInlineEntity(entity);
    
    entityCollection.getEntities().add(new Entity()
        .addProperty(createPrimitive(""PropertyInt16"", Short.MAX_VALUE))
        .addProperty(createPrimitive(""PropertyInt32"", Integer.MAX_VALUE))
        .addProperty(new Property(null, ""PropertyEntityStream"", ValueType.PRIMITIVE, readLink1))
        .addProperty(createComplex(""PropertyCompWithStream"",
            ComplexTypeProvider.nameCTWithStreamProp.getFullQualifiedNameAsString(),
            new Property(null, ""PropertyStream"", ValueType.PRIMITIVE, readLink),
            createComplex(""PropertyComp"", 
                ComplexTypeProvider.nameCTTwoPrim.getFullQualifiedNameAsString(),
                createPrimitive(""PropertyInt16"", (short) 333),
                createPrimitive(""PropertyString"", ""TEST123"")))));
    
    Link editLink = new Link();
    editLink.setRel(Constants.NS_MEDIA_EDIT_LINK_REL);
    editLink.setHref(""http://mediaserver:1234/editLink"");
    editLink.setMediaETag(""eTag"");
    editLink.setType(""image/jpeg"");
    entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyStream"", createImage(""royalblue"")));
    editLink.setInlineEntity(entity);
    
    Link editLink2 = new Link();
    editLink2.setRel(Constants.NS_MEDIA_EDIT_LINK_REL);
    editLink2.setHref(""http://mediaserver:1234/editLink"");
    editLink2.setMediaETag(""eTag"");
    editLink2.setType(""image/jpeg"");
    entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyEntityStream"", createImage(""royalblue"")));
    editLink2.setInlineEntity(entity);


    entityCollection.getEntities().add(new Entity()
        .addProperty(createPrimitive(""PropertyInt16"", (short) 7))
        .addProperty(createPrimitive(""PropertyInt32"", (Integer) 10))
        .addProperty(new Property(null, ""PropertyEntityStream"", ValueType.PRIMITIVE, editLink2))
        .addProperty(createComplex(""PropertyCompWithStream"",
            ComplexTypeProvider.nameCTWithStreamProp.getFullQualifiedNameAsString(),
            new Property(null, ""PropertyStream"", ValueType.PRIMITIVE, editLink),
            createComplex(""PropertyComp"", 
                ComplexTypeProvider.nameCTTwoPrim.getFullQualifiedNameAsString(),
                createPrimitive(""PropertyInt16"", (short) 333),
                createPrimitive(""PropertyString"", ""TEST123"")))));


    setEntityType(entityCollection, edm.getEntityType(EntityTypeProvider.nameETStreamOnComplexProp));
    createEntityId(edm, odata, ""ESStreamOnComplexProp"", entityCollection);
    createOperations(""ESStreamOnComplexProp"", entityCollection, EntityTypeProvider.nameETStreamOnComplexProp);
    return entityCollection;
  }",1,5777
"	@Nullable
	public static PropertyEditor findEditorByConvention(@Nullable Class<?> targetType) {
		if (targetType == null || targetType.isArray() || unknownEditorTypes.contains(targetType)) {
			return null;
		}
		ClassLoader cl = targetType.getClassLoader();
		if (cl == null) {
			try {
				cl = ClassLoader.getSystemClassLoader();
				if (cl == null) {
					return null;
				}
			}
			catch (Throwable ex) {
				// e.g. AccessControlException on Google App Engine
				if (logger.isDebugEnabled()) {
					logger.debug(""Could not access system ClassLoader: "" + ex);
				}
				return null;
			}
		}
		String editorName = targetType.getName() + ""Editor"";
		try {
			Class<?> editorClass = cl.loadClass(editorName);
			if (!PropertyEditor.class.isAssignableFrom(editorClass)) {
				if (logger.isInfoEnabled()) {
					logger.info(""Editor class ["" + editorName +
							""] does not implement [java.beans.PropertyEditor] interface"");
				}
				unknownEditorTypes.add(targetType);
				return null;
			}
			return (PropertyEditor) instantiateClass(editorClass);
		}
		catch (ClassNotFoundException ex) {
			if (logger.isTraceEnabled()) {
				logger.trace(""No property editor ["" + editorName + ""] found for type "" +
						targetType.getName() + "" according to 'Editor' suffix convention"");
			}
			unknownEditorTypes.add(targetType);
			return null;
		}
	}",1,6247
"	private void processInfoOutput(final BufferedReader stdout) {
		Matcher matcher;


		final MainControllerElement tempRoot = new MainControllerElement(""Temporal root"", this);
		readFullLineOnly(stdout);
		if (fastLine == null) {
			return;
		}
		matcher = MC_STATE_PATTERN.matcher(fastLine);
		if (matcher.matches()) {
			final String mcStateName = matcher.group(1);
			tempRoot.setStateInfo(new InformationElement(""State: "" + mcStateName));
			readFullLineOnly(stdout);


			suspectedLastState = getMCStateFromName(mcStateName);
		} else {
			fastLine = null;
			return;
		}
		if (fastLine != null && "" host information:"".equals(fastLine)) {
			readFullLineOnly(stdout);
		} else {
			fastLine = null;
			return;
		}
		if (fastLine != null) {
			if (fastLine.startsWith(""  -"")) {
				// host list
				while (fastLine != null && fastLine.startsWith(""  -"")) {
					processInfoOutputHC(stdout, tempRoot);
				}
			} else if (""  no HCs are connected"".equals(fastLine)) {
				readFullLineOnly(stdout);
			}
		} else {
			fastLine = null;
			return;
		}


		if (fastLine != null && PAUSE_PATTERN.matcher(fastLine).matches()) {
			tempRoot.setPauseInfo(new InformationElement(fastLine.trim()));
			readFullLineOnly(stdout);
		} else {
			fastLine = null;
			return;
		}
		if (fastLine != null && CONSOLE_LOGGING_PATTERN.matcher(fastLine).matches()) {
			tempRoot.setConsoleLoggingInfo(new InformationElement(fastLine.trim()));
		} else {
			fastLine = null;
			return;
		}
		if (mainControllerRoot != null) {
			mainControllerRoot.children().clear();
			mainControllerRoot.transferData(tempRoot);
		}


	}",1,6289
"  @Override
  public ExitCode runWithoutHelp(CommandRunnerParams params) throws Exception {
    ProjectFilesystem projectFilesystem = params.getCell().getFilesystem();
    try (ProjectBuildFileParser parser =
        new DefaultProjectBuildFileParserFactory(
                new DefaultTypeCoercerFactory(),
                params.getConsole(),
                new ParserPythonInterpreterProvider(
                    params.getCell().getBuckConfig(), params.getExecutableFinder()),
                params.getKnownRuleTypesProvider(),
                params.getManifestServiceSupplier(),
                params.getFileHashCache())
            .createBuildFileParser(
                params.getBuckEventBus(), params.getCell(), params.getWatchman())) {
      /*
       * The super console does a bunch of rewriting over the top of the console such that
       * simultaneously writing to stdout and stderr in an interactive session is problematic.
       * (Overwritten characters, lines never showing up, etc). As such, writing to stdout directly
       * stops superconsole rendering (no errors appear). Because of all of this, we need to
       * just buffer the output and print it to stdout at the end fo the run. The downside
       * is that we have to buffer all of the output in memory, and it could potentially be large,
       * however, we'll just have to accept that tradeoff for now to get both error messages
       * from the parser, and the final output
       */


      try (ByteArrayOutputStream byteOut = new ByteArrayOutputStream();
          PrintStream out = new PrintStream(new BufferedOutputStream(byteOut))) {
        for (String pathToBuildFile : getArguments()) {
          // Print a comment with the path to the build file.
          out.printf(""# %s\n\n"", pathToBuildFile);


          // Resolve the path specified by the user.
          Path path = Paths.get(pathToBuildFile);
          if (!path.isAbsolute()) {
            Path root = projectFilesystem.getRootPath();
            path = root.resolve(path);
          }


          // Parse the rules from the build file.
          ImmutableMap<String, Map<String, Object>> rawRules =
              parser.getBuildFileManifest(path).getTargets();


          // Format and print the rules from the raw data, filtered by type.
          ImmutableSet<String> types = getTypes();
          Predicate<String> includeType = type -> types.isEmpty() || types.contains(type);
          printRulesToStdout(out, rawRules, includeType);
        }


        // Make sure we tell the event listener to flush, otherwise there is a race condition where
        // the event listener might not have flushed, we dirty the stream, and then it will not
        // render the last frame (see {@link SuperConsoleEventListener})
        params.getBuckEventBus().post(new FlushConsoleEvent());
        out.close();
        params.getConsole().getStdOut().write(byteOut.toByteArray());
      }
    }


    return ExitCode.SUCCESS;
  }",1,6353
"    protected SQLBuffer toBulkOperation(ClassMapping mapping, Select sel,
        JDBCStore store, Object[] params, Map updateParams) {
        SQLBuffer sql = new SQLBuffer(this);
        if (updateParams == null) {
          if (requiresTargetForDelete) {
            sql.append(""DELETE "");
            SQLBuffer deleteTargets = getDeleteTargets(sel);
            sql.append(deleteTargets);
            sql.append("" FROM "");
          } else {
            sql.append(""DELETE FROM "");
          }
        }
        else
            sql.append(""UPDATE "");
        sel.addJoinClassConditions();


        // if there is only a single table in the select, then we can
        // just issue a single DELETE FROM TABLE WHERE <conditions>
        // statement; otherwise, since SQL doesn't allow deleting
        // from one of a multi-table select, we need to issue a subselect
        // like DELETE FROM TABLE WHERE EXISTS
        // (SELECT 1 FROM TABLE t0 WHERE t0.ID = TABLE.ID); also, some
        // databases do not allow aliases in delete statements, which
        // also causes us to use a subselect
        Collection<String> selectedTables = getSelectTableAliases(sel);
        if (selectedTables.size() == 1 && supportsSubselect
            && allowsAliasInBulkClause) {
            SQLBuffer from;
            if (sel.getFromSelect() != null)
                from = getFromSelect(sel, false);
            else
                from = getFrom(sel, false);


            sql.append(from);
            appendUpdates(sel, store, sql, params, updateParams,
                allowsAliasInBulkClause);


            SQLBuffer where = sel.getWhere();
            if (where != null && !where.isEmpty()) {
                sql.append("" WHERE "");
                sql.append(where);
            }
            return sql;
        }


        Table table = mapping.getTable();
        String tableName = getFullName(table, false);


        // only use a  subselect if the where is not empty; otherwise
        // an unqualified delete or update will work
        if (sel.getWhere() == null || sel.getWhere().isEmpty()) {
            sql.append(tableName);
            appendUpdates(sel, store, sql, params, updateParams, false);
            return sql;
        }


        // we need to use a subselect if we are to bulk delete where
        // the select includes multiple tables; if the database
        // doesn't support it, then we need to signal this by returning null
        if (!supportsSubselect || !supportsCorrelatedSubselect)
            return null;


        Column[] pks = mapping.getPrimaryKeyColumns();
        sel.clearSelects();
        sel.setDistinct(true);


        // if we have only a single PK, we can use a non-correlated
        // subquery (using an IN statement), which is much faster than
        // a correlated subquery (since a correlated subquery needs
        // to be executed once for each row in the table)
        if (pks.length == 1) {
            sel.select(pks[0]);
            sql.append(tableName);
            appendUpdates(sel, store, sql, params, updateParams, false);
            sql.append("" WHERE "").
                append(pks[0]).append("" IN ("").
                append(sel.toSelect(false, null)).append("")"");
        } else {
            sel.clearSelects();
            sel.setDistinct(false);


            // since the select is using a correlated subquery, we
            // only need to select a bogus virtual column
            sel.select(""1"", null);


            // add in the joins to the table
            Column[] cols = table.getPrimaryKey().getColumns();
            SQLBuffer buf = new SQLBuffer(this);
            buf.append(""("");
            for (int i = 0; i < cols.length; i++) {
                if (i > 0)
                    buf.append("" AND "");


                // add in ""t0.PK = MYTABLE.PK""
                buf.append(sel.getColumnAlias(cols[i])).append("" = "").
                    append(table).append(catalogSeparator).append(cols[i]);
            }
            buf.append("")"");
            sel.where(buf, null);


            sql.append(tableName);
            appendUpdates(sel, store, sql, params, updateParams, false);
            sql.append("" WHERE EXISTS ("").
                append(sel.toSelect(false, null)).append("")"");
        }
        return sql;
    }",1,6354
"	public void run( IAction action )
	{
		if ( !preGenerate( ) )
		{
			return;
		}


		IFile file = getSelectedFile( );
		if ( file != null )
		{
			String url = file.getLocation( ).toOSString( );


			Map options = new HashMap( );
			options.put( WebViewer.RESOURCE_FOLDER_KEY,
					ReportPlugin.getDefault( )
							.getResourceFolder( file.getProject( ) ) );
			options.put( WebViewer.SERVLET_NAME_KEY, WebViewer.VIEWER_DOCUMENT );


			Object adapter = ElementAdapterManager.getAdapter( action,
					IPreviewAction.class );


			if ( adapter instanceof IPreviewAction )
			{
				IPreviewAction delegate = (IPreviewAction) adapter;


				delegate.setProperty( IPreviewConstants.REPORT_PREVIEW_OPTIONS,
						options );
				delegate.setProperty( IPreviewConstants.REPORT_FILE_PATH, url );


				delegate.run( );


				return;
			}


			try
			{
				WebViewer.display( url, options );
			}
			catch ( Exception e )
			{
				ExceptionUtil.handle( e );
				return;
			}
		}
		else
		{
			action.setEnabled( false );
		}
	}",1,6389
"    public static RuleSet parse(final Reader configReader, EventLoggerProvider eventLogger)
    {
        RuleSetCreator ruleSetCreator = new RuleSetCreator();


        int line = 0;
        try(Reader fileReader = configReader)
        {
            LOGGER.debug(""About to load ACL file"");
            StreamTokenizer tokenizer = new StreamTokenizer(new BufferedReader(fileReader));
            tokenizer.resetSyntax(); // setup the tokenizer


            tokenizer.commentChar(COMMENT); // single line comments
            tokenizer.eolIsSignificant(true); // return EOL as a token
            tokenizer.ordinaryChar('='); // equals is a token
            tokenizer.ordinaryChar(CONTINUATION); // continuation character (when followed by EOL)
            tokenizer.quoteChar('""'); // double quote
            tokenizer.quoteChar('\''); // single quote
            tokenizer.whitespaceChars('\u0000', '\u0020'); // whitespace (to be ignored) TODO properly
            tokenizer.wordChars('a', 'z'); // unquoted token characters [a-z]
            tokenizer.wordChars('A', 'Z'); // [A-Z]
            tokenizer.wordChars('0', '9'); // [0-9]
            tokenizer.wordChars('_', '_'); // underscore
            tokenizer.wordChars('-', '-'); // dash
            tokenizer.wordChars('.', '.'); // dot
            tokenizer.wordChars('*', '*'); // star
            tokenizer.wordChars('@', '@'); // at
            tokenizer.wordChars(':', ':'); // colon


            // parse the acl file lines
            Stack<String> stack = new Stack<>();
            int current;
            do {
                current = tokenizer.nextToken();
                line = tokenizer.lineno()-1;
                switch (current)
                {
                    case StreamTokenizer.TT_EOF:
                    case StreamTokenizer.TT_EOL:
                        if (stack.isEmpty())
                        {
                            break; // blank line
                        }


                        // pull out the first token from the bottom of the stack and check arguments exist
                        String first = stack.firstElement();
                        stack.removeElementAt(0);
                        if (stack.isEmpty())
                        {
                            throw new IllegalConfigurationException(String.format(NOT_ENOUGH_TOKENS_MSG, line));
                        }


                        // check for and parse optional initial number for ACL lines
                        Integer number = null;
                        if (first != null && first.matches(""\\d+""))
                        {
                            // set the acl number and get the next element
                            number = Integer.valueOf(first);
                            first = stack.firstElement();
                            stack.removeElementAt(0);
                        }


                        if (ACL.equalsIgnoreCase(first))
                        {
                            parseAcl(number, stack, ruleSetCreator, line);
                        }
                        else if (number == null)
                        {
                            if(""GROUP"".equalsIgnoreCase(first))
                            {
                                throw new IllegalConfigurationException(String.format(""GROUP keyword not supported at ""
                                                                                      + ""line %d. Groups should defined ""
                                                                                      + ""via a Group Provider, not in ""
                                                                                      + ""the ACL file."",
                                                                                      line));
                            }
                            else if (CONFIG.equalsIgnoreCase(first))
                            {
                                parseConfig(stack, ruleSetCreator, line);
                            }
                            else
                            {
                                throw new IllegalConfigurationException(String.format(UNRECOGNISED_INITIAL_MSG, first, line));
                            }
                        }
                        else
                        {
                            throw new IllegalConfigurationException(String.format(NUMBER_NOT_ALLOWED_MSG, first, line));
                        }


                        // reset stack, start next line
                        stack.clear();
                        break;
                    case StreamTokenizer.TT_NUMBER:
                        stack.push(Integer.toString(Double.valueOf(tokenizer.nval).intValue()));
                        break;
                    case StreamTokenizer.TT_WORD:
                        stack.push(tokenizer.sval); // token
                        break;
                    default:
                        if (tokenizer.ttype == CONTINUATION)
                        {
                            int next = tokenizer.nextToken();
                            line = tokenizer.lineno()-1;
                            if (next == StreamTokenizer.TT_EOL)
                            {
	                            break; // continue reading next line
                            }


                            // invalid location for continuation character (add one to line because we ate the EOL)
                            throw new IllegalConfigurationException(String.format(PREMATURE_CONTINUATION_MSG, line + 1));
                        }
                        else if (tokenizer.ttype == '\'' || tokenizer.ttype == '""')
                        {
                            stack.push(tokenizer.sval); // quoted token
                        }
                        else
                        {
                            stack.push(Character.toString((char) tokenizer.ttype)); // single character
                        }
                }
            } while (current != StreamTokenizer.TT_EOF);


            if (!stack.isEmpty())
            {
                throw new IllegalConfigurationException(String.format(PREMATURE_EOF_MSG, line));
            }
        }
        catch (IllegalArgumentException iae)
        {
            throw new IllegalConfigurationException(String.format(PARSE_TOKEN_FAILED_MSG, line), iae);
        }
        catch (IOException ioe)
        {
            throw new IllegalConfigurationException(CANNOT_LOAD_MSG, ioe);
        }
        return ruleSetCreator.createRuleSet(eventLogger);
    }",1,7007
"    private void resizeInstructions() {
        byte[] b = code.data; // bytecode of the method
        int u, v, label; // indexes in b
        int i, j; // loop indexes
        /*
         * 1st step: As explained above, resizing an instruction may require to
         * resize another one, which may require to resize yet another one, and
         * so on. The first step of the algorithm consists in finding all the
         * instructions that need to be resized, without modifying the code.
         * This is done by the following ""fix point"" algorithm:
         * 
         * Parse the code to find the jump instructions whose offset will need
         * more than 2 bytes to be stored (the future offset is computed from
         * the current offset and from the number of bytes that will be inserted
         * or removed between the source and target instructions). For each such
         * instruction, adds an entry in (a copy of) the indexes and sizes
         * arrays (if this has not already been done in a previous iteration!).
         * 
         * If at least one entry has been added during the previous step, go
         * back to the beginning, otherwise stop.
         * 
         * In fact the real algorithm is complicated by the fact that the size
         * of TABLESWITCH and LOOKUPSWITCH instructions depends on their
         * position in the bytecode (because of padding). In order to ensure the
         * convergence of the algorithm, the number of bytes to be added or
         * removed from these instructions is over estimated during the previous
         * loop, and computed exactly only after the loop is finished (this
         * requires another pass to parse the bytecode of the method).
         */
        int[] allIndexes = new int[0]; // copy of indexes
        int[] allSizes = new int[0]; // copy of sizes
        boolean[] resize; // instructions to be resized
        int newOffset; // future offset of a jump instruction


        resize = new boolean[code.length];


        // 3 = loop again, 2 = loop ended, 1 = last pass, 0 = done
        int state = 3;
        do {
            if (state == 3) {
                state = 2;
            }
            u = 0;
            while (u < b.length) {
                int opcode = b[u] & 0xFF; // opcode of current instruction
                int insert = 0; // bytes to be added after this instruction


                switch (ClassWriter.TYPE[opcode]) {
                case ClassWriter.NOARG_INSN:
                case ClassWriter.IMPLVAR_INSN:
                    u += 1;
                    break;
                case ClassWriter.LABEL_INSN:
                    if (opcode > 201) {
                        // converts temporary opcodes 202 to 217, 218 and
                        // 219 to IFEQ ... JSR (inclusive), IFNULL and
                        // IFNONNULL
                        opcode = opcode < 218 ? opcode - 49 : opcode - 20;
                        label = u + readUnsignedShort(b, u + 1);
                    } else {
                        label = u + readShort(b, u + 1);
                    }
                    newOffset = getNewOffset(allIndexes, allSizes, u, label);
                    if (newOffset < Short.MIN_VALUE
                            || newOffset > Short.MAX_VALUE) {
                        if (!resize[u]) {
                            if (opcode == Opcodes.GOTO || opcode == Opcodes.JSR) {
                                // two additional bytes will be required to
                                // replace this GOTO or JSR instruction with
                                // a GOTO_W or a JSR_W
                                insert = 2;
                            } else {
                                // five additional bytes will be required to
                                // replace this IFxxx <l> instruction with
                                // IFNOTxxx <l'> GOTO_W <l>, where IFNOTxxx
                                // is the ""opposite"" opcode of IFxxx (i.e.,
                                // IFNE for IFEQ) and where <l'> designates
                                // the instruction just after the GOTO_W.
                                insert = 5;
                            }
                            resize[u] = true;
                        }
                    }
                    u += 3;
                    break;
                case ClassWriter.LABELW_INSN:
                    u += 5;
                    break;
                case ClassWriter.TABL_INSN:
                    if (state == 1) {
                        // true number of bytes to be added (or removed)
                        // from this instruction = (future number of padding
                        // bytes - current number of padding byte) -
                        // previously over estimated variation =
                        // = ((3 - newOffset%4) - (3 - u%4)) - u%4
                        // = (-newOffset%4 + u%4) - u%4
                        // = -(newOffset & 3)
                        newOffset = getNewOffset(allIndexes, allSizes, 0, u);
                        insert = -(newOffset & 3);
                    } else if (!resize[u]) {
                        // over estimation of the number of bytes to be
                        // added to this instruction = 3 - current number
                        // of padding bytes = 3 - (3 - u%4) = u%4 = u & 3
                        insert = u & 3;
                        resize[u] = true;
                    }
                    // skips instruction
                    u = u + 4 - (u & 3);
                    u += 4 * (readInt(b, u + 8) - readInt(b, u + 4) + 1) + 12;
                    break;
                case ClassWriter.LOOK_INSN:
                    if (state == 1) {
                        // like TABL_INSN
                        newOffset = getNewOffset(allIndexes, allSizes, 0, u);
                        insert = -(newOffset & 3);
                    } else if (!resize[u]) {
                        // like TABL_INSN
                        insert = u & 3;
                        resize[u] = true;
                    }
                    // skips instruction
                    u = u + 4 - (u & 3);
                    u += 8 * readInt(b, u + 4) + 8;
                    break;
                case ClassWriter.WIDE_INSN:
                    opcode = b[u + 1] & 0xFF;
                    if (opcode == Opcodes.IINC) {
                        u += 6;
                    } else {
                        u += 4;
                    }
                    break;
                case ClassWriter.VAR_INSN:
                case ClassWriter.SBYTE_INSN:
                case ClassWriter.LDC_INSN:
                    u += 2;
                    break;
                case ClassWriter.SHORT_INSN:
                case ClassWriter.LDCW_INSN:
                case ClassWriter.FIELDORMETH_INSN:
                case ClassWriter.TYPE_INSN:
                case ClassWriter.IINC_INSN:
                    u += 3;
                    break;
                case ClassWriter.ITFMETH_INSN:
                case ClassWriter.INDYMETH_INSN:
                    u += 5;
                    break;
                // case ClassWriter.MANA_INSN:
                default:
                    u += 4;
                    break;
                }
                if (insert != 0) {
                    // adds a new (u, insert) entry in the allIndexes and
                    // allSizes arrays
                    int[] newIndexes = new int[allIndexes.length + 1];
                    int[] newSizes = new int[allSizes.length + 1];
                    System.arraycopy(allIndexes, 0, newIndexes, 0,
                            allIndexes.length);
                    System.arraycopy(allSizes, 0, newSizes, 0, allSizes.length);
                    newIndexes[allIndexes.length] = u;
                    newSizes[allSizes.length] = insert;
                    allIndexes = newIndexes;
                    allSizes = newSizes;
                    if (insert > 0) {
                        state = 3;
                    }
                }
            }
            if (state < 3) {
                --state;
            }
        } while (state != 0);


        // 2nd step:
        // copies the bytecode of the method into a new bytevector, updates the
        // offsets, and inserts (or removes) bytes as requested.


        ByteVector newCode = new ByteVector(code.length);


        u = 0;
        while (u < code.length) {
            int opcode = b[u] & 0xFF;
            switch (ClassWriter.TYPE[opcode]) {
            case ClassWriter.NOARG_INSN:
            case ClassWriter.IMPLVAR_INSN:
                newCode.putByte(opcode);
                u += 1;
                break;
            case ClassWriter.LABEL_INSN:
                if (opcode > 201) {
                    // changes temporary opcodes 202 to 217 (inclusive), 218
                    // and 219 to IFEQ ... JSR (inclusive), IFNULL and
                    // IFNONNULL
                    opcode = opcode < 218 ? opcode - 49 : opcode - 20;
                    label = u + readUnsignedShort(b, u + 1);
                } else {
                    label = u + readShort(b, u + 1);
                }
                newOffset = getNewOffset(allIndexes, allSizes, u, label);
                if (resize[u]) {
                    // replaces GOTO with GOTO_W, JSR with JSR_W and IFxxx
                    // <l> with IFNOTxxx <l'> GOTO_W <l>, where IFNOTxxx is
                    // the ""opposite"" opcode of IFxxx (i.e., IFNE for IFEQ)
                    // and where <l'> designates the instruction just after
                    // the GOTO_W.
                    if (opcode == Opcodes.GOTO) {
                        newCode.putByte(200); // GOTO_W
                    } else if (opcode == Opcodes.JSR) {
                        newCode.putByte(201); // JSR_W
                    } else {
                        newCode.putByte(opcode <= 166 ? ((opcode + 1) ^ 1) - 1
                                : opcode ^ 1);
                        newCode.putShort(8); // jump offset
                        newCode.putByte(200); // GOTO_W
                        // newOffset now computed from start of GOTO_W
                        newOffset -= 3;
                    }
                    newCode.putInt(newOffset);
                } else {
                    newCode.putByte(opcode);
                    newCode.putShort(newOffset);
                }
                u += 3;
                break;
            case ClassWriter.LABELW_INSN:
                label = u + readInt(b, u + 1);
                newOffset = getNewOffset(allIndexes, allSizes, u, label);
                newCode.putByte(opcode);
                newCode.putInt(newOffset);
                u += 5;
                break;
            case ClassWriter.TABL_INSN:
                // skips 0 to 3 padding bytes
                v = u;
                u = u + 4 - (v & 3);
                // reads and copies instruction
                newCode.putByte(Opcodes.TABLESWITCH);
                newCode.putByteArray(null, 0, (4 - newCode.length % 4) % 4);
                label = v + readInt(b, u);
                u += 4;
                newOffset = getNewOffset(allIndexes, allSizes, v, label);
                newCode.putInt(newOffset);
                j = readInt(b, u);
                u += 4;
                newCode.putInt(j);
                j = readInt(b, u) - j + 1;
                u += 4;
                newCode.putInt(readInt(b, u - 4));
                for (; j > 0; --j) {
                    label = v + readInt(b, u);
                    u += 4;
                    newOffset = getNewOffset(allIndexes, allSizes, v, label);
                    newCode.putInt(newOffset);
                }
                break;
            case ClassWriter.LOOK_INSN:
                // skips 0 to 3 padding bytes
                v = u;
                u = u + 4 - (v & 3);
                // reads and copies instruction
                newCode.putByte(Opcodes.LOOKUPSWITCH);
                newCode.putByteArray(null, 0, (4 - newCode.length % 4) % 4);
                label = v + readInt(b, u);
                u += 4;
                newOffset = getNewOffset(allIndexes, allSizes, v, label);
                newCode.putInt(newOffset);
                j = readInt(b, u);
                u += 4;
                newCode.putInt(j);
                for (; j > 0; --j) {
                    newCode.putInt(readInt(b, u));
                    u += 4;
                    label = v + readInt(b, u);
                    u += 4;
                    newOffset = getNewOffset(allIndexes, allSizes, v, label);
                    newCode.putInt(newOffset);
                }
                break;
            case ClassWriter.WIDE_INSN:
                opcode = b[u + 1] & 0xFF;
                if (opcode == Opcodes.IINC) {
                    newCode.putByteArray(b, u, 6);
                    u += 6;
                } else {
                    newCode.putByteArray(b, u, 4);
                    u += 4;
                }
                break;
            case ClassWriter.VAR_INSN:
            case ClassWriter.SBYTE_INSN:
            case ClassWriter.LDC_INSN:
                newCode.putByteArray(b, u, 2);
                u += 2;
                break;
            case ClassWriter.SHORT_INSN:
            case ClassWriter.LDCW_INSN:
            case ClassWriter.FIELDORMETH_INSN:
            case ClassWriter.TYPE_INSN:
            case ClassWriter.IINC_INSN:
                newCode.putByteArray(b, u, 3);
                u += 3;
                break;
            case ClassWriter.ITFMETH_INSN:
            case ClassWriter.INDYMETH_INSN:
                newCode.putByteArray(b, u, 5);
                u += 5;
                break;
            // case MANA_INSN:
            default:
                newCode.putByteArray(b, u, 4);
                u += 4;
                break;
            }
        }


        // recomputes the stack map frames
        if (frameCount > 0) {
            if (compute == FRAMES) {
                frameCount = 0;
                stackMap = null;
                previousFrame = null;
                frame = null;
                Frame f = new Frame();
                f.owner = labels;
                Type[] args = Type.getArgumentTypes(descriptor);
                f.initInputFrame(cw, access, args, maxLocals);
                visitFrame(f);
                Label l = labels;
                while (l != null) {
                    /*
                     * here we need the original label position. getNewOffset
                     * must therefore never have been called for this label.
                     */
                    u = l.position - 3;
                    if ((l.status & Label.STORE) != 0 || (u >= 0 && resize[u])) {
                        getNewOffset(allIndexes, allSizes, l);
                        // TODO update offsets in UNINITIALIZED values
                        visitFrame(l.frame);
                    }
                    l = l.successor;
                }
            } else {
                /*
                 * Resizing an existing stack map frame table is really hard.
                 * Not only the table must be parsed to update the offets, but
                 * new frames may be needed for jump instructions that were
                 * inserted by this method. And updating the offsets or
                 * inserting frames can change the format of the following
                 * frames, in case of packed frames. In practice the whole table
                 * must be recomputed. For this the frames are marked as
                 * potentially invalid. This will cause the whole class to be
                 * reread and rewritten with the COMPUTE_FRAMES option (see the
                 * ClassWriter.toByteArray method). This is not very efficient
                 * but is much easier and requires much less code than any other
                 * method I can think of.
                 */
                cw.invalidFrames = true;
            }
        }
        // updates the exception handler block labels
        Handler h = firstHandler;
        while (h != null) {
            getNewOffset(allIndexes, allSizes, h.start);
            getNewOffset(allIndexes, allSizes, h.end);
            getNewOffset(allIndexes, allSizes, h.handler);
            h = h.next;
        }
        // updates the instructions addresses in the
        // local var and line number tables
        for (i = 0; i < 2; ++i) {
            ByteVector bv = i == 0 ? localVar : localVarType;
            if (bv != null) {
                b = bv.data;
                u = 0;
                while (u < bv.length) {
                    label = readUnsignedShort(b, u);
                    newOffset = getNewOffset(allIndexes, allSizes, 0, label);
                    writeShort(b, u, newOffset);
                    label += readUnsignedShort(b, u + 2);
                    newOffset = getNewOffset(allIndexes, allSizes, 0, label)
                            - newOffset;
                    writeShort(b, u + 2, newOffset);
                    u += 10;
                }
            }
        }
        if (lineNumber != null) {
            b = lineNumber.data;
            u = 0;
            while (u < lineNumber.length) {
                writeShort(
                        b,
                        u,
                        getNewOffset(allIndexes, allSizes, 0,
                                readUnsignedShort(b, u)));
                u += 4;
            }
        }
        // updates the labels of the other attributes
        Attribute attr = cattrs;
        while (attr != null) {
            Label[] labels = attr.getLabels();
            if (labels != null) {
                for (i = labels.length - 1; i >= 0; --i) {
                    getNewOffset(allIndexes, allSizes, labels[i]);
                }
            }
            attr = attr.next;
        }


        // replaces old bytecodes with new ones
        code = newCode;
    }",1,8170
"	@Override
	public ListCompositeContentProvider getContentProvider(EObject object, EStructuralFeature feature, EList<EObject>list) {
		if (contentProvider==null) {
			contentProvider = new ListCompositeContentProvider(this, object, feature, list) {
				@Override
				public Object[] getElements(Object inputElement) {
					
					Object elements[] = super.getElements(inputElement);
					List<Property> props = null;
					ModelExtensionDescriptor med = null;
					ExtendedPropertiesAdapter<?> adapter = ExtendedPropertiesAdapter.adapt(activity);
					if (adapter!=null) {
						// look for it in the property adapter first
						med = adapter.getProperty(ModelExtensionDescriptor.class);
					}


					if (med==null) {
						// not found? get the Custom Task ID from the Task object
						String id = CustomElementFeatureContainer.findId(activity);
						if (id!=null) {
							// and look it up in the Target Runtime's list of
							// Custom Task Descriptors
					    	TargetRuntime rt = TargetRuntime.getRuntime(activity);
					    	med = rt.getCustomTask(id);
						}
					}
					if (med!=null) {
						if (JbpmIoParametersListComposite.this.isInput)
							props = med.getProperties(""ioSpecification/dataInputs/name""); //$NON-NLS-1$
						else
							props = med.getProperties(""ioSpecification/dataOutputs/name""); //$NON-NLS-1$
					}
					
					List<Object> filtered = new ArrayList<Object>();
					for (Object e : elements) {
						boolean skip = false;
						EStructuralFeature f = ((EObject)e).eClass().getEStructuralFeature(""name""); //$NON-NLS-1$
						if (f!=null) {
							Object elementName = (String) ((EObject)e).eGet(f);
							if (props!=null) {
								for (Property p : props) {
									Object propName = p.getFirstStringValue();
									if (elementName!=null && propName!=null && elementName.equals(propName)) {
										skip = true;
										break;
									}
								}
							}
							if (activity instanceof SendTask) {
								if (""Message"".equals(elementName)) {
									skip = true;
								}
							}
							else if (activity instanceof ReceiveTask) {
								if (""Message"".equals(elementName)) {
									skip = true;
								}
//								else if (""MessageId"".equals(elementName)) {
//									skip = true;
//								}
							}
							else if (activity instanceof ServiceTask) {
								if (""Parameter"".equals(elementName)) {
									skip = true;
								}
								else if (""Result"".equals(elementName)) {
									skip = true;
								}
								// TODO: these should be automatically added by the ""Service Task"" tab...
//								else if (""Interface"".equals(elementName)) {
//									skip = true;
//								}
//								else if (""Operation"".equals(elementName)) {
//									skip = true;
//								}
//								else if (""ParameterType"".equals(elementName)) {
//									skip = true;
//								}
							}
						}
						if (!skip)
							filtered.add(e);
					}
					return filtered.toArray();
				}
			};
		}
		return contentProvider;
	}",1,8791
"  private int addManualRecord(Airing recAir, UIClient uiClient)
  {
    // Check to make sure we have an encoder that can receive this station
    Set<EncoderState> tryUs = new HashSet<EncoderState>(encoderStateMap.values());
    Iterator<EncoderState> walker = tryUs.iterator();
    // We only need to worry about conflicts with other recordings that occur within the same set of stations. If
    // encoder A has no intersection with the stations on encoder B; then there's no reason to prompt about conflicts from
    // that tuner since it won't help resolve scheduling issues. So this set will be all the stations that either directly or
    // indirectly could resolve a conflict with the new recording.
    // Due to the indirect nature of this; we have to keep checking through the encoders until this set stops growing in size
    Set<Integer> unifiedStationSet = new HashSet<Integer>();
    boolean encoderExists = false;
    while (walker.hasNext())
    {
      EncoderState es = walker.next();
      synchronized (es.stationSet) {
        if (es.stationSet.contains(recAir.stationID))
        {
          encoderExists = true;
          unifiedStationSet.addAll(es.stationSet);
          walker.remove(); // to avoid redundant checking below
          break;
        }
      }
    }
    if (!encoderExists)
      return VideoFrame.WATCH_FAILED_NO_ENCODERS_HAVE_STATION;


    int lastSetSize;
    do
    {
      lastSetSize = unifiedStationSet.size();
      walker = tryUs.iterator();
      while (walker.hasNext())
      {
        EncoderState es = walker.next();
        synchronized (es.stationSet) {
          if (unifiedStationSet.removeAll(es.stationSet))
          {
            // There was an intersection, so use all of these stations, then ignore this one for later
            unifiedStationSet.addAll(es.stationSet);
            walker.remove();
          }
        }
      }


    } while (lastSetSize != unifiedStationSet.size() && !tryUs.isEmpty());


    long defaultStartPadding = Sage.getLong(""default_mr_start_padding"", 0);
    long defaultStopPadding = Sage.getLong(""default_mr_stop_padding"", 0);
    long requestedStart = recAir.getStartTime() - defaultStartPadding;
    long requestedStop = recAir.getEndTime() + defaultStopPadding;
    long requestedDuration = requestedStop - requestedStart;


    Airing schedAir = recAir;
    if (defaultStartPadding != 0 || defaultStopPadding != 0)
    {
      schedAir = new Airing(0);
      schedAir.time = requestedStart;
      schedAir.duration = requestedDuration;
      schedAir.stationID = recAir.stationID;
      schedAir.showID = recAir.showID;
    }
    Vector<Airing> parallelRecords = new Vector<Airing>();
    Vector<Airing> lastParallel = null;
    do
    {
      parallelRecords.clear();
      ManualRecord[] manualMustSee = wiz.getManualRecordsSortedByTime();
      Vector<ManualRecord> parallelRecurs = new Vector<ManualRecord>();
      for (int i = 0; i < manualMustSee.length; i++)
      {
        ManualRecord currRec = manualMustSee[i];
        if (currRec.getContentAiring() == recAir)
          return VideoFrame.WATCH_OK;
        if (currRec.getEndTime() <= Sage.time()) continue;
        if (currRec.doRecurrencesOverlap(requestedStart, requestedDuration, 0))
        {
          parallelRecords.addElement(manualMustSee[i].getSchedulingAiring());
          if (currRec.recur != 0)
            parallelRecurs.add(currRec);
          else
            parallelRecurs.add(null);
        }
      }


      if (parallelRecords.isEmpty()) break;


      parallelRecords.addElement(schedAir);
      parallelRecurs.add(null);
      if (sched.testMultiTunerSchedulingPermutation(parallelRecords))
        break;
      // Remove any recurrence duplicates from the parallel list that is presented to the user
      for (int i = 0; i < parallelRecurs.size(); i++)
      {
        ManualRecord currRecur = parallelRecurs.get(i);
        if (currRecur == null) continue;
        for (int j = 0; j < parallelRecords.size(); j++)
        {
          if (i == j || parallelRecurs.get(j) == null) continue;


          ManualRecord otherRecur = parallelRecurs.get(j);
          if (currRecur.stationID == otherRecur.stationID && currRecur.duration == otherRecur.duration &&
              currRecur.recur == otherRecur.recur && currRecur.isSameRecurrence(otherRecur.startTime))
          {
            parallelRecurs.remove(j);
            parallelRecords.remove(j);
            j--;
          }
        }
      }


      // Conflict exists, we need to kill a recording that's on an encoder that's capable
      // of recording this
      // Conflict resolution, ask about what you're going to kill
      parallelRecords.remove(schedAir);


      // Remove any items from the conflict options that would not end up in station set overlap either directly or indirectly
      for (int i = 0; i < parallelRecords.size(); i++)
        if (!unifiedStationSet.contains(parallelRecords.get(i).stationID))
          parallelRecords.remove(i--);


      // If we have the same conflicts as when we just checked, then bail. Most likely they
      // aren't processing the Hook correctly and we'll be in an infinite loop.
      if (lastParallel != null && parallelRecords.equals(lastParallel))
        return VideoFrame.WATCH_FAILED_USER_REJECTED_CONFLICT;
      Object hookRes = (uiClient == null) ? null : uiClient.processUIClientHook(""RecordRequestScheduleConflict"", new Object[] { recAir, parallelRecords });
      if (!(hookRes instanceof Boolean) || !((Boolean) hookRes))
        return VideoFrame.WATCH_FAILED_USER_REJECTED_CONFLICT;
      lastParallel = new Vector<Airing>(parallelRecords);
    } while (true);


    ManualRecord newMR;
    if (schedAir.getStartTime() < Sage.time())
    {
      int[] errorReturn = new int[1];
      EncoderState es = findBestEncoderForNow(schedAir, true, uiClient, errorReturn);
      if (es == null)
      {
        if (errorReturn[0] == 0)
          errorReturn[0] = VideoFrame.WATCH_FAILED_GENERAL_CANT_FIND_ENCODER;
        return errorReturn[0];
      }
      synchronized (this)
      {
        es = checkForFoundBestEncoderNowRecordSwitch(es, recAir);
        // Set the acquisition state to manual if it has already started recording
        MediaFile mf = wiz.getFileForAiring(recAir);
        if (mf != null)
          mf.setAcquisitionTech(MediaFile.ACQUISITION_MANUAL);
        newMR = wiz.addManualRecord(requestedStart, requestedDuration, 0, recAir.stationID,
            """", """", recAir.id, 0);
        es.forceWatch = newMR.getSchedulingAiring();
        es.forceProcessed = false;
        work();
      }
    }
    else
      newMR = wiz.addManualRecord(requestedStart, requestedDuration, 0, recAir.stationID,
          """", """", recAir.id, 0);
    PluginEventManager.postEvent(PluginEventManager.MANUAL_RECORD_ADDED,
        new Object[] { PluginEventManager.VAR_AIRING, newMR.getSchedulingAiring() });
    return VideoFrame.WATCH_OK;
  }",1,9955
"  private TtmlRegion parseRegionAttributes(
      XmlPullParser xmlParser, CellResolution cellResolution, TtsExtent ttsExtent) {
    String regionId = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_ID);
    if (regionId == null) {
      return null;
    }


    float position;
    float line;


    String regionOrigin = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_TTS_ORIGIN);
    if (regionOrigin != null) {
      Matcher originPercentageMatcher = PERCENTAGE_COORDINATES.matcher(regionOrigin);
      Matcher originPixelMatcher = PIXEL_COORDINATES.matcher(regionOrigin);
      if (originPercentageMatcher.matches()) {
        try {
          position = Float.parseFloat(originPercentageMatcher.group(1)) / 100f;
          line = Float.parseFloat(originPercentageMatcher.group(2)) / 100f;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed origin: "" + regionOrigin);
          return null;
        }
      } else if (originPixelMatcher.matches()) {
        if (ttsExtent == null) {
          Log.w(TAG, ""Ignoring region with missing tts:extent: "" + regionOrigin);
          return null;
        }
        try {
          int width = Integer.parseInt(originPixelMatcher.group(1));
          int height = Integer.parseInt(originPixelMatcher.group(2));
          // Convert pixel values to fractions.
          position = width / (float) ttsExtent.width;
          line = height / (float) ttsExtent.height;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed origin: "" + regionOrigin);
          return null;
        }
      } else {
        Log.w(TAG, ""Ignoring region with unsupported origin: "" + regionOrigin);
        return null;
      }
    } else {
      Log.w(TAG, ""Ignoring region without an origin"");
      return null;
      // TODO: Should default to top left as below in this case, but need to fix
      // https://github.com/google/ExoPlayer/issues/2953 first.
      // Origin is omitted. Default to top left.
      // position = 0;
      // line = 0;
    }


    float width;
    float height;
    String regionExtent = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_TTS_EXTENT);
    if (regionExtent != null) {
      Matcher extentPercentageMatcher = PERCENTAGE_COORDINATES.matcher(regionExtent);
      Matcher extentPixelMatcher = PIXEL_COORDINATES.matcher(regionExtent);
      if (extentPercentageMatcher.matches()) {
        try {
          width = Float.parseFloat(extentPercentageMatcher.group(1)) / 100f;
          height = Float.parseFloat(extentPercentageMatcher.group(2)) / 100f;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed extent: "" + regionOrigin);
          return null;
        }
      } else if (extentPixelMatcher.matches()) {
        if (ttsExtent == null) {
          Log.w(TAG, ""Ignoring region with missing tts:extent: "" + regionOrigin);
          return null;
        }
        try {
          int extentWidth = Integer.parseInt(extentPixelMatcher.group(1));
          int extentHeight = Integer.parseInt(extentPixelMatcher.group(2));
          // Convert pixel values to fractions.
          width = extentWidth / (float) ttsExtent.width;
          height = extentHeight / (float) ttsExtent.height;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed extent: "" + regionOrigin);
          return null;
        }
      } else {
        Log.w(TAG, ""Ignoring region with unsupported extent: "" + regionOrigin);
        return null;
      }
    } else {
      Log.w(TAG, ""Ignoring region without an extent"");
      return null;
      // TODO: Should default to extent of parent as below in this case, but need to fix
      // https://github.com/google/ExoPlayer/issues/2953 first.
      // Extent is omitted. Default to extent of parent.
      // width = 1;
      // height = 1;
    }


    @Cue.AnchorType int lineAnchor = Cue.ANCHOR_TYPE_START;
    String displayAlign = XmlPullParserUtil.getAttributeValue(xmlParser,
        TtmlNode.ATTR_TTS_DISPLAY_ALIGN);
    if (displayAlign != null) {
      switch (Util.toLowerInvariant(displayAlign)) {
        case ""center"":
          lineAnchor = Cue.ANCHOR_TYPE_MIDDLE;
          line += height / 2;
          break;
        case ""after"":
          lineAnchor = Cue.ANCHOR_TYPE_END;
          line += height;
          break;
        default:
          // Default ""before"" case. Do nothing.
          break;
      }
    }


    float regionTextHeight = 1.0f / cellResolution.rows;
    return new TtmlRegion(
        regionId,
        position,
        line,
        /* lineType= */ Cue.LINE_TYPE_FRACTION,
        lineAnchor,
        width,
        /* textSizeType= */ Cue.TEXT_SIZE_TYPE_FRACTIONAL_IGNORE_PADDING,
        /* textSize= */ regionTextHeight);
  }",1,9959
"    @Override
    ValueNode preprocess(int numTables,
								FromList outerFromList,
								SubqueryList outerSubqueryList,
								PredicateList outerPredicateList) 
					throws StandardException
	{
		/* Only preprocess this node once.  We may get called multiple times
		 * due to tree transformations.
		 */
		if (preprocessed)
		{
			return this;
		}
		preprocessed = true;


		boolean		flattenable;
		ValueNode	topNode = this;


        final boolean haveOrderBy; // need to remember for flattening decision


        // Push the order by list down to the ResultSet
        if (orderByList != null) {
            haveOrderBy = true;
            // If we have more than 1 ORDERBY columns, we may be able to
            // remove duplicate columns, e.g., ""ORDER BY 1, 1, 2"".
            if (orderByList.size() > 1)
            {
                orderByList.removeDupColumns();
            }


            resultSet.pushOrderByList(orderByList);
            orderByList = null;
        } else {
            haveOrderBy = false;
        }


        resultSet = resultSet.preprocess(numTables, null, (FromList) null);


        if (leftOperand != null)
        {
            leftOperand = leftOperand.preprocess(numTables,
                    outerFromList, outerSubqueryList, outerPredicateList);
        }


		// Eliminate any unnecessary DISTINCTs
		if (resultSet instanceof SelectNode)
		{
			if (((SelectNode) resultSet).hasDistinct())
			{
				((SelectNode) resultSet).clearDistinct();
				/* We need to remember to check for single unique value
				 * at execution time for expression subqueries.
				 */
				if  (subqueryType == EXPRESSION_SUBQUERY)
				{
					distinctExpression = true;
				}
			}
		}


		/* Lame transformation - For IN/ANY subqueries, if
		 * result set is guaranteed to return at most 1 row
		 * and it is not correlated
		 * then convert the subquery into the matching expression
		 * subquery type.  For example:
		 *	c1 in (select min(c1) from t2)
		 * becomes:
		 *	c1 = (select min(c1) from t2)
		 * (This actually showed up in an app that a potential customer
		 * was porting from SQL Server.)
		 * The transformed query can then be flattened if appropriate.
		 */
		if ((isIN() || isANY()) &&
			resultSet.returnsAtMostOneRow())
		{
			if (! hasCorrelatedCRs())
			{
				changeToCorrespondingExpressionType();
			}
		}


		/* NOTE: Flattening occurs before the pushing of
		 * the predicate, since the pushing will add a node 
		 * above the SubqueryNode.
		 */


		/* Values subquery is flattenable if:
		 *  o It is not under an OR.
         *  o It is not a subquery in a having clause (DERBY-3257)
		 *  o It is an expression subquery on the right side
		 *	  of a BinaryComparisonOperatorNode.
		 *  o Either a) it does not appear within a WHERE clause, or 
		 *           b) it appears within a WHERE clause but does not itself 
		 *              contain a WHERE clause with other subqueries in it. 
		 *          (DERBY-3301)
		 */
		flattenable = (resultSet instanceof RowResultSetNode) &&
					  underTopAndNode && !havingSubquery &&
                      !haveOrderBy &&
                      offset == null &&
                      fetchFirst == null &&
					  !isWhereExistsAnyInWithWhereSubquery() &&
                      parentComparisonOperator != null;


		if (flattenable)
		{
			/* If we got this far and we are an expression subquery
			 * then we want to set leftOperand to be the left side
			 * of the comparison in case we pull the comparison into
			 * the flattened subquery.
			 */
			leftOperand = parentComparisonOperator.getLeftOperand();
			// Flatten the subquery
			RowResultSetNode rrsn = (RowResultSetNode) resultSet;
            FromList fl = new FromList(getContextManager());


			// Remove ourselves from the outer subquery list
			outerSubqueryList.removeElement(this);


			/* We only need to add the table from the subquery into 
			 * the outer from list if the subquery itself contains
			 * another subquery.  Otherwise, it just becomes a constant.
			 */
			if (rrsn.subquerys.size() != 0)
			{
				fl.addElement(rrsn);
				outerFromList.destructiveAppend(fl);
			}


			/* Append the subquery's subquery list to the 
			 * outer subquery list.
			 */
			outerSubqueryList.destructiveAppend(rrsn.subquerys);


			/* return the new join condition 
			 * If we are flattening an EXISTS then there is no new join
			 * condition since there is no leftOperand.  Simply return
			 * TRUE.
			 *
			 * NOTE: The outer where clause, etc. has already been normalized,
			 * so we simply return the BinaryComparisonOperatorNode above
			 * the new join condition.
			 */
			return getNewJoinCondition(leftOperand, getRightOperand());
		}


		/* Select subquery is flattenable if:
		 *  o It is not under an OR.
		 *  o The subquery type is IN, ANY or EXISTS or
		 *    an expression subquery on the right side
		 *	  of a BinaryComparisonOperatorNode.
		 *  o There are no aggregates in the select list
		 *  o There is no group by clause or having clause.
		 *  o There is a uniqueness condition that ensures
		 *	  that the flattening of the subquery will not
		 *	  introduce duplicates into the result set.
         *  o The subquery is not part of a having clause (DERBY-3257)
		 *  o There are no windows defined on it
		 *
		 *	OR,
		 *  o The subquery is NOT EXISTS, NOT IN, ALL (beetle 5173).
		 *  o Either a) it does not appear within a WHERE clause, or 
		 *           b) it appears within a WHERE clause but does not itself 
		 *              contain a WHERE clause with other subqueries in it. 
		 *          (DERBY-3301)
		 */
		boolean flattenableNotExists = (isNOT_EXISTS() || canAllBeFlattened());


		flattenable = (resultSet instanceof SelectNode) &&
 			          !((SelectNode)resultSet).hasWindows() &&
                      !haveOrderBy &&
                      offset == null &&
                      fetchFirst == null &&
					  underTopAndNode && !havingSubquery &&
					  !isWhereExistsAnyInWithWhereSubquery() &&
					  (isIN() || isANY() || isEXISTS() || flattenableNotExists ||
                       parentComparisonOperator != null);


		if (flattenable)
		{
			SelectNode	select = (SelectNode) resultSet;
			if ((!select.hasAggregatesInSelectList()) &&
			    (select.havingClause == null))
			{
				ValueNode origLeftOperand = leftOperand;


				/* Check for uniqueness condition. */
				/* Is the column being returned by the subquery
				 * a candidate for an = condition?
				 */
				boolean additionalEQ =
							(subqueryType == IN_SUBQUERY) ||
							(subqueryType == EQ_ANY_SUBQUERY);




				additionalEQ = additionalEQ &&
								((leftOperand instanceof ConstantNode) ||
								 (leftOperand instanceof ColumnReference) ||
								 (leftOperand.requiresTypeFromContext()));
				/* If we got this far and we are an expression subquery
				 * then we want to set leftOperand to be the left side
				 * of the comparison in case we pull the comparison into
				 * the flattened subquery.
				 */
                if (parentComparisonOperator != null)
				{
					leftOperand = parentComparisonOperator.getLeftOperand();
				}
				/* Never flatten to normal join for NOT EXISTS.
				 */


				if ((! flattenableNotExists) && select.uniqueSubquery(additionalEQ))
				{
					// Flatten the subquery
					return flattenToNormalJoin(numTables,
										   outerFromList, outerSubqueryList,
										   outerPredicateList);
				}
				/* We can flatten into an EXISTS join if all of the above
				 * conditions except for a uniqueness condition are true
				 * and:
				 *	o Subquery only has a single entry in its from list
				 *	  and that entry is a FromBaseTable
				 *	o All predicates in the subquery's where clause are
				 *	  pushable.
				 *  o The leftOperand, if non-null, is pushable.
				 * If the subquery meets these conditions then we will flatten
				 * the FBT into an EXISTS FBT, pushd the subquery's
				 * predicates down to the PRN above the EBT and
				 * mark the predicates to say that they cannot be pulled 
				 * above the PRN. (The only way that we can guarantee correctness
				 * is if the predicates do not get pulled up.  If they get pulled
				 * up then the single next logic for an EXISTS join does not work
				 * because that row may get disqualified at a higher level.)
                 * DERBY-4001: Extra conditions to allow flattening to a NOT
                 * EXISTS join (in a NOT EXISTS join it does matter on which
                 * side of the join predicates/restrictions are applied):
                 *  o All the predicates must reference the FBT, otherwise
                 *    predicates meant for the right side of the join may be
                 *    applied to the left side of the join.
                 *  o The right operand (in ALL and NOT IN) must reference the
                 *    FBT, otherwise the generated join condition may be used
                 *    to restrict the left side of the join.
				 */
				else if ( (isIN() || isANY() || isEXISTS() || flattenableNotExists) &&
						  ((leftOperand == null) ? true :
							 leftOperand.categorize(new JBitSet(numTables), false)) &&
						  select.getWherePredicates().allPushable())
				{
                    FromBaseTable fbt =
                            singleFromBaseTable(select.getFromList());


                    if (fbt != null && (!flattenableNotExists ||
                         (select.getWherePredicates().allReference(fbt) &&
                          rightOperandFlattenableToNotExists(numTables, fbt))))
                    {
                        return flattenToExistsJoin(numTables,
                                outerFromList, outerSubqueryList,
                                outerPredicateList, flattenableNotExists);
                    }
				}


				// restore leftOperand to its original value
				leftOperand = origLeftOperand;
			}
		}


        resultSet.pushQueryExpressionSuffix();


        resultSet.pushOffsetFetchFirst( offset, fetchFirst, hasJDBClimitClause );


		/* We transform the leftOperand and the select list for quantified 
		 * predicates that have a leftOperand into a new predicate and push it
		 * down to the subquery after we preprocess the subquery's resultSet.
		 * We must do this after preprocessing the underlying subquery so that
		 * we know where to attach the new predicate.
		 * NOTE - If we pushed the predicate before preprocessing the underlying
		 * subquery, then the point of attachment would depend on the form of
		 * that subquery.  (Where clause?  Having clause?)
		 */
		if (leftOperand != null)
		{
			topNode = pushNewPredicate(numTables);
			pushedNewPredicate = true;
		}
        /* EXISTS and NOT EXISTS subqueries that haven't been flattened, need
         * an IS [NOT] NULL node on top so that they return a BOOLEAN. Other
         * cases are taken care of in pushNewPredicate.
		 */
        else if (isEXISTS() || isNOT_EXISTS())
		{
            topNode = genIsNullTree(isEXISTS());
			subqueryType = EXISTS_SUBQUERY;
		}


		/*
		** Do inVariant and correlated checks now.  We
		** aren't going to use the results here, but they
		** have been stashed away by isInvariant() and hasCorrelatedCRs()
		*/
		isInvariant();
		hasCorrelatedCRs();


		/* If parentComparisonOperator is non-null then we are an
		 * expression subquery that was considered to be a candidate 
		 * for flattening, but we didn't get flattened.  In that case
		 * we are the rightOperand of the parent.  We need to update
		 * the parent's rightOperand with the new topNode and return
		 * the parent because the parent is letting us decide whether
		 * or not to replace the entire comparison, which we can do
		 * if we flatten.  Otherwise we simply return the new top node.
		 */
		if (parentComparisonOperator != null)
		{
			parentComparisonOperator.setRightOperand(topNode);
			return parentComparisonOperator;
		}


		return topNode;
	}",1,10095
"    @Override
    public int setPath(Path2D path) {
        Rectangle2D bounds = path.getBounds2D();
        PathIterator it = path.getPathIterator(null);


        List<byte[]> segInfo = new ArrayList<>();
        List<Point2D.Double> pntInfo = new ArrayList<>();
        boolean isClosed = false;
        int numPoints = 0;
        while (!it.isDone()) {
            double[] vals = new double[6];
            int type = it.currentSegment(vals);
            switch (type) {
                case PathIterator.SEG_MOVETO:
                    pntInfo.add(new Point2D.Double(vals[0], vals[1]));
                    segInfo.add(SEGMENTINFO_MOVETO);
                    numPoints++;
                    break;
                case PathIterator.SEG_LINETO:
                    pntInfo.add(new Point2D.Double(vals[0], vals[1]));
                    segInfo.add(SEGMENTINFO_LINETO);
                    segInfo.add(SEGMENTINFO_ESCAPE);
                    numPoints++;
                    break;
                case PathIterator.SEG_CUBICTO:
                    pntInfo.add(new Point2D.Double(vals[0], vals[1]));
                    pntInfo.add(new Point2D.Double(vals[2], vals[3]));
                    pntInfo.add(new Point2D.Double(vals[4], vals[5]));
                    segInfo.add(SEGMENTINFO_CUBICTO);
                    segInfo.add(SEGMENTINFO_ESCAPE2);
                    numPoints++;
                    break;
                case PathIterator.SEG_QUADTO:
                    //TODO: figure out how to convert SEG_QUADTO into SEG_CUBICTO
                    LOG.log(POILogger.WARN, ""SEG_QUADTO is not supported"");
                    break;
                case PathIterator.SEG_CLOSE:
                    pntInfo.add(pntInfo.get(0));
                    segInfo.add(SEGMENTINFO_LINETO);
                    segInfo.add(SEGMENTINFO_ESCAPE);
                    segInfo.add(SEGMENTINFO_LINETO);
                    segInfo.add(SEGMENTINFO_CLOSE);
                    isClosed = true;
                    numPoints++;
                    break;
                default:
                    LOG.log(POILogger.WARN, ""Ignoring invalid segment type ""+type);
                    break;
            }


            it.next();
        }
        if(!isClosed) {
            segInfo.add(SEGMENTINFO_LINETO);
        }
        segInfo.add(SEGMENTINFO_END);


        AbstractEscherOptRecord opt = getEscherOptRecord();
        opt.addEscherProperty(new EscherSimpleProperty(EscherProperties.GEOMETRY__SHAPEPATH, 0x4));


        EscherArrayProperty verticesProp = new EscherArrayProperty((short)(EscherProperties.GEOMETRY__VERTICES + 0x4000), false, null);
        verticesProp.setNumberOfElementsInArray(pntInfo.size());
        verticesProp.setNumberOfElementsInMemory(pntInfo.size());
        verticesProp.setSizeOfElements(8);
        for (int i = 0; i < pntInfo.size(); i++) {
            Point2D.Double pnt = pntInfo.get(i);
            byte[] data = new byte[8];
            LittleEndian.putInt(data, 0, Units.pointsToMaster(pnt.getX() - bounds.getX()));
            LittleEndian.putInt(data, 4, Units.pointsToMaster(pnt.getY() - bounds.getY()));
            verticesProp.setElement(i, data);
        }
        opt.addEscherProperty(verticesProp);


        EscherArrayProperty segmentsProp = new EscherArrayProperty((short)(EscherProperties.GEOMETRY__SEGMENTINFO + 0x4000), false, null);
        segmentsProp.setNumberOfElementsInArray(segInfo.size());
        segmentsProp.setNumberOfElementsInMemory(segInfo.size());
        segmentsProp.setSizeOfElements(0x2);
        for (int i = 0; i < segInfo.size(); i++) {
            byte[] seg = segInfo.get(i);
            segmentsProp.setElement(i, seg);
        }
        opt.addEscherProperty(segmentsProp);


        opt.addEscherProperty(new EscherSimpleProperty(EscherProperties.GEOMETRY__RIGHT, Units.pointsToMaster(bounds.getWidth())));
        opt.addEscherProperty(new EscherSimpleProperty(EscherProperties.GEOMETRY__BOTTOM, Units.pointsToMaster(bounds.getHeight())));


        opt.sortProperties();


        setAnchor(bounds);


        return numPoints;
    }",1,10137
"    public final void mRULE_STRING() throws RecognitionException {
        try {
            int _type = RULE_STRING;
            int _channel = DEFAULT_TOKEN_CHANNEL;
            // InternalXImportSectionTestLang.g:6435:13: ( ( '\""' ( '\\\\' . | ~ ( ( '\\\\' | '\""' ) ) )* ( '\""' )? | '\\'' ( '\\\\' . | ~ ( ( '\\\\' | '\\'' ) ) )* ( '\\'' )? ) )
            // InternalXImportSectionTestLang.g:6435:15: ( '\""' ( '\\\\' . | ~ ( ( '\\\\' | '\""' ) ) )* ( '\""' )? | '\\'' ( '\\\\' . | ~ ( ( '\\\\' | '\\'' ) ) )* ( '\\'' )? )
            {
            // InternalXImportSectionTestLang.g:6435:15: ( '\""' ( '\\\\' . | ~ ( ( '\\\\' | '\""' ) ) )* ( '\""' )? | '\\'' ( '\\\\' . | ~ ( ( '\\\\' | '\\'' ) ) )* ( '\\'' )? )
            int alt15=2;
            int LA15_0 = input.LA(1);


            if ( (LA15_0=='\""') ) {
                alt15=1;
            }
            else if ( (LA15_0=='\'') ) {
                alt15=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("""", 15, 0, input);


                throw nvae;
            }
            switch (alt15) {
                case 1 :
                    // InternalXImportSectionTestLang.g:6435:16: '\""' ( '\\\\' . | ~ ( ( '\\\\' | '\""' ) ) )* ( '\""' )?
                    {
                    match('\""'); 
                    // InternalXImportSectionTestLang.g:6435:20: ( '\\\\' . | ~ ( ( '\\\\' | '\""' ) ) )*
                    loop11:
                    do {
                        int alt11=3;
                        int LA11_0 = input.LA(1);


                        if ( (LA11_0=='\\') ) {
                            alt11=1;
                        }
                        else if ( ((LA11_0>='\u0000' && LA11_0<='!')||(LA11_0>='#' && LA11_0<='[')||(LA11_0>=']' && LA11_0<='\uFFFF')) ) {
                            alt11=2;
                        }




                        switch (alt11) {
                    	case 1 :
                    	    // InternalXImportSectionTestLang.g:6435:21: '\\\\' .
                    	    {
                    	    match('\\'); 
                    	    matchAny(); 


                    	    }
                    	    break;
                    	case 2 :
                    	    // InternalXImportSectionTestLang.g:6435:28: ~ ( ( '\\\\' | '\""' ) )
                    	    {
                    	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='!')||(input.LA(1)>='#' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\uFFFF') ) {
                    	        input.consume();


                    	    }
                    	    else {
                    	        MismatchedSetException mse = new MismatchedSetException(null,input);
                    	        recover(mse);
                    	        throw mse;}




                    	    }
                    	    break;


                    	default :
                    	    break loop11;
                        }
                    } while (true);


                    // InternalXImportSectionTestLang.g:6435:44: ( '\""' )?
                    int alt12=2;
                    int LA12_0 = input.LA(1);


                    if ( (LA12_0=='\""') ) {
                        alt12=1;
                    }
                    switch (alt12) {
                        case 1 :
                            // InternalXImportSectionTestLang.g:6435:44: '\""'
                            {
                            match('\""'); 


                            }
                            break;


                    }




                    }
                    break;
                case 2 :
                    // InternalXImportSectionTestLang.g:6435:49: '\\'' ( '\\\\' . | ~ ( ( '\\\\' | '\\'' ) ) )* ( '\\'' )?
                    {
                    match('\''); 
                    // InternalXImportSectionTestLang.g:6435:54: ( '\\\\' . | ~ ( ( '\\\\' | '\\'' ) ) )*
                    loop13:
                    do {
                        int alt13=3;
                        int LA13_0 = input.LA(1);


                        if ( (LA13_0=='\\') ) {
                            alt13=1;
                        }
                        else if ( ((LA13_0>='\u0000' && LA13_0<='&')||(LA13_0>='(' && LA13_0<='[')||(LA13_0>=']' && LA13_0<='\uFFFF')) ) {
                            alt13=2;
                        }




                        switch (alt13) {
                    	case 1 :
                    	    // InternalXImportSectionTestLang.g:6435:55: '\\\\' .
                    	    {
                    	    match('\\'); 
                    	    matchAny(); 


                    	    }
                    	    break;
                    	case 2 :
                    	    // InternalXImportSectionTestLang.g:6435:62: ~ ( ( '\\\\' | '\\'' ) )
                    	    {
                    	    if ( (input.LA(1)>='\u0000' && input.LA(1)<='&')||(input.LA(1)>='(' && input.LA(1)<='[')||(input.LA(1)>=']' && input.LA(1)<='\uFFFF') ) {
                    	        input.consume();


                    	    }
                    	    else {
                    	        MismatchedSetException mse = new MismatchedSetException(null,input);
                    	        recover(mse);
                    	        throw mse;}




                    	    }
                    	    break;


                    	default :
                    	    break loop13;
                        }
                    } while (true);


                    // InternalXImportSectionTestLang.g:6435:79: ( '\\'' )?
                    int alt14=2;
                    int LA14_0 = input.LA(1);


                    if ( (LA14_0=='\'') ) {
                        alt14=1;
                    }
                    switch (alt14) {
                        case 1 :
                            // InternalXImportSectionTestLang.g:6435:79: '\\''
                            {
                            match('\''); 


                            }
                            break;


                    }




                    }
                    break;


            }




            }


            state.type = _type;
            state.channel = _channel;
        }
        finally {
        }
    }",1,10197
"	private void findObjectsToPack(@NonNull ProgressMonitor countingMonitor,
			@NonNull ObjectWalk walker, @NonNull Set<? extends ObjectId> want,
			@NonNull Set<? extends ObjectId> have,
			@NonNull Set<? extends ObjectId> noBitmaps) throws IOException {
		final long countingStart = System.currentTimeMillis();
		beginPhase(PackingPhase.COUNTING, countingMonitor, ProgressMonitor.UNKNOWN);


		stats.interestingObjects = Collections.unmodifiableSet(new HashSet<ObjectId>(want));
		stats.uninterestingObjects = Collections.unmodifiableSet(new HashSet<ObjectId>(have));
		excludeFromBitmapSelection = noBitmaps;


		canBuildBitmaps = config.isBuildBitmaps()
				&& !shallowPack
				&& have.isEmpty()
				&& (excludeInPacks == null || excludeInPacks.length == 0);
		if (!shallowPack && useBitmaps) {
			BitmapIndex bitmapIndex = reader.getBitmapIndex();
			if (bitmapIndex != null) {
				BitmapWalker bitmapWalker = new BitmapWalker(
						walker, bitmapIndex, countingMonitor);
				findObjectsToPackUsingBitmaps(bitmapWalker, want, have);
				endPhase(countingMonitor);
				stats.timeCounting = System.currentTimeMillis() - countingStart;
				stats.bitmapIndexMisses = bitmapWalker.getCountOfBitmapIndexMisses();
				return;
			}
		}


		List<ObjectId> all = new ArrayList<>(want.size() + have.size());
		all.addAll(want);
		all.addAll(have);


		final RevFlag include = walker.newFlag(""include""); //$NON-NLS-1$
		final RevFlag added = walker.newFlag(""added""); //$NON-NLS-1$


		walker.carry(include);


		int haveEst = have.size();
		if (have.isEmpty()) {
			walker.sort(RevSort.COMMIT_TIME_DESC);
		} else {
			walker.sort(RevSort.TOPO);
			if (thin)
				walker.sort(RevSort.BOUNDARY, true);
		}


		List<RevObject> wantObjs = new ArrayList<>(want.size());
		List<RevObject> haveObjs = new ArrayList<>(haveEst);
		List<RevTag> wantTags = new ArrayList<>(want.size());


		// Retrieve the RevWalk's versions of ""want"" and ""have"" objects to
		// maintain any state previously set in the RevWalk.
		AsyncRevObjectQueue q = walker.parseAny(all, true);
		try {
			for (;;) {
				try {
					RevObject o = q.next();
					if (o == null)
						break;
					if (have.contains(o))
						haveObjs.add(o);
					if (want.contains(o)) {
						o.add(include);
						wantObjs.add(o);
						if (o instanceof RevTag)
							wantTags.add((RevTag) o);
					}
				} catch (MissingObjectException e) {
					if (ignoreMissingUninteresting
							&& have.contains(e.getObjectId()))
						continue;
					throw e;
				}
			}
		} finally {
			q.release();
		}


		if (!wantTags.isEmpty()) {
			all = new ArrayList<>(wantTags.size());
			for (RevTag tag : wantTags)
				all.add(tag.getObject());
			q = walker.parseAny(all, true);
			try {
				while (q.next() != null) {
					// Just need to pop the queue item to parse the object.
				}
			} finally {
				q.release();
			}
		}


		if (walker instanceof DepthWalk.ObjectWalk) {
			DepthWalk.ObjectWalk depthWalk = (DepthWalk.ObjectWalk) walker;
			for (RevObject obj : wantObjs) {
				depthWalk.markRoot(obj);
			}
			// Mark the tree objects associated with ""have"" commits as
			// uninteresting to avoid writing redundant blobs. A normal RevWalk
			// lazily propagates the ""uninteresting"" state from a commit to its
			// tree during the walk, but DepthWalks can terminate early so
			// preemptively propagate that state here.
			for (RevObject obj : haveObjs) {
				if (obj instanceof RevCommit) {
					RevTree t = ((RevCommit) obj).getTree();
					depthWalk.markUninteresting(t);
				}
			}


			if (unshallowObjects != null) {
				for (ObjectId id : unshallowObjects) {
					depthWalk.markUnshallow(walker.parseAny(id));
				}
			}
		} else {
			for (RevObject obj : wantObjs)
				walker.markStart(obj);
		}
		for (RevObject obj : haveObjs)
			walker.markUninteresting(obj);


		final int maxBases = config.getDeltaSearchWindowSize();
		Set<RevTree> baseTrees = new HashSet<>();
		BlockList<RevCommit> commits = new BlockList<>();
		Set<ObjectId> roots = new HashSet<>();
		RevCommit c;
		while ((c = walker.next()) != null) {
			if (exclude(c))
				continue;
			if (c.has(RevFlag.UNINTERESTING)) {
				if (baseTrees.size() <= maxBases)
					baseTrees.add(c.getTree());
				continue;
			}


			commits.add(c);
			if (c.getParentCount() == 0) {
				roots.add(c.copy());
			}
			countingMonitor.update(1);
		}
		stats.rootCommits = Collections.unmodifiableSet(roots);


		if (shallowPack) {
			for (RevCommit cmit : commits) {
				addObject(cmit, 0);
			}
		} else {
			int commitCnt = 0;
			boolean putTagTargets = false;
			for (RevCommit cmit : commits) {
				if (!cmit.has(added)) {
					cmit.add(added);
					addObject(cmit, 0);
					commitCnt++;
				}


				for (int i = 0; i < cmit.getParentCount(); i++) {
					RevCommit p = cmit.getParent(i);
					if (!p.has(added) && !p.has(RevFlag.UNINTERESTING)
							&& !exclude(p)) {
						p.add(added);
						addObject(p, 0);
						commitCnt++;
					}
				}


				if (!putTagTargets && 4096 < commitCnt) {
					for (ObjectId id : tagTargets) {
						RevObject obj = walker.lookupOrNull(id);
						if (obj instanceof RevCommit
								&& obj.has(include)
								&& !obj.has(RevFlag.UNINTERESTING)
								&& !obj.has(added)) {
							obj.add(added);
							addObject(obj, 0);
						}
					}
					putTagTargets = true;
				}
			}
		}
		commits = null;


		if (thin && !baseTrees.isEmpty()) {
			BaseSearch bases = new BaseSearch(countingMonitor, baseTrees, //
					objectsMap, edgeObjects, reader);
			RevObject o;
			while ((o = walker.nextObject()) != null) {
				if (o.has(RevFlag.UNINTERESTING))
					continue;
				if (exclude(o))
					continue;


				int pathHash = walker.getPathHashCode();
				byte[] pathBuf = walker.getPathBuffer();
				int pathLen = walker.getPathLength();
				bases.addBase(o.getType(), pathBuf, pathLen, pathHash);
				filterAndAddObject(o, o.getType(), pathHash, want);
				countingMonitor.update(1);
			}
		} else {
			RevObject o;
			while ((o = walker.nextObject()) != null) {
				if (o.has(RevFlag.UNINTERESTING))
					continue;
				if (exclude(o))
					continue;
				filterAndAddObject(o, o.getType(), walker.getPathHashCode(), want);
				countingMonitor.update(1);
			}
		}


		for (CachedPack pack : cachedPacks)
			countingMonitor.update((int) pack.getObjectCount());
		endPhase(countingMonitor);
		stats.timeCounting = System.currentTimeMillis() - countingStart;
		stats.bitmapIndexMisses = -1;
	}",1,10203
"	private void createMenuEntries(Menu menu, DisplayItem parent,
			boolean trackDynamics) {
		if (menu == null)
			return;
		MenuItem[] menuItems = menu.getItems();


		Map findDynamics = new HashMap();
		DynamicContributionItem dynamicEntry = null;


		if (trackDynamics && menu.getParentItem() != null) {
			//Search for any dynamic menu entries which will be handled later
			Object data = menu.getParentItem().getData();
			if (data instanceof IContributionManager) {
				IContributionManager manager = (IContributionManager) data;
				IContributionItem[] items = manager.getItems();
				for (int i = 0; i < items.length; i++) {
					if (items[i].isDynamic()) {
						findDynamics.put(i > 0 ? items[i - 1] : null, items[i]);
					}
				}


				//If there is an item with no preceeding item, set it up to be
				//added first.
				if (findDynamics.containsKey(null)) {
					IContributionItem item = (IContributionItem) findDynamics
							.get(null);
					dynamicEntry = new DynamicContributionItem(item);
					parent.addChild(dynamicEntry);
				}
			}
		}


		for (int i = 0; i < menuItems.length; i++) {
			if (!menuItems[i].getText().equals("""")) { //$NON-NLS-1$
				IContributionItem contributionItem =
						(IContributionItem) menuItems[i].getData();
				if (dynamicEntry != null
						&& contributionItem.equals(dynamicEntry
								.getIContributionItem())) {
					//If the last item added is the item meant to go before the
					//given dynamic entry, add the dynamic entry so it is in the
					//correct order.
					dynamicEntry.addCurrentItem(menuItems[i]);
				} else {
					DisplayItem menuEntry = new DisplayItem(
							menuItems[i].getText(), contributionItem);


					Image image = menuItems[i].getImage();
					if (image != null) {
						menuEntry.setImageDescriptor(ImageDescriptor
								.createFromImage(image));
					}
					menuEntry.setActionSet((ActionSet) idToActionSet
							.get(getActionSetID(contributionItem)));
					parent.addChild(menuEntry);


					if (ActionFactory.NEW.getId()
							.equals(((IContributionItem) menuItems[i].getData())
									.getId())) {
						initializeNewWizardsMenu(menuEntry);
						wizards = menuEntry;
					} else if (SHORTCUT_CONTRIBUTION_ITEM_ID_OPEN_PERSPECTIVE
							.equals(((IContributionItem) menuItems[i].getData())
									.getId())) {
						initializePerspectivesMenu(menuEntry);
						perspectives = menuEntry;
					} else if (SHORTCUT_CONTRIBUTION_ITEM_ID_SHOW_VIEW
							.equals(((IContributionItem) menuItems[i].getData())
									.getId())) {
						initializeViewsMenu(menuEntry);
						views = menuEntry;
					} else {
						createMenuEntries(menuItems[i].getMenu(), menuEntry,
								trackDynamics);
					}


					if (menuEntry.getChildren().isEmpty()) {
						menuEntry
								.setCheckState(getMenuItemIsVisible(menuEntry));
					}


					if (image == null) {
						if (parent != null && parent.getParent() == null) {
							menuEntry.setImageDescriptor(menuImageDescriptor);
						} else if (menuEntry.getChildren().size() > 0) {
							menuEntry
									.setImageDescriptor(submenuImageDescriptor);
						}
					}
				}
				if (trackDynamics
						&& findDynamics.containsKey(menuItems[i].getData())) {
					IContributionItem item = (IContributionItem) findDynamics
							.get(menuItems[i].getData());
					dynamicEntry = new DynamicContributionItem(item);
					dynamicEntry
							.setCheckState(getMenuItemIsVisible(dynamicEntry));
					parent.addChild(dynamicEntry);
				}
			}
		}
	}",1,10212
"    private JPEGImageMetadataFormat() {
        super(JPEG.nativeImageMetadataFormatName,
              CHILD_POLICY_ALL);


        addElement(""JPEGvariety"",
                   JPEG.nativeImageMetadataFormatName,
                   CHILD_POLICY_CHOICE);


        addElement(""markerSequence"",
                   JPEG.nativeImageMetadataFormatName,
                   CHILD_POLICY_SEQUENCE);


        addElement(""app0JFIF"", ""JPEGvariety"", CHILD_POLICY_SOME);


        addStreamElements(""markerSequence"");


        addElement(""app14Adobe"", ""markerSequence"", CHILD_POLICY_EMPTY);


        addElement(""sof"", ""markerSequence"", 1, 4);


        addElement(""sos"", ""markerSequence"", 1, 4);


        addElement(""JFXX"", ""app0JFIF"", 1, Integer.MAX_VALUE);


        addElement(""app0JFXX"", ""JFXX"", CHILD_POLICY_CHOICE);


        addElement(""app2ICC"", ""app0JFIF"", CHILD_POLICY_EMPTY);


        addAttribute(""app0JFIF"",
                     ""majorVersion"",
                     DATATYPE_INTEGER,
                     false,
                     ""1"",
                     ""0"", ""255"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""minorVersion"",
                     DATATYPE_INTEGER,
                     false,
                     ""2"",
                     ""0"", ""255"",
                     true, true);
        List<String> resUnits = new ArrayList<>();
        resUnits.add(""0"");
        resUnits.add(""1"");
        resUnits.add(""2"");
        addAttribute(""app0JFIF"",
                     ""resUnits"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     resUnits);
        addAttribute(""app0JFIF"",
                     ""Xdensity"",
                     DATATYPE_INTEGER,
                     false,
                     ""1"",
                     ""1"", ""65535"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""Ydensity"",
                     DATATYPE_INTEGER,
                     false,
                     ""1"",
                     ""1"", ""65535"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""thumbWidth"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""255"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""thumbHeight"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""255"",
                     true, true);


        addElement(""JFIFthumbJPEG"", ""app0JFXX"", CHILD_POLICY_SOME);
        addElement(""JFIFthumbPalette"", ""app0JFXX"", CHILD_POLICY_EMPTY);
        addElement(""JFIFthumbRGB"", ""app0JFXX"", CHILD_POLICY_EMPTY);


        List<String> codes = new ArrayList<>();
        codes.add(""16""); // Hex 10
        codes.add(""17""); // Hex 11
        codes.add(""19""); // Hex 13
        addAttribute(""app0JFXX"",
                     ""extensionCode"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     codes);


        addChildElement(""markerSequence"", ""JFIFthumbJPEG"");


        addAttribute(""JFIFthumbPalette"",
                     ""thumbWidth"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""JFIFthumbPalette"",
                     ""thumbHeight"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);


        addAttribute(""JFIFthumbRGB"",
                     ""thumbWidth"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""JFIFthumbRGB"",
                     ""thumbHeight"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);


        addObjectValue(""app2ICC"", ICC_Profile.class, false, null);


        addAttribute(""app14Adobe"",
                     ""version"",
                     DATATYPE_INTEGER,
                     false,
                     ""100"",
                     ""100"", ""255"",
                     true, true);
        addAttribute(""app14Adobe"",
                     ""flags0"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""65535"",
                     true, true);
        addAttribute(""app14Adobe"",
                     ""flags1"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""65535"",
                     true, true);


        List<String> transforms = new ArrayList<>();
        transforms.add(""0"");
        transforms.add(""1"");
        transforms.add(""2"");
        addAttribute(""app14Adobe"",
                     ""transform"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     transforms);


        addElement(""componentSpec"", ""sof"", CHILD_POLICY_EMPTY);


        List<String> procs = new ArrayList<>();
        procs.add(""0"");
        procs.add(""1"");
        procs.add(""2"");
        addAttribute(""sof"",
                     ""process"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     procs);
        addAttribute(""sof"",
                     ""samplePrecision"",
                     DATATYPE_INTEGER,
                     false,
                     ""8"");
        addAttribute(""sof"",
                     ""numLines"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""65535"",
                     true, true);
        addAttribute(""sof"",
                     ""samplesPerLine"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""65535"",
                     true, true);
        List<String> comps = new ArrayList<>();
        comps.add(""1"");
        comps.add(""2"");
        comps.add(""3"");
        comps.add(""4"");
        addAttribute(""sof"",
                     ""numFrameComponents"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     comps);


        addAttribute(""componentSpec"",
                     ""componentId"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""componentSpec"",
                     ""HsamplingFactor"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""1"", ""255"",
                     true, true);
        addAttribute(""componentSpec"",
                     ""VsamplingFactor"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""1"", ""255"",
                     true, true);
        List<String> tabids = new ArrayList<>();
        tabids.add(""0"");
        tabids.add(""1"");
        tabids.add(""2"");
        tabids.add(""3"");
        addAttribute(""componentSpec"",
                     ""QtableSelector"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     tabids);


        addElement(""scanComponentSpec"", ""sos"", CHILD_POLICY_EMPTY);


        addAttribute(""sos"",
                     ""numScanComponents"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     comps);
        addAttribute(""sos"",
                     ""startSpectralSelection"",
                      DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""63"",
                     true, true);
        addAttribute(""sos"",
                     ""endSpectralSelection"",
                      DATATYPE_INTEGER,
                     false,
                     ""63"",
                     ""0"", ""63"",
                     true, true);
        addAttribute(""sos"",
                     ""approxHigh"",
                      DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""15"",
                     true, true);
        addAttribute(""sos"",
                     ""approxLow"",
                      DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""15"",
                     true, true);


        addAttribute(""scanComponentSpec"",
                     ""componentSelector"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""scanComponentSpec"",
                     ""dcHuffTable"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     tabids);
        addAttribute(""scanComponentSpec"",
                     ""acHuffTable"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     tabids);
    }",1,10219
"    public Object doExecute() throws Exception {


        Group group = groupManager.findGroupByName(groupName);
        if (group == null) {
            System.err.println(""Cluster group "" + groupName + "" doesn't exist"");
            return null;
        }


        CellarSupport support = new CellarSupport();
        support.setClusterManager(clusterManager);
        support.setGroupManager(groupManager);
        support.setConfigurationAdmin(configurationAdmin);


        if (!in && !out) {
            in = true;
            out = true;
        }
        if (!whitelist && !blacklist) {
            whitelist = true;
            blacklist = true;
        }


        if (pid == null || pid.isEmpty()) {
            // display mode
            if (in) {
                System.out.println(""INBOUND:"");
                if (whitelist) {
                    System.out.print(""\twhitelist: "");
                    Set<String> list = support.getListEntries(Configurations.WHITELIST, groupName, Constants.CATEGORY, EventType.INBOUND);
                    System.out.println(list.toString());
                }
                if (blacklist) {
                    System.out.print(""\tblacklist: "");
                    Set<String> list = support.getListEntries(Configurations.BLACKLIST, groupName, Constants.CATEGORY, EventType.INBOUND);
                    System.out.println(list.toString());
                }
            }
            if (out) {
                System.out.println(""OUTBOUND:"");
                if (whitelist) {
                    System.out.print(""\twhitelist: "");
                    Set<String> list = support.getListEntries(Configurations.WHITELIST, groupName, Constants.CATEGORY, EventType.OUTBOUND);
                    System.out.println(list.toString());
                }
                if (blacklist) {
                    System.out.print(""\tblacklist: "");
                    Set<String> list = support.getListEntries(Configurations.BLACKLIST, groupName, Constants.CATEGORY, EventType.OUTBOUND);
                    System.out.println(list.toString());
                }
            }
        } else {
            // edit mode
            System.out.println(""Updating blocking policy for "" + pid);
            if (in) {
                if (whitelist) {
                    System.out.println(""\tinbound whitelist ..."");
                    support.switchListEntry(Configurations.WHITELIST, groupName, Constants.CATEGORY, EventType.INBOUND, pid);
                }
                if (blacklist) {
                    System.out.println(""\tinbound blacklist ..."");
                    support.switchListEntry(Configurations.BLACKLIST, groupName, Constants.CATEGORY, EventType.INBOUND, pid);
                }
            }
            if (out) {
                if (whitelist) {
                    System.out.println(""\toutbound whitelist ..."");
                    support.switchListEntry(Configurations.WHITELIST, groupName, Constants.CATEGORY, EventType.OUTBOUND, pid);
                }
                if (blacklist) {
                    System.out.println(""\toutbound blacklist ..."");
                    support.switchListEntry(Configurations.BLACKLIST, groupName, Constants.CATEGORY, EventType.OUTBOUND, pid);
                }
            }
        }


        return null;
    }",1,10227
"    public String toString() {


        if (subject == null || pubKey == null || interval == null
            || issuer == null || algId == null || serialNum == null) {
                throw new NullPointerException(""X.509 cert is incomplete"");
        }
        StringBuilder sb = new StringBuilder();


        sb.append(""[\n"");
        sb.append(""  "" + version.toString() + ""\n"");
        sb.append(""  Subject: "" + subject.toString() + ""\n"");
        sb.append(""  Signature Algorithm: "" + algId.toString() + ""\n"");
        sb.append(""  Key:  "" + pubKey.toString() + ""\n"");
        sb.append(""  "" + interval.toString() + ""\n"");
        sb.append(""  Issuer: "" + issuer.toString() + ""\n"");
        sb.append(""  "" + serialNum.toString() + ""\n"");


        // optional v2, v3 extras
        if (issuerUniqueId != null) {
            sb.append(""  Issuer Id:\n"" + issuerUniqueId.toString() + ""\n"");
        }
        if (subjectUniqueId != null) {
            sb.append(""  Subject Id:\n"" + subjectUniqueId.toString() + ""\n"");
        }
        if (extensions != null) {
            Collection<Extension> allExts = extensions.getAllExtensions();
            Extension[] exts = allExts.toArray(new Extension[0]);
            sb.append(""\nCertificate Extensions: "" + exts.length);
            for (int i = 0; i < exts.length; i++) {
                sb.append(""\n["" + (i+1) + ""]: "");
                Extension ext = exts[i];
                try {
                    if (OIDMap.getClass(ext.getExtensionId()) == null) {
                        sb.append(ext.toString());
                        byte[] extValue = ext.getExtensionValue();
                        if (extValue != null) {
                            DerOutputStream out = new DerOutputStream();
                            out.putOctetString(extValue);
                            extValue = out.toByteArray();
                            HexDumpEncoder enc = new HexDumpEncoder();
                            sb.append(""Extension unknown: ""
                                      + ""DER encoded OCTET string =\n""
                                      + enc.encodeBuffer(extValue) + ""\n"");
                        }
                    } else
                        sb.append(ext.toString()); //sub-class exists
                } catch (Exception e) {
                    sb.append("", Error parsing this extension"");
                }
            }
            Map<String,Extension> invalid = extensions.getUnparseableExtensions();
            if (invalid.isEmpty() == false) {
                sb.append(""\nUnparseable certificate extensions: "" + invalid.size());
                int i = 1;
                for (Extension ext : invalid.values()) {
                    sb.append(""\n["" + (i++) + ""]: "");
                    sb.append(ext);
                }
            }
        }
        sb.append(""\n]"");
        return sb.toString();
    }",1,10253
"  private EntityCollection createETStreamOnComplexProp(Edm edm, OData odata) {
    EntityCollection entityCollection = new EntityCollection();


    Link readLink = new Link();
    readLink.setRel(Constants.NS_MEDIA_READ_LINK_REL);
    readLink.setHref(""readLink"");
    Entity entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyStream"", createImage(""darkturquoise"")));
    readLink.setInlineEntity(entity);
    
    Link readLink1 = new Link();
    readLink1.setRel(Constants.NS_MEDIA_READ_LINK_REL);
    readLink1.setHref(""readLink"");
    entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyEntityStream"", createImage(""darkturquoise"")));
    readLink1.setInlineEntity(entity);
    
    entityCollection.getEntities().add(new Entity()
        .addProperty(createPrimitive(""PropertyInt16"", Short.MAX_VALUE))
        .addProperty(createPrimitive(""PropertyInt32"", Integer.MAX_VALUE))
        .addProperty(new Property(null, ""PropertyEntityStream"", ValueType.PRIMITIVE, readLink1))
        .addProperty(createComplex(""PropertyCompWithStream"",
            ComplexTypeProvider.nameCTWithStreamProp.getFullQualifiedNameAsString(),
            new Property(null, ""PropertyStream"", ValueType.PRIMITIVE, readLink),
            createComplex(""PropertyComp"", 
                ComplexTypeProvider.nameCTTwoPrim.getFullQualifiedNameAsString(),
                createPrimitive(""PropertyInt16"", (short) 333),
                createPrimitive(""PropertyString"", ""TEST123"")))));
    
    Link editLink = new Link();
    editLink.setRel(Constants.NS_MEDIA_EDIT_LINK_REL);
    editLink.setHref(""http://mediaserver:1234/editLink"");
    editLink.setMediaETag(""eTag"");
    editLink.setType(""image/jpeg"");
    entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyStream"", createImage(""royalblue"")));
    editLink.setInlineEntity(entity);
    
    Link editLink2 = new Link();
    editLink2.setRel(Constants.NS_MEDIA_EDIT_LINK_REL);
    editLink2.setHref(""http://mediaserver:1234/editLink"");
    editLink2.setMediaETag(""eTag"");
    editLink2.setType(""image/jpeg"");
    entity = new Entity();
    entity.addProperty(createPrimitive(""PropertyEntityStream"", createImage(""royalblue"")));
    editLink2.setInlineEntity(entity);


    entityCollection.getEntities().add(new Entity()
        .addProperty(createPrimitive(""PropertyInt16"", (short) 7))
        .addProperty(createPrimitive(""PropertyInt32"", (Integer) 10))
        .addProperty(new Property(null, ""PropertyEntityStream"", ValueType.PRIMITIVE, editLink2))
        .addProperty(createComplex(""PropertyCompWithStream"",
            ComplexTypeProvider.nameCTWithStreamProp.getFullQualifiedNameAsString(),
            new Property(null, ""PropertyStream"", ValueType.PRIMITIVE, editLink),
            createComplex(""PropertyComp"", 
                ComplexTypeProvider.nameCTTwoPrim.getFullQualifiedNameAsString(),
                createPrimitive(""PropertyInt16"", (short) 333),
                createPrimitive(""PropertyString"", ""TEST123"")))));


    setEntityType(entityCollection, edm.getEntityType(EntityTypeProvider.nameETStreamOnComplexProp));
    createEntityId(edm, odata, ""ESStreamOnComplexProp"", entityCollection);
    createOperations(""ESStreamOnComplexProp"", entityCollection, EntityTypeProvider.nameETStreamOnComplexProp);
    return entityCollection;
  }",1,10271
"    private void resizeInstructions() {
        byte[] b = code.data; // bytecode of the method
        int u, v, label; // indexes in b
        int i, j; // loop indexes
        /*
         * 1st step: As explained above, resizing an instruction may require to
         * resize another one, which may require to resize yet another one, and
         * so on. The first step of the algorithm consists in finding all the
         * instructions that need to be resized, without modifying the code.
         * This is done by the following ""fix point"" algorithm:
         * 
         * Parse the code to find the jump instructions whose offset will need
         * more than 2 bytes to be stored (the future offset is computed from
         * the current offset and from the number of bytes that will be inserted
         * or removed between the source and target instructions). For each such
         * instruction, adds an entry in (a copy of) the indexes and sizes
         * arrays (if this has not already been done in a previous iteration!).
         * 
         * If at least one entry has been added during the previous step, go
         * back to the beginning, otherwise stop.
         * 
         * In fact the real algorithm is complicated by the fact that the size
         * of TABLESWITCH and LOOKUPSWITCH instructions depends on their
         * position in the bytecode (because of padding). In order to ensure the
         * convergence of the algorithm, the number of bytes to be added or
         * removed from these instructions is over estimated during the previous
         * loop, and computed exactly only after the loop is finished (this
         * requires another pass to parse the bytecode of the method).
         */
        int[] allIndexes = new int[0]; // copy of indexes
        int[] allSizes = new int[0]; // copy of sizes
        boolean[] resize; // instructions to be resized
        int newOffset; // future offset of a jump instruction


        resize = new boolean[code.length];


        // 3 = loop again, 2 = loop ended, 1 = last pass, 0 = done
        int state = 3;
        do {
            if (state == 3) {
                state = 2;
            }
            u = 0;
            while (u < b.length) {
                int opcode = b[u] & 0xFF; // opcode of current instruction
                int insert = 0; // bytes to be added after this instruction


                switch (ClassWriter.TYPE[opcode]) {
                case ClassWriter.NOARG_INSN:
                case ClassWriter.IMPLVAR_INSN:
                    u += 1;
                    break;
                case ClassWriter.LABEL_INSN:
                    if (opcode > 201) {
                        // converts temporary opcodes 202 to 217, 218 and
                        // 219 to IFEQ ... JSR (inclusive), IFNULL and
                        // IFNONNULL
                        opcode = opcode < 218 ? opcode - 49 : opcode - 20;
                        label = u + readUnsignedShort(b, u + 1);
                    } else {
                        label = u + readShort(b, u + 1);
                    }
                    newOffset = getNewOffset(allIndexes, allSizes, u, label);
                    if (newOffset < Short.MIN_VALUE
                            || newOffset > Short.MAX_VALUE) {
                        if (!resize[u]) {
                            if (opcode == Opcodes.GOTO || opcode == Opcodes.JSR) {
                                // two additional bytes will be required to
                                // replace this GOTO or JSR instruction with
                                // a GOTO_W or a JSR_W
                                insert = 2;
                            } else {
                                // five additional bytes will be required to
                                // replace this IFxxx <l> instruction with
                                // IFNOTxxx <l'> GOTO_W <l>, where IFNOTxxx
                                // is the ""opposite"" opcode of IFxxx (i.e.,
                                // IFNE for IFEQ) and where <l'> designates
                                // the instruction just after the GOTO_W.
                                insert = 5;
                            }
                            resize[u] = true;
                        }
                    }
                    u += 3;
                    break;
                case ClassWriter.LABELW_INSN:
                    u += 5;
                    break;
                case ClassWriter.TABL_INSN:
                    if (state == 1) {
                        // true number of bytes to be added (or removed)
                        // from this instruction = (future number of padding
                        // bytes - current number of padding byte) -
                        // previously over estimated variation =
                        // = ((3 - newOffset%4) - (3 - u%4)) - u%4
                        // = (-newOffset%4 + u%4) - u%4
                        // = -(newOffset & 3)
                        newOffset = getNewOffset(allIndexes, allSizes, 0, u);
                        insert = -(newOffset & 3);
                    } else if (!resize[u]) {
                        // over estimation of the number of bytes to be
                        // added to this instruction = 3 - current number
                        // of padding bytes = 3 - (3 - u%4) = u%4 = u & 3
                        insert = u & 3;
                        resize[u] = true;
                    }
                    // skips instruction
                    u = u + 4 - (u & 3);
                    u += 4 * (readInt(b, u + 8) - readInt(b, u + 4) + 1) + 12;
                    break;
                case ClassWriter.LOOK_INSN:
                    if (state == 1) {
                        // like TABL_INSN
                        newOffset = getNewOffset(allIndexes, allSizes, 0, u);
                        insert = -(newOffset & 3);
                    } else if (!resize[u]) {
                        // like TABL_INSN
                        insert = u & 3;
                        resize[u] = true;
                    }
                    // skips instruction
                    u = u + 4 - (u & 3);
                    u += 8 * readInt(b, u + 4) + 8;
                    break;
                case ClassWriter.WIDE_INSN:
                    opcode = b[u + 1] & 0xFF;
                    if (opcode == Opcodes.IINC) {
                        u += 6;
                    } else {
                        u += 4;
                    }
                    break;
                case ClassWriter.VAR_INSN:
                case ClassWriter.SBYTE_INSN:
                case ClassWriter.LDC_INSN:
                    u += 2;
                    break;
                case ClassWriter.SHORT_INSN:
                case ClassWriter.LDCW_INSN:
                case ClassWriter.FIELDORMETH_INSN:
                case ClassWriter.TYPE_INSN:
                case ClassWriter.IINC_INSN:
                    u += 3;
                    break;
                case ClassWriter.ITFMETH_INSN:
                case ClassWriter.INDYMETH_INSN:
                    u += 5;
                    break;
                // case ClassWriter.MANA_INSN:
                default:
                    u += 4;
                    break;
                }
                if (insert != 0) {
                    // adds a new (u, insert) entry in the allIndexes and
                    // allSizes arrays
                    int[] newIndexes = new int[allIndexes.length + 1];
                    int[] newSizes = new int[allSizes.length + 1];
                    System.arraycopy(allIndexes, 0, newIndexes, 0,
                            allIndexes.length);
                    System.arraycopy(allSizes, 0, newSizes, 0, allSizes.length);
                    newIndexes[allIndexes.length] = u;
                    newSizes[allSizes.length] = insert;
                    allIndexes = newIndexes;
                    allSizes = newSizes;
                    if (insert > 0) {
                        state = 3;
                    }
                }
            }
            if (state < 3) {
                --state;
            }
        } while (state != 0);


        // 2nd step:
        // copies the bytecode of the method into a new bytevector, updates the
        // offsets, and inserts (or removes) bytes as requested.


        ByteVector newCode = new ByteVector(code.length);


        u = 0;
        while (u < code.length) {
            int opcode = b[u] & 0xFF;
            switch (ClassWriter.TYPE[opcode]) {
            case ClassWriter.NOARG_INSN:
            case ClassWriter.IMPLVAR_INSN:
                newCode.putByte(opcode);
                u += 1;
                break;
            case ClassWriter.LABEL_INSN:
                if (opcode > 201) {
                    // changes temporary opcodes 202 to 217 (inclusive), 218
                    // and 219 to IFEQ ... JSR (inclusive), IFNULL and
                    // IFNONNULL
                    opcode = opcode < 218 ? opcode - 49 : opcode - 20;
                    label = u + readUnsignedShort(b, u + 1);
                } else {
                    label = u + readShort(b, u + 1);
                }
                newOffset = getNewOffset(allIndexes, allSizes, u, label);
                if (resize[u]) {
                    // replaces GOTO with GOTO_W, JSR with JSR_W and IFxxx
                    // <l> with IFNOTxxx <l'> GOTO_W <l>, where IFNOTxxx is
                    // the ""opposite"" opcode of IFxxx (i.e., IFNE for IFEQ)
                    // and where <l'> designates the instruction just after
                    // the GOTO_W.
                    if (opcode == Opcodes.GOTO) {
                        newCode.putByte(200); // GOTO_W
                    } else if (opcode == Opcodes.JSR) {
                        newCode.putByte(201); // JSR_W
                    } else {
                        newCode.putByte(opcode <= 166 ? ((opcode + 1) ^ 1) - 1
                                : opcode ^ 1);
                        newCode.putShort(8); // jump offset
                        newCode.putByte(200); // GOTO_W
                        // newOffset now computed from start of GOTO_W
                        newOffset -= 3;
                    }
                    newCode.putInt(newOffset);
                } else {
                    newCode.putByte(opcode);
                    newCode.putShort(newOffset);
                }
                u += 3;
                break;
            case ClassWriter.LABELW_INSN:
                label = u + readInt(b, u + 1);
                newOffset = getNewOffset(allIndexes, allSizes, u, label);
                newCode.putByte(opcode);
                newCode.putInt(newOffset);
                u += 5;
                break;
            case ClassWriter.TABL_INSN:
                // skips 0 to 3 padding bytes
                v = u;
                u = u + 4 - (v & 3);
                // reads and copies instruction
                newCode.putByte(Opcodes.TABLESWITCH);
                newCode.putByteArray(null, 0, (4 - newCode.length % 4) % 4);
                label = v + readInt(b, u);
                u += 4;
                newOffset = getNewOffset(allIndexes, allSizes, v, label);
                newCode.putInt(newOffset);
                j = readInt(b, u);
                u += 4;
                newCode.putInt(j);
                j = readInt(b, u) - j + 1;
                u += 4;
                newCode.putInt(readInt(b, u - 4));
                for (; j > 0; --j) {
                    label = v + readInt(b, u);
                    u += 4;
                    newOffset = getNewOffset(allIndexes, allSizes, v, label);
                    newCode.putInt(newOffset);
                }
                break;
            case ClassWriter.LOOK_INSN:
                // skips 0 to 3 padding bytes
                v = u;
                u = u + 4 - (v & 3);
                // reads and copies instruction
                newCode.putByte(Opcodes.LOOKUPSWITCH);
                newCode.putByteArray(null, 0, (4 - newCode.length % 4) % 4);
                label = v + readInt(b, u);
                u += 4;
                newOffset = getNewOffset(allIndexes, allSizes, v, label);
                newCode.putInt(newOffset);
                j = readInt(b, u);
                u += 4;
                newCode.putInt(j);
                for (; j > 0; --j) {
                    newCode.putInt(readInt(b, u));
                    u += 4;
                    label = v + readInt(b, u);
                    u += 4;
                    newOffset = getNewOffset(allIndexes, allSizes, v, label);
                    newCode.putInt(newOffset);
                }
                break;
            case ClassWriter.WIDE_INSN:
                opcode = b[u + 1] & 0xFF;
                if (opcode == Opcodes.IINC) {
                    newCode.putByteArray(b, u, 6);
                    u += 6;
                } else {
                    newCode.putByteArray(b, u, 4);
                    u += 4;
                }
                break;
            case ClassWriter.VAR_INSN:
            case ClassWriter.SBYTE_INSN:
            case ClassWriter.LDC_INSN:
                newCode.putByteArray(b, u, 2);
                u += 2;
                break;
            case ClassWriter.SHORT_INSN:
            case ClassWriter.LDCW_INSN:
            case ClassWriter.FIELDORMETH_INSN:
            case ClassWriter.TYPE_INSN:
            case ClassWriter.IINC_INSN:
                newCode.putByteArray(b, u, 3);
                u += 3;
                break;
            case ClassWriter.ITFMETH_INSN:
            case ClassWriter.INDYMETH_INSN:
                newCode.putByteArray(b, u, 5);
                u += 5;
                break;
            // case MANA_INSN:
            default:
                newCode.putByteArray(b, u, 4);
                u += 4;
                break;
            }
        }


        // recomputes the stack map frames
        if (frameCount > 0) {
            if (compute == FRAMES) {
                frameCount = 0;
                stackMap = null;
                previousFrame = null;
                frame = null;
                Frame f = new Frame();
                f.owner = labels;
                Type[] args = Type.getArgumentTypes(descriptor);
                f.initInputFrame(cw, access, args, maxLocals);
                visitFrame(f);
                Label l = labels;
                while (l != null) {
                    /*
                     * here we need the original label position. getNewOffset
                     * must therefore never have been called for this label.
                     */
                    u = l.position - 3;
                    if ((l.status & Label.STORE) != 0 || (u >= 0 && resize[u])) {
                        getNewOffset(allIndexes, allSizes, l);
                        // TODO update offsets in UNINITIALIZED values
                        visitFrame(l.frame);
                    }
                    l = l.successor;
                }
            } else {
                /*
                 * Resizing an existing stack map frame table is really hard.
                 * Not only the table must be parsed to update the offets, but
                 * new frames may be needed for jump instructions that were
                 * inserted by this method. And updating the offsets or
                 * inserting frames can change the format of the following
                 * frames, in case of packed frames. In practice the whole table
                 * must be recomputed. For this the frames are marked as
                 * potentially invalid. This will cause the whole class to be
                 * reread and rewritten with the COMPUTE_FRAMES option (see the
                 * ClassWriter.toByteArray method). This is not very efficient
                 * but is much easier and requires much less code than any other
                 * method I can think of.
                 */
                cw.invalidFrames = true;
            }
        }
        // updates the exception handler block labels
        Handler h = firstHandler;
        while (h != null) {
            getNewOffset(allIndexes, allSizes, h.start);
            getNewOffset(allIndexes, allSizes, h.end);
            getNewOffset(allIndexes, allSizes, h.handler);
            h = h.next;
        }
        // updates the instructions addresses in the
        // local var and line number tables
        for (i = 0; i < 2; ++i) {
            ByteVector bv = i == 0 ? localVar : localVarType;
            if (bv != null) {
                b = bv.data;
                u = 0;
                while (u < bv.length) {
                    label = readUnsignedShort(b, u);
                    newOffset = getNewOffset(allIndexes, allSizes, 0, label);
                    writeShort(b, u, newOffset);
                    label += readUnsignedShort(b, u + 2);
                    newOffset = getNewOffset(allIndexes, allSizes, 0, label)
                            - newOffset;
                    writeShort(b, u + 2, newOffset);
                    u += 10;
                }
            }
        }
        if (lineNumber != null) {
            b = lineNumber.data;
            u = 0;
            while (u < lineNumber.length) {
                writeShort(
                        b,
                        u,
                        getNewOffset(allIndexes, allSizes, 0,
                                readUnsignedShort(b, u)));
                u += 4;
            }
        }
        // updates the labels of the other attributes
        Attribute attr = cattrs;
        while (attr != null) {
            Label[] labels = attr.getLabels();
            if (labels != null) {
                for (i = labels.length - 1; i >= 0; --i) {
                    getNewOffset(allIndexes, allSizes, labels[i]);
                }
            }
            attr = attr.next;
        }


        // replaces old bytecodes with new ones
        code = newCode;
    }",1,10287
"	public BindStatus(RequestContext requestContext, String path, boolean htmlEscape) throws IllegalStateException {
		this.requestContext = requestContext;
		this.path = path;
		this.htmlEscape = htmlEscape;


		// determine name of the object and property
		String beanName;
		int dotPos = path.indexOf('.');
		if (dotPos == -1) {
			// property not set, only the object itself
			beanName = path;
			this.expression = null;
		}
		else {
			beanName = path.substring(0, dotPos);
			this.expression = path.substring(dotPos + 1);
		}


		this.errors = requestContext.getErrors(beanName, false);


		if (this.errors != null) {
			// Usual case: A BindingResult is available as request attribute.
			// Can determine error codes and messages for the given expression.
			// Can use a custom PropertyEditor, as registered by a form controller.
			if (this.expression != null) {
				if (""*"".equals(this.expression)) {
					this.objectErrors = this.errors.getAllErrors();
				}
				else if (this.expression.endsWith(""*"")) {
					this.objectErrors = this.errors.getFieldErrors(this.expression);
				}
				else {
					this.objectErrors = this.errors.getFieldErrors(this.expression);
					this.value = this.errors.getFieldValue(this.expression);
					this.valueType = this.errors.getFieldType(this.expression);
					if (this.errors instanceof BindingResult) {
						this.bindingResult = (BindingResult) this.errors;
						this.actualValue = this.bindingResult.getRawFieldValue(this.expression);
						this.editor = this.bindingResult.findEditor(this.expression, null);
					}
					else {
						this.actualValue = this.value;
					}
				}
			}
			else {
				this.objectErrors = this.errors.getGlobalErrors();
			}
			this.errorCodes = initErrorCodes(this.objectErrors);
		}


		else {
			// No BindingResult available as request attribute:
			// Probably forwarded directly to a form view.
			// Let's do the best we can: extract a plain target if appropriate.
			Object target = requestContext.getModelObject(beanName);
			if (target == null) {
				throw new IllegalStateException(""Neither BindingResult nor plain target object for bean name '"" +
						beanName + ""' available as request attribute"");
			}
			if (this.expression != null && !""*"".equals(this.expression) && !this.expression.endsWith(""*"")) {
				BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(target);
				this.value = bw.getPropertyValue(this.expression);
				this.valueType = bw.getPropertyType(this.expression);
				this.actualValue = this.value;
			}
			this.errorCodes = new String[0];
			this.errorMessages = new String[0];
		}


		if (htmlEscape && this.value instanceof String) {
			this.value = HtmlUtils.htmlEscape((String) this.value);
		}
	}",1,10409
"    public static String shortenDbName(String dbName, int desiredLength) {
        StringBuilder dbBuf = new StringBuilder(dbName);
        if (dbBuf.length() > desiredLength) {
            // remove one vowel at a time, starting at beginning
            for (int i = dbBuf.length() - 1; i > 0; i--) {
                // don't remove vowels that are at the beginning of the string (taken care of by the i > 0) or right after an underscore
                if (dbBuf.charAt(i - 1) == '_') {
                    continue;
                }


                char curChar = dbBuf.charAt(i);
                if (vowelBag.indexOf(curChar) > 0) {
                    dbBuf.deleteCharAt(i);
                }
            }
        }


        // remove all double underscores
        while (dbBuf.indexOf(""__"") > 0) {
            dbBuf.deleteCharAt(dbBuf.indexOf(""__""));
        }


        while (dbBuf.length() > desiredLength) {
            boolean removedChars = false;


            int usIndex = dbBuf.lastIndexOf(""_"");
            while (usIndex > 0 && dbBuf.length() > desiredLength) {
                // if this is the first word in the group, don't pull letters off unless it is 4 letters or more
                int prevUsIndex = dbBuf.lastIndexOf(""_"", usIndex - 1);
                if (prevUsIndex < 0 && usIndex < 4) {
                    break;
                }


                // don't remove characters to reduce the size two less than three characters between underscores
                if (prevUsIndex >= 0 && (usIndex - prevUsIndex) <= 4) {
                    usIndex = prevUsIndex;
                    continue;
                }


                // delete the second to last character instead of the last, better chance of being unique
                dbBuf.deleteCharAt(usIndex - 2);
                removedChars = true;
                if (usIndex > 2) {
                    usIndex = dbBuf.lastIndexOf(""_"", usIndex - 2);
                } else {
                    break;
                }
            }


            // now delete the char at the end of the string if necessary
            if (dbBuf.length() > desiredLength) {
                int removeIndex = dbBuf.length() - 1;
                int prevRemoveIndex = dbBuf.lastIndexOf(""_"", removeIndex - 1);
                // don't remove characters to reduce the size two less than two characters between underscores
                if (prevRemoveIndex < 0 || (removeIndex - prevRemoveIndex) >= 3) {
                    // delete the second to last character instead of the last, better chance of being unique
                    dbBuf.deleteCharAt(removeIndex - 1);
                    removedChars = true;
                }
            }


            // remove all double underscores
            while (dbBuf.indexOf(""__"") > 0) {
                dbBuf.deleteCharAt(dbBuf.indexOf(""__""));
                removedChars = true;
            }


            // if we didn't remove anything break out to avoid an infinite loop
            if (!removedChars) {
                break;
            }
        }


        // remove all double underscores
        while (dbBuf.indexOf(""__"") > 0) {
            dbBuf.deleteCharAt(dbBuf.indexOf(""__""));
        }


        while (dbBuf.length() > desiredLength) {
            // still not short enough, get more aggressive
            // don't remove the first segment, just remove the second over and over until we are short enough
            int firstUs = dbBuf.indexOf(""_"");
            if (firstUs > 0) {
                int nextUs = dbBuf.indexOf(""_"", firstUs + 1);
                if (nextUs > 0) {
                    //Debug.logInfo(""couldn't shorten enough normally, removing second segment from "" + dbBuf, module);
                    dbBuf.delete(firstUs, nextUs);
                }
            }
        }


        //Debug.logInfo(""Shortened "" + dbName + "" to "" + dbBuf.toString(), module);
        return dbBuf.toString();
    }",1,10513
"    protected SQLBuffer toBulkOperation(ClassMapping mapping, Select sel,
        JDBCStore store, Object[] params, Map updateParams) {
        SQLBuffer sql = new SQLBuffer(this);
        if (updateParams == null) {
          if (requiresTargetForDelete) {
            sql.append(""DELETE "");
            SQLBuffer deleteTargets = getDeleteTargets(sel);
            sql.append(deleteTargets);
            sql.append("" FROM "");
          } else {
            sql.append(""DELETE FROM "");
          }
        }
        else
            sql.append(""UPDATE "");
        sel.addJoinClassConditions();


        // if there is only a single table in the select, then we can
        // just issue a single DELETE FROM TABLE WHERE <conditions>
        // statement; otherwise, since SQL doesn't allow deleting
        // from one of a multi-table select, we need to issue a subselect
        // like DELETE FROM TABLE WHERE EXISTS
        // (SELECT 1 FROM TABLE t0 WHERE t0.ID = TABLE.ID); also, some
        // databases do not allow aliases in delete statements, which
        // also causes us to use a subselect
        Collection<String> selectedTables = getSelectTableAliases(sel);
        if (selectedTables.size() == 1 && supportsSubselect
            && allowsAliasInBulkClause) {
            SQLBuffer from;
            if (sel.getFromSelect() != null)
                from = getFromSelect(sel, false);
            else
                from = getFrom(sel, false);


            sql.append(from);
            appendUpdates(sel, store, sql, params, updateParams,
                allowsAliasInBulkClause);


            SQLBuffer where = sel.getWhere();
            if (where != null && !where.isEmpty()) {
                sql.append("" WHERE "");
                sql.append(where);
            }
            return sql;
        }


        Table table = mapping.getTable();
        String tableName = getFullName(table, false);


        // only use a  subselect if the where is not empty; otherwise
        // an unqualified delete or update will work
        if (sel.getWhere() == null || sel.getWhere().isEmpty()) {
            sql.append(tableName);
            appendUpdates(sel, store, sql, params, updateParams, false);
            return sql;
        }


        // we need to use a subselect if we are to bulk delete where
        // the select includes multiple tables; if the database
        // doesn't support it, then we need to signal this by returning null
        if (!supportsSubselect || !supportsCorrelatedSubselect)
            return null;


        Column[] pks = mapping.getPrimaryKeyColumns();
        sel.clearSelects();
        sel.setDistinct(true);


        // if we have only a single PK, we can use a non-correlated
        // subquery (using an IN statement), which is much faster than
        // a correlated subquery (since a correlated subquery needs
        // to be executed once for each row in the table)
        if (pks.length == 1) {
            sel.select(pks[0]);
            sql.append(tableName);
            appendUpdates(sel, store, sql, params, updateParams, false);
            sql.append("" WHERE "").
                append(pks[0]).append("" IN ("").
                append(sel.toSelect(false, null)).append("")"");
        } else {
            sel.clearSelects();
            sel.setDistinct(false);


            // since the select is using a correlated subquery, we
            // only need to select a bogus virtual column
            sel.select(""1"", null);


            // add in the joins to the table
            Column[] cols = table.getPrimaryKey().getColumns();
            SQLBuffer buf = new SQLBuffer(this);
            buf.append(""("");
            for (int i = 0; i < cols.length; i++) {
                if (i > 0)
                    buf.append("" AND "");


                // add in ""t0.PK = MYTABLE.PK""
                buf.append(sel.getColumnAlias(cols[i])).append("" = "").
                    append(table).append(catalogSeparator).append(cols[i]);
            }
            buf.append("")"");
            sel.where(buf, null);


            sql.append(tableName);
            appendUpdates(sel, store, sql, params, updateParams, false);
            sql.append("" WHERE EXISTS ("").
                append(sel.toSelect(false, null)).append("")"");
        }
        return sql;
    }",1,10679
"    @Override
    public ListenableFuture<Void> recover(QueueManagingVirtualHost<?> virtualHost)
    {
        EventLogger eventLogger = virtualHost.getEventLogger();
        MessageStore store = virtualHost.getMessageStore();
        MessageStore.MessageStoreReader storeReader = store.newMessageStoreReader();
        MessageStoreLogSubject logSubject = new MessageStoreLogSubject(virtualHost.getName(), store.getClass().getSimpleName());


        Map<Queue<?>, Integer> queueRecoveries = new TreeMap<>();
        Map<Long, ServerMessage<?>> recoveredMessages = new HashMap<>();
        Map<Long, StoredMessage<?>> unusedMessages = new TreeMap<>();
        Map<UUID, Integer> unknownQueuesWithMessages = new HashMap<>();
        Map<Queue<?>, Integer> queuesWithUnknownMessages = new HashMap<>();


        eventLogger.message(logSubject, MessageStoreMessages.RECOVERY_START());


        storeReader.visitMessages(new MessageVisitor(recoveredMessages, unusedMessages));


        eventLogger.message(logSubject, TransactionLogMessages.RECOVERY_START(null, false));
        try
        {
            storeReader.visitMessageInstances(new MessageInstanceVisitor(virtualHost,
                                                                         store,
                                                                         queueRecoveries,
                                                                         recoveredMessages,
                                                                         unusedMessages,
                                                                         unknownQueuesWithMessages,
                                                                         queuesWithUnknownMessages));
        }
        finally
        {
            if (!unknownQueuesWithMessages.isEmpty())
            {
                unknownQueuesWithMessages.forEach((queueId, count) -> {
                    LOGGER.info(""Discarded {} entry(s) associated with queue id '{}' as a queue with this ""
                                 + ""id does not appear in the configuration."",
                                 count, queueId);
                });
            }
            if (!queuesWithUnknownMessages.isEmpty())
            {
                queuesWithUnknownMessages.forEach((queue, count) -> {
                    LOGGER.info(""Discarded {} entry(s) associated with queue '{}' as the referenced message ""
                                 + ""does not exist."",
                                 count, queue.getName());
                });
            }
        }


        for(Map.Entry<Queue<?>, Integer> entry : queueRecoveries.entrySet())
        {
            Queue<?> queue = entry.getKey();
            Integer deliveredCount = entry.getValue();
            eventLogger.message(logSubject, TransactionLogMessages.RECOVERED(deliveredCount, queue.getName()));
            eventLogger.message(logSubject, TransactionLogMessages.RECOVERY_COMPLETE(queue.getName(), true));
            queue.completeRecovery();
        }


        for (Queue<?> q : virtualHost.getChildren(Queue.class))
        {
            if (!queueRecoveries.containsKey(q))
            {
                q.completeRecovery();
            }
        }


        storeReader.visitDistributedTransactions(new DistributedTransactionVisitor(virtualHost,
                                                                                   eventLogger,
                                                                                   logSubject, recoveredMessages, unusedMessages));


        for(StoredMessage<?> m : unusedMessages.values())
        {
            LOGGER.debug(""Message id '{}' is orphaned, removing"", m.getMessageNumber());
            m.remove();
        }


        if (unusedMessages.size() > 0)
        {
            LOGGER.info(""Discarded {} orphaned message(s)."", unusedMessages.size());
        }


        eventLogger.message(logSubject, TransactionLogMessages.RECOVERY_COMPLETE(null, false));


        eventLogger.message(logSubject,
                             MessageStoreMessages.RECOVERED(recoveredMessages.size() - unusedMessages.size()));
        eventLogger.message(logSubject, MessageStoreMessages.RECOVERY_COMPLETE());


        return Futures.immediateFuture(null);
    }",1,10681
"    public final EObject ruleXOtherOperatorExpression() throws RecognitionException {
        EObject current = null;


        EObject this_XAdditiveExpression_0 = null;


        EObject lv_rightOperand_3_0 = null;






        	enterRule();


        try {
            // InternalXbase.g:873:2: ( (this_XAdditiveExpression_0= ruleXAdditiveExpression ( ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) ) ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) ) )* ) )
            // InternalXbase.g:874:2: (this_XAdditiveExpression_0= ruleXAdditiveExpression ( ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) ) ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) ) )* )
            {
            // InternalXbase.g:874:2: (this_XAdditiveExpression_0= ruleXAdditiveExpression ( ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) ) ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) ) )* )
            // InternalXbase.g:875:3: this_XAdditiveExpression_0= ruleXAdditiveExpression ( ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) ) ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) ) )*
            {
            if ( state.backtracking==0 ) {


              			newCompositeNode(grammarAccess.getXOtherOperatorExpressionAccess().getXAdditiveExpressionParserRuleCall_0());
              		
            }
            pushFollow(FOLLOW_14);
            this_XAdditiveExpression_0=ruleXAdditiveExpression();


            state._fsp--;
            if (state.failed) return current;
            if ( state.backtracking==0 ) {


              			current = this_XAdditiveExpression_0;
              			afterParserOrEnumRuleCall();
              		
            }
            // InternalXbase.g:883:3: ( ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) ) ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) ) )*
            loop11:
            do {
                int alt11=2;
                alt11 = dfa11.predict(input);
                switch (alt11) {
            	case 1 :
            	    // InternalXbase.g:884:4: ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) ) ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) )
            	    {
            	    // InternalXbase.g:884:4: ( ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) ) )
            	    // InternalXbase.g:885:5: ( ( () ( ( ruleOpOther ) ) ) )=> ( () ( ( ruleOpOther ) ) )
            	    {
            	    // InternalXbase.g:895:5: ( () ( ( ruleOpOther ) ) )
            	    // InternalXbase.g:896:6: () ( ( ruleOpOther ) )
            	    {
            	    // InternalXbase.g:896:6: ()
            	    // InternalXbase.g:897:7: 
            	    {
            	    if ( state.backtracking==0 ) {


            	      							current = forceCreateModelElementAndSet(
            	      								grammarAccess.getXOtherOperatorExpressionAccess().getXBinaryOperationLeftOperandAction_1_0_0_0(),
            	      								current);
            	      						
            	    }


            	    }


            	    // InternalXbase.g:903:6: ( ( ruleOpOther ) )
            	    // InternalXbase.g:904:7: ( ruleOpOther )
            	    {
            	    // InternalXbase.g:904:7: ( ruleOpOther )
            	    // InternalXbase.g:905:8: ruleOpOther
            	    {
            	    if ( state.backtracking==0 ) {


            	      								if (current==null) {
            	      									current = createModelElement(grammarAccess.getXOtherOperatorExpressionRule());
            	      								}
            	      							
            	    }
            	    if ( state.backtracking==0 ) {


            	      								newCompositeNode(grammarAccess.getXOtherOperatorExpressionAccess().getFeatureJvmIdentifiableElementCrossReference_1_0_0_1_0());
            	      							
            	    }
            	    pushFollow(FOLLOW_4);
            	    ruleOpOther();


            	    state._fsp--;
            	    if (state.failed) return current;
            	    if ( state.backtracking==0 ) {


            	      								afterParserOrEnumRuleCall();
            	      							
            	    }


            	    }




            	    }




            	    }




            	    }


            	    // InternalXbase.g:921:4: ( (lv_rightOperand_3_0= ruleXAdditiveExpression ) )
            	    // InternalXbase.g:922:5: (lv_rightOperand_3_0= ruleXAdditiveExpression )
            	    {
            	    // InternalXbase.g:922:5: (lv_rightOperand_3_0= ruleXAdditiveExpression )
            	    // InternalXbase.g:923:6: lv_rightOperand_3_0= ruleXAdditiveExpression
            	    {
            	    if ( state.backtracking==0 ) {


            	      						newCompositeNode(grammarAccess.getXOtherOperatorExpressionAccess().getRightOperandXAdditiveExpressionParserRuleCall_1_1_0());
            	      					
            	    }
            	    pushFollow(FOLLOW_14);
            	    lv_rightOperand_3_0=ruleXAdditiveExpression();


            	    state._fsp--;
            	    if (state.failed) return current;
            	    if ( state.backtracking==0 ) {


            	      						if (current==null) {
            	      							current = createModelElementForParent(grammarAccess.getXOtherOperatorExpressionRule());
            	      						}
            	      						set(
            	      							current,
            	      							""rightOperand"",
            	      							lv_rightOperand_3_0,
            	      							""org.eclipse.xtext.xbase.Xbase.XAdditiveExpression"");
            	      						afterParserOrEnumRuleCall();
            	      					
            	    }


            	    }




            	    }




            	    }
            	    break;


            	default :
            	    break loop11;
                }
            } while (true);




            }




            }


            if ( state.backtracking==0 ) {


              	leaveRule();


            }
        }


            catch (RecognitionException re) {
                recover(input,re);
                appendSkippedTokens();
            }
        finally {
        }
        return current;
    }",1,10690
"  long recoverDrf(OplogEntryIdSet deletedIds, boolean alreadyRecoveredOnce, boolean latestOplog) {
    File drfFile = this.drf.f;
    if (drfFile == null) {
      this.haveRecoveredDrf = true;
      return 0L;
    }
    lockCompactor();
    try {
      if (this.haveRecoveredDrf && !getHasDeletes())
        return 0L; // do this while holding lock
      if (!this.haveRecoveredDrf) {
        this.haveRecoveredDrf = true;
      }
      logger.info(""Recovering {} {} for disk store {}."",
          new Object[] {toString(), drfFile.getAbsolutePath(), getParent().getName()});
      this.recoverDelEntryId = DiskStoreImpl.INVALID_ID;
      boolean readLastRecord = true;
      CountingDataInputStream dis = null;
      try {
        int recordCount = 0;
        boolean foundDiskStoreRecord = false;
        FileInputStream fis = null;
        try {
          fis = new FileInputStream(drfFile);
          dis = new CountingDataInputStream(new BufferedInputStream(fis, 32 * 1024),
              drfFile.length());
          boolean endOfLog = false;
          while (!endOfLog) {
            if (dis.atEndOfFile()) {
              endOfLog = true;
              break;
            }
            readLastRecord = false;
            byte opCode = dis.readByte();
            if (logger.isTraceEnabled(LogMarker.PERSIST_RECOVERY_VERBOSE)) {
              logger.trace(LogMarker.PERSIST_RECOVERY_VERBOSE, ""drf byte={} location={}"", opCode,
                  Long.toHexString(dis.getCount()));
            }
            switch (opCode) {
              case OPLOG_EOF_ID:
                // we are at the end of the oplog. So we need to back up one byte
                dis.decrementCount();
                endOfLog = true;
                break;
              case OPLOG_DEL_ENTRY_1ID:
              case OPLOG_DEL_ENTRY_2ID:
              case OPLOG_DEL_ENTRY_3ID:
              case OPLOG_DEL_ENTRY_4ID:
              case OPLOG_DEL_ENTRY_5ID:
              case OPLOG_DEL_ENTRY_6ID:
              case OPLOG_DEL_ENTRY_7ID:
              case OPLOG_DEL_ENTRY_8ID:
                readDelEntry(dis, opCode, deletedIds, parent);
                recordCount++;
                break;
              case OPLOG_DISK_STORE_ID:
                readDiskStoreRecord(dis, this.drf.f);
                foundDiskStoreRecord = true;
                recordCount++;
                break;
              case OPLOG_MAGIC_SEQ_ID:
                readOplogMagicSeqRecord(dis, this.drf.f, OPLOG_TYPE.DRF);
                break;
              case OPLOG_GEMFIRE_VERSION:
                readGemfireVersionRecord(dis, this.drf.f);
                recordCount++;
                break;


              case OPLOG_RVV:
                long idx = dis.getCount();
                readRVVRecord(dis, this.drf.f, true, latestOplog);
                recordCount++;
                break;


              default:
                throw new DiskAccessException(
                    String.format(""Unknown opCode %s found in disk operation log."",
                        opCode),
                    getParent());
            }
            readLastRecord = true;
            // @todo
            // if (rgn.isDestroyed()) {
            // break;
            // }
          } // while
        } finally {
          if (dis != null) {
            dis.close();
          }
          if (fis != null) {
            fis.close();
          }
        }
        if (!foundDiskStoreRecord && recordCount > 0) {
          throw new DiskAccessException(
              ""The oplog file \"""" + this.drf.f + ""\"" does not belong to the init file \""""
                  + getParent().getInitFile() + ""\"". Drf did not contain a disk store id."",
              getParent());
        }
      } catch (EOFException ignore) {
        // ignore since a partial record write can be caused by a crash
      } catch (IOException ex) {
        getParent().getCancelCriterion().checkCancelInProgress(ex);
        throw new DiskAccessException(
            String.format(""Failed to read file during recovery from %s"",
                drfFile.getPath()),
            ex, getParent());
      } catch (CancelException e) {
        if (logger.isDebugEnabled()) {
          logger.debug(""Oplog::readOplog:Error in recovery as Cache was closed"", e);
        }
      } catch (RegionDestroyedException e) {
        if (logger.isDebugEnabled()) {
          logger.debug(""Oplog::readOplog:Error in recovery as Region was destroyed"", e);
        }
      }
      // Add the Oplog size to the Directory Holder which owns this oplog,
      // so that available space is correctly calculated & stats updated.
      long byteCount = 0;
      if (!readLastRecord) {
        // this means that there was a crash
        // and hence we should not continue to read
        // the next oplog
        this.crashed = true;
        if (dis != null) {
          byteCount = dis.getFileLength();
        }
      } else {
        if (dis != null) {
          byteCount = dis.getCount();
        }
      }
      if (!alreadyRecoveredOnce) {
        setRecoveredDrfSize(byteCount);
        this.dirHolder.incrementTotalOplogSize(byteCount);
      }
      return byteCount;
    } finally {
      unlockCompactor();
    }
  }",1,10697
"    public static RuleSet parse(final Reader configReader, EventLoggerProvider eventLogger)
    {
        RuleSetCreator ruleSetCreator = new RuleSetCreator();


        int line = 0;
        try(Reader fileReader = configReader)
        {
            LOGGER.debug(""About to load ACL file"");
            StreamTokenizer tokenizer = new StreamTokenizer(new BufferedReader(fileReader));
            tokenizer.resetSyntax(); // setup the tokenizer


            tokenizer.commentChar(COMMENT); // single line comments
            tokenizer.eolIsSignificant(true); // return EOL as a token
            tokenizer.ordinaryChar('='); // equals is a token
            tokenizer.ordinaryChar(CONTINUATION); // continuation character (when followed by EOL)
            tokenizer.quoteChar('""'); // double quote
            tokenizer.quoteChar('\''); // single quote
            tokenizer.whitespaceChars('\u0000', '\u0020'); // whitespace (to be ignored) TODO properly
            tokenizer.wordChars('a', 'z'); // unquoted token characters [a-z]
            tokenizer.wordChars('A', 'Z'); // [A-Z]
            tokenizer.wordChars('0', '9'); // [0-9]
            tokenizer.wordChars('_', '_'); // underscore
            tokenizer.wordChars('-', '-'); // dash
            tokenizer.wordChars('.', '.'); // dot
            tokenizer.wordChars('*', '*'); // star
            tokenizer.wordChars('@', '@'); // at
            tokenizer.wordChars(':', ':'); // colon


            // parse the acl file lines
            Stack<String> stack = new Stack<>();
            int current;
            do {
                current = tokenizer.nextToken();
                line = tokenizer.lineno()-1;
                switch (current)
                {
                    case StreamTokenizer.TT_EOF:
                    case StreamTokenizer.TT_EOL:
                        if (stack.isEmpty())
                        {
                            break; // blank line
                        }


                        // pull out the first token from the bottom of the stack and check arguments exist
                        String first = stack.firstElement();
                        stack.removeElementAt(0);
                        if (stack.isEmpty())
                        {
                            throw new IllegalConfigurationException(String.format(NOT_ENOUGH_TOKENS_MSG, line));
                        }


                        // check for and parse optional initial number for ACL lines
                        Integer number = null;
                        if (first != null && first.matches(""\\d+""))
                        {
                            // set the acl number and get the next element
                            number = Integer.valueOf(first);
                            first = stack.firstElement();
                            stack.removeElementAt(0);
                        }


                        if (ACL.equalsIgnoreCase(first))
                        {
                            parseAcl(number, stack, ruleSetCreator, line);
                        }
                        else if (number == null)
                        {
                            if(""GROUP"".equalsIgnoreCase(first))
                            {
                                throw new IllegalConfigurationException(String.format(""GROUP keyword not supported at ""
                                                                                      + ""line %d. Groups should defined ""
                                                                                      + ""via a Group Provider, not in ""
                                                                                      + ""the ACL file."",
                                                                                      line));
                            }
                            else if (CONFIG.equalsIgnoreCase(first))
                            {
                                parseConfig(stack, ruleSetCreator, line);
                            }
                            else
                            {
                                throw new IllegalConfigurationException(String.format(UNRECOGNISED_INITIAL_MSG, first, line));
                            }
                        }
                        else
                        {
                            throw new IllegalConfigurationException(String.format(NUMBER_NOT_ALLOWED_MSG, first, line));
                        }


                        // reset stack, start next line
                        stack.clear();
                        break;
                    case StreamTokenizer.TT_NUMBER:
                        stack.push(Integer.toString(Double.valueOf(tokenizer.nval).intValue()));
                        break;
                    case StreamTokenizer.TT_WORD:
                        stack.push(tokenizer.sval); // token
                        break;
                    default:
                        if (tokenizer.ttype == CONTINUATION)
                        {
                            int next = tokenizer.nextToken();
                            line = tokenizer.lineno()-1;
                            if (next == StreamTokenizer.TT_EOL)
                            {
	                            break; // continue reading next line
                            }


                            // invalid location for continuation character (add one to line because we ate the EOL)
                            throw new IllegalConfigurationException(String.format(PREMATURE_CONTINUATION_MSG, line + 1));
                        }
                        else if (tokenizer.ttype == '\'' || tokenizer.ttype == '""')
                        {
                            stack.push(tokenizer.sval); // quoted token
                        }
                        else
                        {
                            stack.push(Character.toString((char) tokenizer.ttype)); // single character
                        }
                }
            } while (current != StreamTokenizer.TT_EOF);


            if (!stack.isEmpty())
            {
                throw new IllegalConfigurationException(String.format(PREMATURE_EOF_MSG, line));
            }
        }
        catch (IllegalArgumentException iae)
        {
            throw new IllegalConfigurationException(String.format(PARSE_TOKEN_FAILED_MSG, line), iae);
        }
        catch (IOException ioe)
        {
            throw new IllegalConfigurationException(CANNOT_LOAD_MSG, ioe);
        }
        return ruleSetCreator.createRuleSet(eventLogger);
    }",1,10803
"  private static String normalizePath(String path) {
    // count the number of '/'s, to determine number of segments
    int index = -1;
    int pathlen = path.length();
    int size = 0;
    if (pathlen > 0 && path.charAt(0) != '/') {
      size++;
    }
    while ((index = path.indexOf('/', index + 1)) != -1) {
      if (index + 1 < pathlen && path.charAt(index + 1) != '/') {
        size++;
      }
    }


    String[] seglist = new String[size];
    boolean[] include = new boolean[size];


    // break the path into segments and store in the list
    int current = 0;
    int index2 = 0;
    index = (pathlen > 0 && path.charAt(0) == '/') ? 1 : 0;
    while ((index2 = path.indexOf('/', index + 1)) != -1) {
      seglist[current++] = path.substring(index, index2);
      index = index2 + 1;
    }


    // if current==size, then the last character was a slash
    // and there are no more segments
    if (current < size) {
      seglist[current] = path.substring(index);
    }


    // determine which segments get included in the normalized path
    for (int i = 0; i < size; i++) {
      include[i] = true;
      if (seglist[i].equals("".."")) { //$NON-NLS-1$
        int remove = i - 1;
        // search back to find a segment to remove, if possible
        while (remove > -1 && !include[remove]) {
          remove--;
        }
        // if we find a segment to remove, remove it and the ""..""
        // segment
        if (remove > -1 && !seglist[remove].equals("".."")) { //$NON-NLS-1$
          include[remove] = false;
          include[i] = false;
        }
      } else if (seglist[i].equals(""."")) { //$NON-NLS-1$
        include[i] = false;
      }
    }


    // put the path back together
    StringBuilder newpath = new StringBuilder();
    if (path.startsWith(""/"")) { //$NON-NLS-1$
      newpath.append('/');
    }


    for (int i = 0; i < seglist.length; i++) {
      if (include[i]) {
        newpath.append(seglist[i]);
        newpath.append('/');
      }
    }


    // if we used at least one segment and the path previously ended with
    // a slash and the last segment is still used, then delete the extra
    // trailing '/'
    if (!path.endsWith(""/"") && seglist.length > 0 //$NON-NLS-1$
        && include[seglist.length - 1]) {
      newpath.deleteCharAt(newpath.length() - 1);
    }


    String result = newpath.toString();


    // check for a ':' in the first segment if one exists,
    // prepend ""./"" to normalize
    index = result.indexOf(':');
    index2 = result.indexOf('/');
    if (index != -1 && (index < index2 || index2 == -1)) {
      newpath.insert(0, ""./""); //$NON-NLS-1$
      result = newpath.toString();
    }
    return result;
  }",1,10817
"    public synchronized void start(BundleContext context) throws Exception
    {
        PermissionAdminImpl pai = null;


        SecureAction action = new SecureAction();


        Permissions permissions = new Permissions(context, action);


        File tmp = context.getDataFile(""security"" + File.separator + ""tmp"");
        if ((tmp == null) || (!tmp.isDirectory() && !tmp.mkdirs()))
        {
            throw new IOException(""Can't create tmp dir."");
        }
        // TODO: log something if we can not clean-up the tmp dir
        File[] old = tmp.listFiles();
        if (old != null)
        {
            for (int i = 0; i < old.length; i++)
            {
                old[i].delete();
            }
        }


        if (""TRUE"".equalsIgnoreCase(getProperty(context,
            SecurityConstants.ENABLE_PERMISSIONADMIN_PROP,
            SecurityConstants.ENABLE_PERMISSIONADMIN_VALUE)))
        {
            File cache = context.getDataFile(""security"" + File.separator
                + ""pa.txt"");
            if ((cache == null) || (!cache.isFile() && !cache.createNewFile()))
            {
                throw new IOException(""Can't create cache file"");
            }
            pai = new PermissionAdminImpl(permissions, new PropertiesCache(
                cache, tmp, action));
        }


        ConditionalPermissionAdminImpl cpai = null;


        if (""TRUE"".equalsIgnoreCase(getProperty(context,
            SecurityConstants.ENABLE_CONDPERMADMIN_PROP,
            SecurityConstants.ENABLE_CONDPERMADMIN_VALUE)))
        {
            File cpaCache = context.getDataFile(""security"" + File.separator
                + ""cpa.txt"");
            if ((cpaCache == null)
                || (!cpaCache.isFile() && !cpaCache.createNewFile()))
            {
                throw new IOException(""Can't create cache file"");
            }


            LocalPermissions localPermissions = new LocalPermissions(
                permissions);


            cpai = new ConditionalPermissionAdminImpl(permissions,
                new Conditions(action), localPermissions, new PropertiesCache(
                    cpaCache, tmp, action), pai);
        }


        if ((pai != null) || (cpai != null))
        {
            String crlList = getProperty(context,
                SecurityConstants.CRL_FILE_PROP,
                SecurityConstants.CRL_FILE_VALUE);
            String storeList = getProperty(context,
                SecurityConstants.KEYSTORE_FILE_PROP,
                SecurityConstants.KEYSTORE_FILE_VALUE);
            String passwdList = getProperty(context,
                SecurityConstants.KEYSTORE_PASS_PROP,
                SecurityConstants.KEYSTORE_PASS_VALUE);
            String typeList = getProperty(context,
                SecurityConstants.KEYSTORE_TYPE_PROP,
                SecurityConstants.KEYSTORE_TYPE_VALUE);
            String osgi_keystores = getProperty(context,
                Constants.FRAMEWORK_TRUST_REPOSITORIES, null);
            if (osgi_keystores != null)
            {
                StringTokenizer tok = new StringTokenizer(osgi_keystores,
                    File.pathSeparator);


                if (storeList.length() == 0)
                {
                    storeList += ""file:"" + tok.nextToken();
                    passwdList += "" "";
                    typeList += ""JKS"";
                }
                while (tok.hasMoreTokens())
                {
                    storeList += ""|file:"" + tok.nextToken();
                    passwdList += ""| "";
                    typeList += ""|JKS"";
                }
            }


            StringTokenizer storeTok = new StringTokenizer(storeList, ""|"");
            StringTokenizer passwdTok = new StringTokenizer(passwdList, ""|"");
            StringTokenizer typeTok = new StringTokenizer(typeList, ""|"");


            if ((storeTok.countTokens() != typeTok.countTokens())
                || (passwdTok.countTokens() != storeTok.countTokens()))
            {
                throw new BundleException(
                    ""Each CACerts keystore must have one type and one passwd entry and vice versa."");
            }


            SecurityProvider provider = new SecurityProviderImpl(crlList,
                typeList, passwdList, storeList, pai, cpai, action, ((Felix) context.getBundle(0)).getLogger());


            ((Felix) context.getBundle(0)).setSecurityProvider(provider);
        }


        if (pai != null)
        {
            context.registerService(PermissionAdmin.class.getName(), pai, null);
        }


        if (cpai != null)
        {
            context.registerService(ConditionalPermissionAdmin.class.getName(),
                cpai, null);
        }
    }",1,10839
"  @Override
  public java.lang.String toString() {
    java.lang.StringBuilder sb = new java.lang.StringBuilder(""SupervisorInfo("");
    boolean first = true;


    sb.append(""time_secs:"");
    sb.append(this.time_secs);
    first = false;
    if (!first) sb.append("", "");
    sb.append(""hostname:"");
    if (this.hostname == null) {
      sb.append(""null"");
    } else {
      sb.append(this.hostname);
    }
    first = false;
    if (is_set_assignment_id()) {
      if (!first) sb.append("", "");
      sb.append(""assignment_id:"");
      if (this.assignment_id == null) {
        sb.append(""null"");
      } else {
        sb.append(this.assignment_id);
      }
      first = false;
    }
    if (is_set_used_ports()) {
      if (!first) sb.append("", "");
      sb.append(""used_ports:"");
      if (this.used_ports == null) {
        sb.append(""null"");
      } else {
        sb.append(this.used_ports);
      }
      first = false;
    }
    if (is_set_meta()) {
      if (!first) sb.append("", "");
      sb.append(""meta:"");
      if (this.meta == null) {
        sb.append(""null"");
      } else {
        sb.append(this.meta);
      }
      first = false;
    }
    if (is_set_scheduler_meta()) {
      if (!first) sb.append("", "");
      sb.append(""scheduler_meta:"");
      if (this.scheduler_meta == null) {
        sb.append(""null"");
      } else {
        sb.append(this.scheduler_meta);
      }
      first = false;
    }
    if (is_set_uptime_secs()) {
      if (!first) sb.append("", "");
      sb.append(""uptime_secs:"");
      sb.append(this.uptime_secs);
      first = false;
    }
    if (is_set_version()) {
      if (!first) sb.append("", "");
      sb.append(""version:"");
      if (this.version == null) {
        sb.append(""null"");
      } else {
        sb.append(this.version);
      }
      first = false;
    }
    if (is_set_resources_map()) {
      if (!first) sb.append("", "");
      sb.append(""resources_map:"");
      if (this.resources_map == null) {
        sb.append(""null"");
      } else {
        sb.append(this.resources_map);
      }
      first = false;
    }
    if (is_set_server_port()) {
      if (!first) sb.append("", "");
      sb.append(""server_port:"");
      sb.append(this.server_port);
      first = false;
    }
    sb.append("")"");
    return sb.toString();
  }",1,10965
"    public synchronized void start(BundleContext context) throws Exception
    {
        PermissionAdminImpl pai = null;


        SecureAction action = new SecureAction();


        Permissions permissions = new Permissions(context, action);


        File tmp = context.getDataFile(""security"" + File.separator + ""tmp"");
        if ((tmp == null) || (!tmp.isDirectory() && !tmp.mkdirs()))
        {
            throw new IOException(""Can't create tmp dir."");
        }
        // TODO: log something if we can not clean-up the tmp dir
        File[] old = tmp.listFiles();
        if (old != null)
        {
            for (int i = 0; i < old.length; i++)
            {
                old[i].delete();
            }
        }


        if (""TRUE"".equalsIgnoreCase(getProperty(context,
            SecurityConstants.ENABLE_PERMISSIONADMIN_PROP,
            SecurityConstants.ENABLE_PERMISSIONADMIN_VALUE)))
        {
            File cache = context.getDataFile(""security"" + File.separator
                + ""pa.txt"");
            if ((cache == null) || (!cache.isFile() && !cache.createNewFile()))
            {
                throw new IOException(""Can't create cache file"");
            }
            pai = new PermissionAdminImpl(permissions, new PropertiesCache(
                cache, tmp, action));
        }


        ConditionalPermissionAdminImpl cpai = null;


        if (""TRUE"".equalsIgnoreCase(getProperty(context,
            SecurityConstants.ENABLE_CONDPERMADMIN_PROP,
            SecurityConstants.ENABLE_CONDPERMADMIN_VALUE)))
        {
            File cpaCache = context.getDataFile(""security"" + File.separator
                + ""cpa.txt"");
            if ((cpaCache == null)
                || (!cpaCache.isFile() && !cpaCache.createNewFile()))
            {
                throw new IOException(""Can't create cache file"");
            }


            LocalPermissions localPermissions = new LocalPermissions(
                permissions);


            cpai = new ConditionalPermissionAdminImpl(permissions,
                new Conditions(action), localPermissions, new PropertiesCache(
                    cpaCache, tmp, action), pai);
        }


        if ((pai != null) || (cpai != null))
        {
            String crlList = getProperty(context,
                SecurityConstants.CRL_FILE_PROP,
                SecurityConstants.CRL_FILE_VALUE);
            String storeList = getProperty(context,
                SecurityConstants.KEYSTORE_FILE_PROP,
                SecurityConstants.KEYSTORE_FILE_VALUE);
            String passwdList = getProperty(context,
                SecurityConstants.KEYSTORE_PASS_PROP,
                SecurityConstants.KEYSTORE_PASS_VALUE);
            String typeList = getProperty(context,
                SecurityConstants.KEYSTORE_TYPE_PROP,
                SecurityConstants.KEYSTORE_TYPE_VALUE);
            String osgi_keystores = getProperty(context,
                Constants.FRAMEWORK_TRUST_REPOSITORIES, null);
            if (osgi_keystores != null)
            {
                StringTokenizer tok = new StringTokenizer(osgi_keystores,
                    File.pathSeparator);


                if (storeList.length() == 0)
                {
                    storeList += ""file:"" + tok.nextToken();
                    passwdList += "" "";
                    typeList += ""JKS"";
                }
                while (tok.hasMoreTokens())
                {
                    storeList += ""|file:"" + tok.nextToken();
                    passwdList += ""| "";
                    typeList += ""|JKS"";
                }
            }


            StringTokenizer storeTok = new StringTokenizer(storeList, ""|"");
            StringTokenizer passwdTok = new StringTokenizer(passwdList, ""|"");
            StringTokenizer typeTok = new StringTokenizer(typeList, ""|"");


            if ((storeTok.countTokens() != typeTok.countTokens())
                || (passwdTok.countTokens() != storeTok.countTokens()))
            {
                throw new BundleException(
                    ""Each CACerts keystore must have one type and one passwd entry and vice versa."");
            }


            SecurityProvider provider = new SecurityProviderImpl(crlList,
                typeList, passwdList, storeList, pai, cpai, action, ((Felix) context.getBundle(0)).getLogger());


            ((Felix) context.getBundle(0)).setSecurityProvider(provider);
        }


        if (pai != null)
        {
            context.registerService(PermissionAdmin.class.getName(), pai, null);
        }


        if (cpai != null)
        {
            context.registerService(ConditionalPermissionAdmin.class.getName(),
                cpai, null);
        }
    }",1,11110
"    protected void refreshInternal(Collection objs, OpCallbacks call) {
    	if (objs == null || objs.isEmpty())
    		return;
        List<Exception> exceps = null;
        try {
            // collect instances that need a refresh
            Collection<OpenJPAStateManager> load = null;
            StateManagerImpl sm;
            Object obj;
            for (Iterator<?> itr = objs.iterator(); itr.hasNext();) {
                obj = itr.next();
                if (obj == null)
                    continue;


                try {
                    sm = getStateManagerImpl(obj, true);
                    if ((processArgument(OpCallbacks.OP_REFRESH, obj, sm, call)
                        & OpCallbacks.ACT_RUN) == 0)
                        continue;


                    if (sm != null) {
                        if (sm.isDetached())
                            throw newDetachedException(obj, ""refresh"");
                        else if (sm.beforeRefresh(true)) {
                        	if (load == null)
                        		load = new ArrayList<>(objs.size());
                            load.add(sm);
                        }
                        int level = _fc.getReadLockLevel();
                        int timeout = _fc.getLockTimeout();
                        _lm.refreshLock(sm, level, timeout, null);
                        sm.readLocked(level, level);
                    } else if (assertPersistenceCapable(obj).pcIsDetached()
                        == Boolean.TRUE)
                        throw newDetachedException(obj, ""refresh"");
                } catch (OpenJPAException ke) {
                    exceps = add(exceps, ke);
                }
            }


            // refresh all
            if (load != null) {
                Collection<Object> failed = _store.loadAll(load, null,
                    StoreManager.FORCE_LOAD_REFRESH, _fc, null);
                if (failed != null && !failed.isEmpty())
                    exceps = add(exceps, newObjectNotFoundException(failed));


                // perform post-refresh transitions and make sure all fetch
                // group fields are loaded
                for (Iterator<OpenJPAStateManager> itr = load.iterator(); itr.hasNext();) {
                    sm = (StateManagerImpl) itr.next();
                    if (failed != null && failed.contains(sm.getId()))
                        continue;


                    try {
                        sm.afterRefresh();
                        sm.load(_fc, StateManagerImpl.LOAD_FGS, null, null,
                            false);
                    } catch (OpenJPAException ke) {
                        exceps = add(exceps, ke);
                    }
                }
            }


            // now invoke postRefresh on all the instances
            for (Iterator<?> itr = objs.iterator(); itr.hasNext();) {
                try {
                    sm = getStateManagerImpl(itr.next(), true);
                    if (sm != null && !sm.isDetached())
                        fireLifecycleEvent(sm.getManagedInstance(), null,
                            sm.getMetaData(), LifecycleEvent.AFTER_REFRESH);
                } catch (OpenJPAException ke) {
                    exceps = add(exceps, ke);
                }
            }
        } catch (OpenJPAException ke) {
            throw ke;
        } catch (RuntimeException re) {
            throw new GeneralException(re);
        }
        throwNestedExceptions(exceps, false);
    }",1,11135
"		@Override
		@Nullable
		public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
			// Invocation on EntityManager interface coming in...


			if (method.getName().equals(""equals"")) {
				// Only consider equal when proxies are identical.
				return (proxy == args[0]);
			}
			else if (method.getName().equals(""hashCode"")) {
				// Use hashCode of EntityManager proxy.
				return hashCode();
			}
			else if (method.getName().equals(""toString"")) {
				// Deliver toString without touching a target EntityManager.
				return ""Shared EntityManager proxy for target factory ["" + this.targetFactory + ""]"";
			}
			else if (method.getName().equals(""getEntityManagerFactory"")) {
				// JPA 2.0: return EntityManagerFactory without creating an EntityManager.
				return this.targetFactory;
			}
			else if (method.getName().equals(""getCriteriaBuilder"") || method.getName().equals(""getMetamodel"")) {
				// JPA 2.0: return EntityManagerFactory's CriteriaBuilder/Metamodel (avoid creation of EntityManager)
				try {
					return EntityManagerFactory.class.getMethod(method.getName()).invoke(this.targetFactory);
				}
				catch (InvocationTargetException ex) {
					throw ex.getTargetException();
				}
			}
			else if (method.getName().equals(""unwrap"")) {
				// JPA 2.0: handle unwrap method - could be a proxy match.
				Class<?> targetClass = (Class<?>) args[0];
				if (targetClass != null && targetClass.isInstance(proxy)) {
					return proxy;
				}
			}
			else if (method.getName().equals(""isOpen"")) {
				// Handle isOpen method: always return true.
				return true;
			}
			else if (method.getName().equals(""close"")) {
				// Handle close method: suppress, not valid.
				return null;
			}
			else if (method.getName().equals(""getTransaction"")) {
				throw new IllegalStateException(
						""Not allowed to create transaction on shared EntityManager - "" +
						""use Spring transactions or EJB CMT instead"");
			}


			// Determine current EntityManager: either the transactional one
			// managed by the factory or a temporary one for the given invocation.
			EntityManager target = EntityManagerFactoryUtils.doGetTransactionalEntityManager(
					this.targetFactory, this.properties, this.synchronizedWithTransaction);


			if (method.getName().equals(""getTargetEntityManager"")) {
				// Handle EntityManagerProxy interface.
				if (target == null) {
					throw new IllegalStateException(""No transactional EntityManager available"");
				}
				return target;
			}
			else if (method.getName().equals(""unwrap"")) {
				Class<?> targetClass = (Class<?>) args[0];
				if (targetClass == null) {
					return (target != null ? target : proxy);
				}
				// We need a transactional target now.
				if (target == null) {
					throw new IllegalStateException(""No transactional EntityManager available"");
				}
				// Still perform unwrap call on target EntityManager.
			}
			else if (transactionRequiringMethods.contains(method.getName())) {
				// We need a transactional target now, according to the JPA spec.
				// Otherwise, the operation would get accepted but remain unflushed...
				if (target == null || (!TransactionSynchronizationManager.isActualTransactionActive() &&
						!target.getTransaction().isActive())) {
					throw new TransactionRequiredException(""No EntityManager with actual transaction available "" +
							""for current thread - cannot reliably process '"" + method.getName() + ""' call"");
				}
			}


			// Regular EntityManager operations.
			boolean isNewEm = false;
			if (target == null) {
				logger.debug(""Creating new EntityManager for shared EntityManager invocation"");
				target = (!CollectionUtils.isEmpty(this.properties) ?
						this.targetFactory.createEntityManager(this.properties) :
						this.targetFactory.createEntityManager());
				isNewEm = true;
			}


			// Invoke method on current EntityManager.
			try {
				Object result = method.invoke(target, args);
				if (result instanceof Query) {
					Query query = (Query) result;
					if (isNewEm) {
						Class<?>[] ifcs = ClassUtils.getAllInterfacesForClass(query.getClass(), this.proxyClassLoader);
						result = Proxy.newProxyInstance(this.proxyClassLoader, ifcs,
								new DeferredQueryInvocationHandler(query, target));
						isNewEm = false;
					}
					else {
						EntityManagerFactoryUtils.applyTransactionTimeout(query, this.targetFactory);
					}
				}
				return result;
			}
			catch (InvocationTargetException ex) {
				throw ex.getTargetException();
			}
			finally {
				if (isNewEm) {
					EntityManagerFactoryUtils.closeEntityManager(target);
				}
			}
		}",1,11137
"    public String toString() {


        if (subject == null || pubKey == null || interval == null
            || issuer == null || algId == null || serialNum == null) {
                throw new NullPointerException(""X.509 cert is incomplete"");
        }
        StringBuilder sb = new StringBuilder();


        sb.append(""[\n"");
        sb.append(""  "" + version.toString() + ""\n"");
        sb.append(""  Subject: "" + subject.toString() + ""\n"");
        sb.append(""  Signature Algorithm: "" + algId.toString() + ""\n"");
        sb.append(""  Key:  "" + pubKey.toString() + ""\n"");
        sb.append(""  "" + interval.toString() + ""\n"");
        sb.append(""  Issuer: "" + issuer.toString() + ""\n"");
        sb.append(""  "" + serialNum.toString() + ""\n"");


        // optional v2, v3 extras
        if (issuerUniqueId != null) {
            sb.append(""  Issuer Id:\n"" + issuerUniqueId.toString() + ""\n"");
        }
        if (subjectUniqueId != null) {
            sb.append(""  Subject Id:\n"" + subjectUniqueId.toString() + ""\n"");
        }
        if (extensions != null) {
            Collection<Extension> allExts = extensions.getAllExtensions();
            Extension[] exts = allExts.toArray(new Extension[0]);
            sb.append(""\nCertificate Extensions: "" + exts.length);
            for (int i = 0; i < exts.length; i++) {
                sb.append(""\n["" + (i+1) + ""]: "");
                Extension ext = exts[i];
                try {
                    if (OIDMap.getClass(ext.getExtensionId()) == null) {
                        sb.append(ext.toString());
                        byte[] extValue = ext.getExtensionValue();
                        if (extValue != null) {
                            DerOutputStream out = new DerOutputStream();
                            out.putOctetString(extValue);
                            extValue = out.toByteArray();
                            HexDumpEncoder enc = new HexDumpEncoder();
                            sb.append(""Extension unknown: ""
                                      + ""DER encoded OCTET string =\n""
                                      + enc.encodeBuffer(extValue) + ""\n"");
                        }
                    } else
                        sb.append(ext.toString()); //sub-class exists
                } catch (Exception e) {
                    sb.append("", Error parsing this extension"");
                }
            }
            Map<String,Extension> invalid = extensions.getUnparseableExtensions();
            if (invalid.isEmpty() == false) {
                sb.append(""\nUnparseable certificate extensions: "" + invalid.size());
                int i = 1;
                for (Extension ext : invalid.values()) {
                    sb.append(""\n["" + (i++) + ""]: "");
                    sb.append(ext);
                }
            }
        }
        sb.append(""\n]"");
        return sb.toString();
    }",1,11243
"    private JPEGImageMetadataFormat() {
        super(JPEG.nativeImageMetadataFormatName,
              CHILD_POLICY_ALL);


        addElement(""JPEGvariety"",
                   JPEG.nativeImageMetadataFormatName,
                   CHILD_POLICY_CHOICE);


        addElement(""markerSequence"",
                   JPEG.nativeImageMetadataFormatName,
                   CHILD_POLICY_SEQUENCE);


        addElement(""app0JFIF"", ""JPEGvariety"", CHILD_POLICY_SOME);


        addStreamElements(""markerSequence"");


        addElement(""app14Adobe"", ""markerSequence"", CHILD_POLICY_EMPTY);


        addElement(""sof"", ""markerSequence"", 1, 4);


        addElement(""sos"", ""markerSequence"", 1, 4);


        addElement(""JFXX"", ""app0JFIF"", 1, Integer.MAX_VALUE);


        addElement(""app0JFXX"", ""JFXX"", CHILD_POLICY_CHOICE);


        addElement(""app2ICC"", ""app0JFIF"", CHILD_POLICY_EMPTY);


        addAttribute(""app0JFIF"",
                     ""majorVersion"",
                     DATATYPE_INTEGER,
                     false,
                     ""1"",
                     ""0"", ""255"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""minorVersion"",
                     DATATYPE_INTEGER,
                     false,
                     ""2"",
                     ""0"", ""255"",
                     true, true);
        List<String> resUnits = new ArrayList<>();
        resUnits.add(""0"");
        resUnits.add(""1"");
        resUnits.add(""2"");
        addAttribute(""app0JFIF"",
                     ""resUnits"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     resUnits);
        addAttribute(""app0JFIF"",
                     ""Xdensity"",
                     DATATYPE_INTEGER,
                     false,
                     ""1"",
                     ""1"", ""65535"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""Ydensity"",
                     DATATYPE_INTEGER,
                     false,
                     ""1"",
                     ""1"", ""65535"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""thumbWidth"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""255"",
                     true, true);
        addAttribute(""app0JFIF"",
                     ""thumbHeight"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""255"",
                     true, true);


        addElement(""JFIFthumbJPEG"", ""app0JFXX"", CHILD_POLICY_SOME);
        addElement(""JFIFthumbPalette"", ""app0JFXX"", CHILD_POLICY_EMPTY);
        addElement(""JFIFthumbRGB"", ""app0JFXX"", CHILD_POLICY_EMPTY);


        List<String> codes = new ArrayList<>();
        codes.add(""16""); // Hex 10
        codes.add(""17""); // Hex 11
        codes.add(""19""); // Hex 13
        addAttribute(""app0JFXX"",
                     ""extensionCode"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     codes);


        addChildElement(""markerSequence"", ""JFIFthumbJPEG"");


        addAttribute(""JFIFthumbPalette"",
                     ""thumbWidth"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""JFIFthumbPalette"",
                     ""thumbHeight"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);


        addAttribute(""JFIFthumbRGB"",
                     ""thumbWidth"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""JFIFthumbRGB"",
                     ""thumbHeight"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""255"",
                     true, true);


        addObjectValue(""app2ICC"", ICC_Profile.class, false, null);


        addAttribute(""app14Adobe"",
                     ""version"",
                     DATATYPE_INTEGER,
                     false,
                     ""100"",
                     ""100"", ""255"",
                     true, true);
        addAttribute(""app14Adobe"",
                     ""flags0"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""65535"",
                     true, true);
        addAttribute(""app14Adobe"",
                     ""flags1"",
                     DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""65535"",
                     true, true);


        List<String> transforms = new ArrayList<>();
        transforms.add(""0"");
        transforms.add(""1"");
        transforms.add(""2"");
        addAttribute(""app14Adobe"",
                     ""transform"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     transforms);


        addElement(""componentSpec"", ""sof"", CHILD_POLICY_EMPTY);


        List<String> procs = new ArrayList<>();
        procs.add(""0"");
        procs.add(""1"");
        procs.add(""2"");
        addAttribute(""sof"",
                     ""process"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     procs);
        addAttribute(""sof"",
                     ""samplePrecision"",
                     DATATYPE_INTEGER,
                     false,
                     ""8"");
        addAttribute(""sof"",
                     ""numLines"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""65535"",
                     true, true);
        addAttribute(""sof"",
                     ""samplesPerLine"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     ""0"", ""65535"",
                     true, true);
        List<String> comps = new ArrayList<>();
        comps.add(""1"");
        comps.add(""2"");
        comps.add(""3"");
        comps.add(""4"");
        addAttribute(""sof"",
                     ""numFrameComponents"",
                     DATATYPE_INTEGER,
                     false,
                     null,
                     comps);


        addAttribute(""componentSpec"",
                     ""componentId"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""componentSpec"",
                     ""HsamplingFactor"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""1"", ""255"",
                     true, true);
        addAttribute(""componentSpec"",
                     ""VsamplingFactor"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""1"", ""255"",
                     true, true);
        List<String> tabids = new ArrayList<>();
        tabids.add(""0"");
        tabids.add(""1"");
        tabids.add(""2"");
        tabids.add(""3"");
        addAttribute(""componentSpec"",
                     ""QtableSelector"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     tabids);


        addElement(""scanComponentSpec"", ""sos"", CHILD_POLICY_EMPTY);


        addAttribute(""sos"",
                     ""numScanComponents"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     comps);
        addAttribute(""sos"",
                     ""startSpectralSelection"",
                      DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""63"",
                     true, true);
        addAttribute(""sos"",
                     ""endSpectralSelection"",
                      DATATYPE_INTEGER,
                     false,
                     ""63"",
                     ""0"", ""63"",
                     true, true);
        addAttribute(""sos"",
                     ""approxHigh"",
                      DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""15"",
                     true, true);
        addAttribute(""sos"",
                     ""approxLow"",
                      DATATYPE_INTEGER,
                     false,
                     ""0"",
                     ""0"", ""15"",
                     true, true);


        addAttribute(""scanComponentSpec"",
                     ""componentSelector"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     ""0"", ""255"",
                     true, true);
        addAttribute(""scanComponentSpec"",
                     ""dcHuffTable"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     tabids);
        addAttribute(""scanComponentSpec"",
                     ""acHuffTable"",
                     DATATYPE_INTEGER,
                     true,
                     null,
                     tabids);
    }",1,11256
"    @Override
    ValueNode preprocess(int numTables,
								FromList outerFromList,
								SubqueryList outerSubqueryList,
								PredicateList outerPredicateList) 
					throws StandardException
	{
		/* Only preprocess this node once.  We may get called multiple times
		 * due to tree transformations.
		 */
		if (preprocessed)
		{
			return this;
		}
		preprocessed = true;


		boolean		flattenable;
		ValueNode	topNode = this;


        final boolean haveOrderBy; // need to remember for flattening decision


        // Push the order by list down to the ResultSet
        if (orderByList != null) {
            haveOrderBy = true;
            // If we have more than 1 ORDERBY columns, we may be able to
            // remove duplicate columns, e.g., ""ORDER BY 1, 1, 2"".
            if (orderByList.size() > 1)
            {
                orderByList.removeDupColumns();
            }


            resultSet.pushOrderByList(orderByList);
            orderByList = null;
        } else {
            haveOrderBy = false;
        }


        resultSet = resultSet.preprocess(numTables, null, (FromList) null);


        if (leftOperand != null)
        {
            leftOperand = leftOperand.preprocess(numTables,
                    outerFromList, outerSubqueryList, outerPredicateList);
        }


		// Eliminate any unnecessary DISTINCTs
		if (resultSet instanceof SelectNode)
		{
			if (((SelectNode) resultSet).hasDistinct())
			{
				((SelectNode) resultSet).clearDistinct();
				/* We need to remember to check for single unique value
				 * at execution time for expression subqueries.
				 */
				if  (subqueryType == EXPRESSION_SUBQUERY)
				{
					distinctExpression = true;
				}
			}
		}


		/* Lame transformation - For IN/ANY subqueries, if
		 * result set is guaranteed to return at most 1 row
		 * and it is not correlated
		 * then convert the subquery into the matching expression
		 * subquery type.  For example:
		 *	c1 in (select min(c1) from t2)
		 * becomes:
		 *	c1 = (select min(c1) from t2)
		 * (This actually showed up in an app that a potential customer
		 * was porting from SQL Server.)
		 * The transformed query can then be flattened if appropriate.
		 */
		if ((isIN() || isANY()) &&
			resultSet.returnsAtMostOneRow())
		{
			if (! hasCorrelatedCRs())
			{
				changeToCorrespondingExpressionType();
			}
		}


		/* NOTE: Flattening occurs before the pushing of
		 * the predicate, since the pushing will add a node 
		 * above the SubqueryNode.
		 */


		/* Values subquery is flattenable if:
		 *  o It is not under an OR.
         *  o It is not a subquery in a having clause (DERBY-3257)
		 *  o It is an expression subquery on the right side
		 *	  of a BinaryComparisonOperatorNode.
		 *  o Either a) it does not appear within a WHERE clause, or 
		 *           b) it appears within a WHERE clause but does not itself 
		 *              contain a WHERE clause with other subqueries in it. 
		 *          (DERBY-3301)
		 */
		flattenable = (resultSet instanceof RowResultSetNode) &&
					  underTopAndNode && !havingSubquery &&
                      !haveOrderBy &&
                      offset == null &&
                      fetchFirst == null &&
					  !isWhereExistsAnyInWithWhereSubquery() &&
                      parentComparisonOperator != null;


		if (flattenable)
		{
			/* If we got this far and we are an expression subquery
			 * then we want to set leftOperand to be the left side
			 * of the comparison in case we pull the comparison into
			 * the flattened subquery.
			 */
			leftOperand = parentComparisonOperator.getLeftOperand();
			// Flatten the subquery
			RowResultSetNode rrsn = (RowResultSetNode) resultSet;
            FromList fl = new FromList(getContextManager());


			// Remove ourselves from the outer subquery list
			outerSubqueryList.removeElement(this);


			/* We only need to add the table from the subquery into 
			 * the outer from list if the subquery itself contains
			 * another subquery.  Otherwise, it just becomes a constant.
			 */
			if (rrsn.subquerys.size() != 0)
			{
				fl.addElement(rrsn);
				outerFromList.destructiveAppend(fl);
			}


			/* Append the subquery's subquery list to the 
			 * outer subquery list.
			 */
			outerSubqueryList.destructiveAppend(rrsn.subquerys);


			/* return the new join condition 
			 * If we are flattening an EXISTS then there is no new join
			 * condition since there is no leftOperand.  Simply return
			 * TRUE.
			 *
			 * NOTE: The outer where clause, etc. has already been normalized,
			 * so we simply return the BinaryComparisonOperatorNode above
			 * the new join condition.
			 */
			return getNewJoinCondition(leftOperand, getRightOperand());
		}


		/* Select subquery is flattenable if:
		 *  o It is not under an OR.
		 *  o The subquery type is IN, ANY or EXISTS or
		 *    an expression subquery on the right side
		 *	  of a BinaryComparisonOperatorNode.
		 *  o There are no aggregates in the select list
		 *  o There is no group by clause or having clause.
		 *  o There is a uniqueness condition that ensures
		 *	  that the flattening of the subquery will not
		 *	  introduce duplicates into the result set.
         *  o The subquery is not part of a having clause (DERBY-3257)
		 *  o There are no windows defined on it
		 *
		 *	OR,
		 *  o The subquery is NOT EXISTS, NOT IN, ALL (beetle 5173).
		 *  o Either a) it does not appear within a WHERE clause, or 
		 *           b) it appears within a WHERE clause but does not itself 
		 *              contain a WHERE clause with other subqueries in it. 
		 *          (DERBY-3301)
		 */
		boolean flattenableNotExists = (isNOT_EXISTS() || canAllBeFlattened());


		flattenable = (resultSet instanceof SelectNode) &&
 			          !((SelectNode)resultSet).hasWindows() &&
                      !haveOrderBy &&
                      offset == null &&
                      fetchFirst == null &&
					  underTopAndNode && !havingSubquery &&
					  !isWhereExistsAnyInWithWhereSubquery() &&
					  (isIN() || isANY() || isEXISTS() || flattenableNotExists ||
                       parentComparisonOperator != null);


		if (flattenable)
		{
			SelectNode	select = (SelectNode) resultSet;
			if ((!select.hasAggregatesInSelectList()) &&
			    (select.havingClause == null))
			{
				ValueNode origLeftOperand = leftOperand;


				/* Check for uniqueness condition. */
				/* Is the column being returned by the subquery
				 * a candidate for an = condition?
				 */
				boolean additionalEQ =
							(subqueryType == IN_SUBQUERY) ||
							(subqueryType == EQ_ANY_SUBQUERY);




				additionalEQ = additionalEQ &&
								((leftOperand instanceof ConstantNode) ||
								 (leftOperand instanceof ColumnReference) ||
								 (leftOperand.requiresTypeFromContext()));
				/* If we got this far and we are an expression subquery
				 * then we want to set leftOperand to be the left side
				 * of the comparison in case we pull the comparison into
				 * the flattened subquery.
				 */
                if (parentComparisonOperator != null)
				{
					leftOperand = parentComparisonOperator.getLeftOperand();
				}
				/* Never flatten to normal join for NOT EXISTS.
				 */


				if ((! flattenableNotExists) && select.uniqueSubquery(additionalEQ))
				{
					// Flatten the subquery
					return flattenToNormalJoin(numTables,
										   outerFromList, outerSubqueryList,
										   outerPredicateList);
				}
				/* We can flatten into an EXISTS join if all of the above
				 * conditions except for a uniqueness condition are true
				 * and:
				 *	o Subquery only has a single entry in its from list
				 *	  and that entry is a FromBaseTable
				 *	o All predicates in the subquery's where clause are
				 *	  pushable.
				 *  o The leftOperand, if non-null, is pushable.
				 * If the subquery meets these conditions then we will flatten
				 * the FBT into an EXISTS FBT, pushd the subquery's
				 * predicates down to the PRN above the EBT and
				 * mark the predicates to say that they cannot be pulled 
				 * above the PRN. (The only way that we can guarantee correctness
				 * is if the predicates do not get pulled up.  If they get pulled
				 * up then the single next logic for an EXISTS join does not work
				 * because that row may get disqualified at a higher level.)
                 * DERBY-4001: Extra conditions to allow flattening to a NOT
                 * EXISTS join (in a NOT EXISTS join it does matter on which
                 * side of the join predicates/restrictions are applied):
                 *  o All the predicates must reference the FBT, otherwise
                 *    predicates meant for the right side of the join may be
                 *    applied to the left side of the join.
                 *  o The right operand (in ALL and NOT IN) must reference the
                 *    FBT, otherwise the generated join condition may be used
                 *    to restrict the left side of the join.
				 */
				else if ( (isIN() || isANY() || isEXISTS() || flattenableNotExists) &&
						  ((leftOperand == null) ? true :
							 leftOperand.categorize(new JBitSet(numTables), false)) &&
						  select.getWherePredicates().allPushable())
				{
                    FromBaseTable fbt =
                            singleFromBaseTable(select.getFromList());


                    if (fbt != null && (!flattenableNotExists ||
                         (select.getWherePredicates().allReference(fbt) &&
                          rightOperandFlattenableToNotExists(numTables, fbt))))
                    {
                        return flattenToExistsJoin(numTables,
                                outerFromList, outerSubqueryList,
                                outerPredicateList, flattenableNotExists);
                    }
				}


				// restore leftOperand to its original value
				leftOperand = origLeftOperand;
			}
		}


        resultSet.pushQueryExpressionSuffix();


        resultSet.pushOffsetFetchFirst( offset, fetchFirst, hasJDBClimitClause );


		/* We transform the leftOperand and the select list for quantified 
		 * predicates that have a leftOperand into a new predicate and push it
		 * down to the subquery after we preprocess the subquery's resultSet.
		 * We must do this after preprocessing the underlying subquery so that
		 * we know where to attach the new predicate.
		 * NOTE - If we pushed the predicate before preprocessing the underlying
		 * subquery, then the point of attachment would depend on the form of
		 * that subquery.  (Where clause?  Having clause?)
		 */
		if (leftOperand != null)
		{
			topNode = pushNewPredicate(numTables);
			pushedNewPredicate = true;
		}
        /* EXISTS and NOT EXISTS subqueries that haven't been flattened, need
         * an IS [NOT] NULL node on top so that they return a BOOLEAN. Other
         * cases are taken care of in pushNewPredicate.
		 */
        else if (isEXISTS() || isNOT_EXISTS())
		{
            topNode = genIsNullTree(isEXISTS());
			subqueryType = EXISTS_SUBQUERY;
		}


		/*
		** Do inVariant and correlated checks now.  We
		** aren't going to use the results here, but they
		** have been stashed away by isInvariant() and hasCorrelatedCRs()
		*/
		isInvariant();
		hasCorrelatedCRs();


		/* If parentComparisonOperator is non-null then we are an
		 * expression subquery that was considered to be a candidate 
		 * for flattening, but we didn't get flattened.  In that case
		 * we are the rightOperand of the parent.  We need to update
		 * the parent's rightOperand with the new topNode and return
		 * the parent because the parent is letting us decide whether
		 * or not to replace the entire comparison, which we can do
		 * if we flatten.  Otherwise we simply return the new top node.
		 */
		if (parentComparisonOperator != null)
		{
			parentComparisonOperator.setRightOperand(topNode);
			return parentComparisonOperator;
		}


		return topNode;
	}",1,11359
"  private int addManualRecord(Airing recAir, UIClient uiClient)
  {
    // Check to make sure we have an encoder that can receive this station
    Set<EncoderState> tryUs = new HashSet<EncoderState>(encoderStateMap.values());
    Iterator<EncoderState> walker = tryUs.iterator();
    // We only need to worry about conflicts with other recordings that occur within the same set of stations. If
    // encoder A has no intersection with the stations on encoder B; then there's no reason to prompt about conflicts from
    // that tuner since it won't help resolve scheduling issues. So this set will be all the stations that either directly or
    // indirectly could resolve a conflict with the new recording.
    // Due to the indirect nature of this; we have to keep checking through the encoders until this set stops growing in size
    Set<Integer> unifiedStationSet = new HashSet<Integer>();
    boolean encoderExists = false;
    while (walker.hasNext())
    {
      EncoderState es = walker.next();
      synchronized (es.stationSet) {
        if (es.stationSet.contains(recAir.stationID))
        {
          encoderExists = true;
          unifiedStationSet.addAll(es.stationSet);
          walker.remove(); // to avoid redundant checking below
          break;
        }
      }
    }
    if (!encoderExists)
      return VideoFrame.WATCH_FAILED_NO_ENCODERS_HAVE_STATION;


    int lastSetSize;
    do
    {
      lastSetSize = unifiedStationSet.size();
      walker = tryUs.iterator();
      while (walker.hasNext())
      {
        EncoderState es = walker.next();
        synchronized (es.stationSet) {
          if (unifiedStationSet.removeAll(es.stationSet))
          {
            // There was an intersection, so use all of these stations, then ignore this one for later
            unifiedStationSet.addAll(es.stationSet);
            walker.remove();
          }
        }
      }


    } while (lastSetSize != unifiedStationSet.size() && !tryUs.isEmpty());


    long defaultStartPadding = Sage.getLong(""default_mr_start_padding"", 0);
    long defaultStopPadding = Sage.getLong(""default_mr_stop_padding"", 0);
    long requestedStart = recAir.getStartTime() - defaultStartPadding;
    long requestedStop = recAir.getEndTime() + defaultStopPadding;
    long requestedDuration = requestedStop - requestedStart;


    Airing schedAir = recAir;
    if (defaultStartPadding != 0 || defaultStopPadding != 0)
    {
      schedAir = new Airing(0);
      schedAir.time = requestedStart;
      schedAir.duration = requestedDuration;
      schedAir.stationID = recAir.stationID;
      schedAir.showID = recAir.showID;
    }
    Vector<Airing> parallelRecords = new Vector<Airing>();
    Vector<Airing> lastParallel = null;
    do
    {
      parallelRecords.clear();
      ManualRecord[] manualMustSee = wiz.getManualRecordsSortedByTime();
      Vector<ManualRecord> parallelRecurs = new Vector<ManualRecord>();
      for (int i = 0; i < manualMustSee.length; i++)
      {
        ManualRecord currRec = manualMustSee[i];
        if (currRec.getContentAiring() == recAir)
          return VideoFrame.WATCH_OK;
        if (currRec.getEndTime() <= Sage.time()) continue;
        if (currRec.doRecurrencesOverlap(requestedStart, requestedDuration, 0))
        {
          parallelRecords.addElement(manualMustSee[i].getSchedulingAiring());
          if (currRec.recur != 0)
            parallelRecurs.add(currRec);
          else
            parallelRecurs.add(null);
        }
      }


      if (parallelRecords.isEmpty()) break;


      parallelRecords.addElement(schedAir);
      parallelRecurs.add(null);
      if (sched.testMultiTunerSchedulingPermutation(parallelRecords))
        break;
      // Remove any recurrence duplicates from the parallel list that is presented to the user
      for (int i = 0; i < parallelRecurs.size(); i++)
      {
        ManualRecord currRecur = parallelRecurs.get(i);
        if (currRecur == null) continue;
        for (int j = 0; j < parallelRecords.size(); j++)
        {
          if (i == j || parallelRecurs.get(j) == null) continue;


          ManualRecord otherRecur = parallelRecurs.get(j);
          if (currRecur.stationID == otherRecur.stationID && currRecur.duration == otherRecur.duration &&
              currRecur.recur == otherRecur.recur && currRecur.isSameRecurrence(otherRecur.startTime))
          {
            parallelRecurs.remove(j);
            parallelRecords.remove(j);
            j--;
          }
        }
      }


      // Conflict exists, we need to kill a recording that's on an encoder that's capable
      // of recording this
      // Conflict resolution, ask about what you're going to kill
      parallelRecords.remove(schedAir);


      // Remove any items from the conflict options that would not end up in station set overlap either directly or indirectly
      for (int i = 0; i < parallelRecords.size(); i++)
        if (!unifiedStationSet.contains(parallelRecords.get(i).stationID))
          parallelRecords.remove(i--);


      // If we have the same conflicts as when we just checked, then bail. Most likely they
      // aren't processing the Hook correctly and we'll be in an infinite loop.
      if (lastParallel != null && parallelRecords.equals(lastParallel))
        return VideoFrame.WATCH_FAILED_USER_REJECTED_CONFLICT;
      Object hookRes = (uiClient == null) ? null : uiClient.processUIClientHook(""RecordRequestScheduleConflict"", new Object[] { recAir, parallelRecords });
      if (!(hookRes instanceof Boolean) || !((Boolean) hookRes))
        return VideoFrame.WATCH_FAILED_USER_REJECTED_CONFLICT;
      lastParallel = new Vector<Airing>(parallelRecords);
    } while (true);


    ManualRecord newMR;
    if (schedAir.getStartTime() < Sage.time())
    {
      int[] errorReturn = new int[1];
      EncoderState es = findBestEncoderForNow(schedAir, true, uiClient, errorReturn);
      if (es == null)
      {
        if (errorReturn[0] == 0)
          errorReturn[0] = VideoFrame.WATCH_FAILED_GENERAL_CANT_FIND_ENCODER;
        return errorReturn[0];
      }
      synchronized (this)
      {
        es = checkForFoundBestEncoderNowRecordSwitch(es, recAir);
        // Set the acquisition state to manual if it has already started recording
        MediaFile mf = wiz.getFileForAiring(recAir);
        if (mf != null)
          mf.setAcquisitionTech(MediaFile.ACQUISITION_MANUAL);
        newMR = wiz.addManualRecord(requestedStart, requestedDuration, 0, recAir.stationID,
            """", """", recAir.id, 0);
        es.forceWatch = newMR.getSchedulingAiring();
        es.forceProcessed = false;
        work();
      }
    }
    else
      newMR = wiz.addManualRecord(requestedStart, requestedDuration, 0, recAir.stationID,
          """", """", recAir.id, 0);
    PluginEventManager.postEvent(PluginEventManager.MANUAL_RECORD_ADDED,
        new Object[] { PluginEventManager.VAR_AIRING, newMR.getSchedulingAiring() });
    return VideoFrame.WATCH_OK;
  }",1,11563
"   private static byte[] encodeBase64(byte[] binaryData, boolean isChunked)
   {
      int lengthDataBits = binaryData.length * EIGHTBIT;
      int fewerThan24bits = lengthDataBits % TWENTYFOURBITGROUP;
      int numberTriplets = lengthDataBits / TWENTYFOURBITGROUP;
      byte encodedData[] = null;
      int encodedDataLength = 0;
      int nbrChunks = 0;


      if (fewerThan24bits != 0)
      {
         //data not divisible by 24 bit
         encodedDataLength = (numberTriplets + 1) * 4;
      }
      else
      {
         // 16 or 8 bit
         encodedDataLength = numberTriplets * 4;
      }


      // If the output is to be ""chunked"" into 76 character sections,
      // for compliance with RFC 2045 MIME, then it is important to
      // allow for extra length to account for the separator(s)
      if (isChunked)
      {


         nbrChunks =
                 (CHUNK_SEPARATOR.length == 0
                 ? 0
                 : (int)Math.ceil((float)encodedDataLength / CHUNK_SIZE));
         encodedDataLength += nbrChunks * CHUNK_SEPARATOR.length;
      }


      encodedData = new byte[encodedDataLength];


      byte k = 0, l = 0, b1 = 0, b2 = 0, b3 = 0;


      int encodedIndex = 0;
      int dataIndex = 0;
      int i = 0;
      int nextSeparatorIndex = CHUNK_SIZE;
      int chunksSoFar = 0;


      //log.debug(""number of triplets = "" + numberTriplets);
      for (i = 0; i < numberTriplets; i++)
      {
         dataIndex = i * 3;
         b1 = binaryData[dataIndex];
         b2 = binaryData[dataIndex + 1];
         b3 = binaryData[dataIndex + 2];


         //log.debug(""b1= "" + b1 +"", b2= "" + b2 + "", b3= "" + b3);


         l = (byte)(b2 & 0x0f);
         k = (byte)(b1 & 0x03);


         byte val1 =
                 ((b1 & SIGN) == 0)
                 ? (byte)(b1 >> 2)
                 : (byte)((b1) >> 2 ^ 0xc0);
         byte val2 =
                 ((b2 & SIGN) == 0)
                 ? (byte)(b2 >> 4)
                 : (byte)((b2) >> 4 ^ 0xf0);
         byte val3 =
                 ((b3 & SIGN) == 0)
                 ? (byte)(b3 >> 6)
                 : (byte)((b3) >> 6 ^ 0xfc);


         encodedData[encodedIndex] = lookUpBase64Alphabet[val1];
         //log.debug( ""val2 = "" + val2 );
         //log.debug( ""k4   = "" + (k<<4) );
         //log.debug(  ""vak  = "" + (val2 | (k<<4)) );
         encodedData[encodedIndex + 1] =
                 lookUpBase64Alphabet[val2 | (k << 4)];
         encodedData[encodedIndex + 2] =
                 lookUpBase64Alphabet[(l << 2) | val3];
         encodedData[encodedIndex + 3] = lookUpBase64Alphabet[b3 & 0x3f];


         encodedIndex += 4;


         // If we are chunking, let's put a chunk separator down.
         if (isChunked)
         {
            // this assumes that CHUNK_SIZE % 4 == 0
            if (encodedIndex == nextSeparatorIndex)
            {
               System.arraycopy(
                       CHUNK_SEPARATOR,
                       0,
                       encodedData,
                       encodedIndex,
                       CHUNK_SEPARATOR.length);
               chunksSoFar++;
               nextSeparatorIndex =
                       (CHUNK_SIZE * (chunksSoFar + 1))
                       + (chunksSoFar * CHUNK_SEPARATOR.length);
               encodedIndex += CHUNK_SEPARATOR.length;
            }
         }
      }


      // form integral number of 6-bit groups
      dataIndex = i * 3;


      if (fewerThan24bits == EIGHTBIT)
      {
         b1 = binaryData[dataIndex];
         k = (byte)(b1 & 0x03);
         //log.debug(""b1="" + b1);
         //log.debug(""b1<<2 = "" + (b1>>2) );
         byte val1 =
                 ((b1 & SIGN) == 0)
                 ? (byte)(b1 >> 2)
                 : (byte)((b1) >> 2 ^ 0xc0);
         encodedData[encodedIndex] = lookUpBase64Alphabet[val1];
         encodedData[encodedIndex + 1] = lookUpBase64Alphabet[k << 4];
         encodedData[encodedIndex + 2] = PAD;
         encodedData[encodedIndex + 3] = PAD;
      }
      else if (fewerThan24bits == SIXTEENBIT)
      {


         b1 = binaryData[dataIndex];
         b2 = binaryData[dataIndex + 1];
         l = (byte)(b2 & 0x0f);
         k = (byte)(b1 & 0x03);


         byte val1 =
                 ((b1 & SIGN) == 0)
                 ? (byte)(b1 >> 2)
                 : (byte)((b1) >> 2 ^ 0xc0);
         byte val2 =
                 ((b2 & SIGN) == 0)
                 ? (byte)(b2 >> 4)
                 : (byte)((b2) >> 4 ^ 0xf0);


         encodedData[encodedIndex] = lookUpBase64Alphabet[val1];
         encodedData[encodedIndex + 1] =
                 lookUpBase64Alphabet[val2 | (k << 4)];
         encodedData[encodedIndex + 2] = lookUpBase64Alphabet[l << 2];
         encodedData[encodedIndex + 3] = PAD;
      }


      if (isChunked)
      {
         // we also add a separator to the end of the final chunk.
         if (chunksSoFar < nbrChunks)
         {
            System.arraycopy(
                    CHUNK_SEPARATOR,
                    0,
                    encodedData,
                    encodedDataLength - CHUNK_SEPARATOR.length,
                    CHUNK_SEPARATOR.length);
         }
      }


      return encodedData;
   }",1,11792
"    public JsonGenerator(LogIterator iter) {
	servers = new HashSet<Integer>();


	Pattern stateChangeP = Pattern.compile(""- (LOOKING|FOLLOWING|LEADING)"");
	Pattern newElectionP = Pattern.compile(""New election. My id =  (\\d+), Proposed zxid = (\\d+)"");
	Pattern receivedProposalP = Pattern.compile(""Notification: (\\d+) \\(n.leader\\), (\\d+) \\(n.zxid\\), (\\d+) \\(n.round\\), .+ \\(n.state\\), (\\d+) \\(n.sid\\), .+ \\(my state\\)"");
	Pattern exceptionP = Pattern.compile(""xception"");
	
	root = new JSONObject();
	Matcher m = null;
	JSONArray events = new JSONArray();
	root.put(""events"", events);
	
	long starttime = Long.MAX_VALUE;
	long endtime = 0;


	int leader = 0;
	long curEpoch = 0;
	boolean newEpoch = false;


	while (iter.hasNext()) {
	    LogEntry ent = iter.next();
	    
	    if (ent.getTimestamp() < starttime) {
		starttime = ent.getTimestamp();
	    }
	    if (ent.getTimestamp() > endtime) {
		endtime = ent.getTimestamp();
	    }
	    
	    if (ent.getType() == LogEntry.Type.TXN) {
		events.add(txnEntry((TransactionEntry)ent));
	    } else {
		Log4JEntry e = (Log4JEntry)ent;
		servers.add(e.getNode());
		
		if ((m = stateChangeP.matcher(e.getEntry())).find()) {
		    JSONObject stateChange = new JSONObject();
		    stateChange.put(""type"", ""stateChange"");
		    stateChange.put(""time"", e.getTimestamp());
		    stateChange.put(""server"", e.getNode());
		    stateChange.put(""state"", m.group(1));
		    events.add(stateChange);
		    
		    if (m.group(1).equals(""LEADING"")) {
			leader = e.getNode();
		    }
		} else if ((m = newElectionP.matcher(e.getEntry())).find()) {
		    Iterator<Integer> iterator = servers.iterator();
		    long zxid = Long.valueOf(m.group(2));
		    int count = (int)zxid;// & 0xFFFFFFFFL;
		    int epoch = (int)Long.rotateRight(zxid, 32);// >> 32;
		    
		    if (leader != 0 && epoch > curEpoch) {
			JSONObject stateChange = new JSONObject();
			stateChange.put(""type"", ""stateChange"");
			stateChange.put(""time"", e.getTimestamp());
			stateChange.put(""server"", leader);
			stateChange.put(""state"", ""INIT"");
			events.add(stateChange);
			leader = 0;
		    }
		    
		    while (iterator.hasNext()) {
			int dst = iterator.next();
			if (dst != e.getNode()) {
			    JSONObject msg = new JSONObject();
			    msg.put(""type"", ""postmessage"");
			    msg.put(""src"", e.getNode());
			    msg.put(""dst"", dst);
			    msg.put(""time"", e.getTimestamp());
			    msg.put(""zxid"", m.group(2));
			    msg.put(""count"", count);
			    msg.put(""epoch"", epoch);
			    
			    events.add(msg);
			}
		    }
		} else if ((m = receivedProposalP.matcher(e.getEntry())).find()) {
		    // Pattern.compile(""Notification: \\d+, (\\d+), (\\d+), \\d+, [^,]*, [^,]*, (\\d+)"");//, LOOKING, LOOKING, 2
		    int src = Integer.valueOf(m.group(4));
		    long zxid = Long.valueOf(m.group(2));
		    int dst = e.getNode();
		    long epoch2 = Long.valueOf(m.group(3));
		    
		    int count = (int)zxid;// & 0xFFFFFFFFL;
		    int epoch = (int)Long.rotateRight(zxid, 32);// >> 32;
		    
		    if (leader != 0 && epoch > curEpoch) {
			JSONObject stateChange = new JSONObject();
			stateChange.put(""type"", ""stateChange"");
			stateChange.put(""time"", e.getTimestamp());
			stateChange.put(""server"", leader);
			stateChange.put(""state"", ""INIT"");
			events.add(stateChange);
			leader = 0;
		    }
		    
		    if (src != dst) {
			JSONObject msg = new JSONObject();
			msg.put(""type"", ""delivermessage"");
			msg.put(""src"", src);
			msg.put(""dst"", dst);
			msg.put(""time"", e.getTimestamp());
			msg.put(""zxid"", zxid);
			msg.put(""epoch"", epoch);
			msg.put(""count"", count);
			msg.put(""epoch2"", epoch2);
			
			events.add(msg);
		    }
		} else if ((m = exceptionP.matcher(e.getEntry())).find()) {
		    JSONObject ex = new JSONObject();
		    ex.put(""type"", ""exception"");
		    ex.put(""server"", e.getNode());
		    ex.put(""time"", e.getTimestamp());
		    ex.put(""text"", e.getEntry());
		    events.add(ex);
		} 
	    }
	    JSONObject ex = new JSONObject();
	    ex.put(""type"", ""text"");
	    ex.put(""time"", ent.getTimestamp());
	    String txt = ent.toString();
	    ex.put(""text"", txt);
	    events.add(ex);
	}
	//	System.out.println(""pending messages: ""+pendingMessages.size());
	root.put(""starttime"", starttime);
	root.put(""endtime"", endtime);


	JSONArray serversarray = new JSONArray();
	root.put(""servers"", serversarray);
	
	Iterator<Integer> iterator = servers.iterator();
	while (iterator.hasNext()) {
	    serversarray.add(iterator.next());
	}
    }",1,11821
"    @SuppressWarnings(""try"")
    private void doRun(Map<Method, CEntryPointData> entryPoints, Method mainEntryPoint,
                    JavaMainSupport javaMainSupport, String imageName, AbstractBootImage.NativeImageKind k,
                    SubstitutionProcessor harnessSubstitutions,
                    ForkJoinPool compilationExecutor, ForkJoinPool analysisExecutor) {
        List<HostedMethod> hostedEntryPoints = new ArrayList<>();


        OptionValues options = HostedOptionValues.singleton();
        SnippetReflectionProvider originalSnippetReflection = GraalAccess.getOriginalSnippetReflection();
        try (DebugContext debug = DebugContext.create(options, new GraalDebugHandlersFactory(originalSnippetReflection))) {
            setupNativeImage(imageName, options, entryPoints, javaMainSupport, harnessSubstitutions, analysisExecutor, originalSnippetReflection, debug);


            boolean returnAfterAnalysis = runPointsToAnalysis(imageName, options, debug);
            if (returnAfterAnalysis) {
                return;
            }


            NativeImageHeap heap;
            HostedMethod mainEntryPointHostedStub;
            HostedMetaAccess hMetaAccess;
            SharedRuntimeConfigurationBuilder runtime;
            try (StopTimer t = new Timer(imageName, ""universe"").start()) {
                hUniverse = new HostedUniverse(bigbang);
                hMetaAccess = new HostedMetaAccess(hUniverse, bigbang.getMetaAccess());


                new UniverseBuilder(aUniverse, bigbang.getMetaAccess(), hUniverse, hMetaAccess, HostedConfiguration.instance().createStaticAnalysisResultsBuilder(bigbang, hUniverse),
                                bigbang.getUnsupportedFeatures()).build(debug);


                runtime = new HostedRuntimeConfigurationBuilder(options, bigbang.getHostVM(), hUniverse, hMetaAccess, bigbang.getProviders()).build();
                registerGraphBuilderPlugins(featureHandler, runtime.getRuntimeConfig(), (HostedProviders) runtime.getRuntimeConfig().getProviders(), bigbang.getMetaAccess(), aUniverse,
                                hMetaAccess, hUniverse,
                                nativeLibraries, loader, false, true, bigbang.getAnnotationSubstitutionProcessor(), new SubstrateClassInitializationPlugin((SVMHost) aUniverse.hostVM()),
                                bigbang.getHostVM().getClassInitializationSupport());


                if (NativeImageOptions.PrintUniverse.getValue()) {
                    printTypes();
                }


                /* Find the entry point methods in the hosted world. */
                for (AnalysisMethod m : aUniverse.getMethods()) {
                    if (m.isEntryPoint()) {
                        HostedMethod found = hUniverse.lookup(m);
                        assert found != null;
                        hostedEntryPoints.add(found);
                    }
                }
                /* Find main entry point */
                if (mainEntryPoint != null) {
                    AnalysisMethod analysisStub = CEntryPointCallStubSupport.singleton().getStubForMethod(mainEntryPoint);
                    mainEntryPointHostedStub = (HostedMethod) hMetaAccess.getUniverse().lookup(analysisStub);
                    assert hostedEntryPoints.contains(mainEntryPointHostedStub);
                } else {
                    mainEntryPointHostedStub = null;
                }
                if (hostedEntryPoints.size() == 0) {
                    throw UserError.abort(""Warning: no entry points found, i.e., no method annotated with @"" + CEntryPoint.class.getSimpleName());
                }


                heap = new NativeImageHeap(aUniverse, hUniverse, hMetaAccess);


                BeforeCompilationAccessImpl config = new BeforeCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.beforeCompilation(config));


                bigbang.getUnsupportedFeatures().report(bigbang);
            } catch (UnsupportedFeatureException ufe) {
                throw UserError.abort(ufe.getMessage());
            }


            recordMethodsWithStackValues();
            recordRestrictHeapAccessCallees(aUniverse.getMethods());


            /*
             * After this point, all TypeFlow (and therefore also TypeState) objects are unreachable
             * and can be garbage collected. This is important to keep the overall memory footprint
             * low. However, this also means we no longer have complete call chain information. Only
             * the summarized information stored in the StaticAnalysisResult objects is available
             * after this point.
             */
            bigbang.cleanupAfterAnalysis();


            NativeImageCodeCache codeCache;
            CompileQueue compileQueue;
            try (StopTimer t = new Timer(imageName, ""compile"").start()) {
                compileQueue = HostedConfiguration.instance().createCompileQueue(debug, featureHandler, hUniverse, runtime, DeoptTester.enabled(), bigbang.getProviders().getSnippetReflection(),
                                compilationExecutor);
                compileQueue.finish(debug);


                /* release memory taken by graphs for the image writing */
                hUniverse.getMethods().forEach(HostedMethod::clear);


                codeCache = NativeImageCodeCacheFactory.get().newCodeCache(compileQueue, heap);
                codeCache.layoutConstants();
                codeCache.layoutMethods(debug, imageName);


                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.afterCompilation(config));
            }


            try (Indent indent = debug.logAndIndent(""create native image"")) {
                try (DebugContext.Scope buildScope = debug.scope(""CreateBootImage"")) {
                    try (StopTimer t = new Timer(imageName, ""image"").start()) {


                        // Start building the model of the native image heap.
                        heap.addInitialObjects();
                        // Then build the model of the code cache, which can
                        // add objects to the native image heap.
                        codeCache.addConstantsToHeap();
                        // Finish building the model of the native image heap.
                        heap.addTrailingObjects();


                        AfterHeapLayoutAccessImpl config = new AfterHeapLayoutAccessImpl(featureHandler, loader, hMetaAccess, debug);
                        featureHandler.forEachFeature(feature -> feature.afterHeapLayout(config));


                        this.image = AbstractBootImage.create(k, hUniverse, hMetaAccess, nativeLibraries, heap, codeCache, hostedEntryPoints, mainEntryPointHostedStub, loader.getClassLoader());
                        image.build(debug);
                        if (NativeImageOptions.PrintUniverse.getValue()) {
                            /*
                             * This debug output must be printed _after_ and not _during_ image
                             * building, because it adds some PrintStream objects to static fields,
                             * which disrupts the heap.
                             */
                            codeCache.printCompilationResults();
                        }
                    }
                }
            }


            BeforeImageWriteAccessImpl beforeConfig = new BeforeImageWriteAccessImpl(featureHandler, loader, imageName, image,
                            runtime.getRuntimeConfig(), aUniverse, hUniverse, optionProvider, hMetaAccess, debug);
            featureHandler.forEachFeature(feature -> feature.beforeImageWrite(beforeConfig));


            try (StopTimer t = new Timer(imageName, ""write"").start()) {
                /*
                 * This will write the debug info too -- i.e. we may be writing more than one file,
                 * if the debug info is in a separate file. We need to push writing the file to the
                 * image implementation, because whether the debug info and image share a file or
                 * not is an implementation detail of the image.
                 */
                Path tmpDir = tempDirectory();
                Path imagePath = image.write(debug, generatedFiles(HostedOptionValues.singleton()), tmpDir, imageName, beforeConfig).getOutputFile();


                AfterImageWriteAccessImpl afterConfig = new AfterImageWriteAccessImpl(featureHandler, loader, hUniverse, imagePath, tmpDir, image.getBootImageKind(), debug);
                featureHandler.forEachFeature(feature -> feature.afterImageWrite(afterConfig));
            }
        }
    }",1,12087
"    public double correlation(final double[] xArray, final double[] yArray)
            throws DimensionMismatchException {


        if (xArray.length != yArray.length) {
            throw new DimensionMismatchException(xArray.length, yArray.length);
        }


        final int n = xArray.length;
        final long numPairs = sum(n - 1);


        @SuppressWarnings(""unchecked"")
        Pair<Double, Double>[] pairs = new Pair[n];
        for (int i = 0; i < n; i++) {
            pairs[i] = new Pair<>(xArray[i], yArray[i]);
        }


        Arrays.sort(pairs, new Comparator<Pair<Double, Double>>() {
            /** {@inheritDoc} */
            @Override
            public int compare(Pair<Double, Double> pair1, Pair<Double, Double> pair2) {
                int compareFirst = pair1.getFirst().compareTo(pair2.getFirst());
                return compareFirst != 0 ? compareFirst : pair1.getSecond().compareTo(pair2.getSecond());
            }
        });


        long tiedXPairs = 0;
        long tiedXYPairs = 0;
        long consecutiveXTies = 1;
        long consecutiveXYTies = 1;
        Pair<Double, Double> prev = pairs[0];
        for (int i = 1; i < n; i++) {
            final Pair<Double, Double> curr = pairs[i];
            if (curr.getFirst().equals(prev.getFirst())) {
                consecutiveXTies++;
                if (curr.getSecond().equals(prev.getSecond())) {
                    consecutiveXYTies++;
                } else {
                    tiedXYPairs += sum(consecutiveXYTies - 1);
                    consecutiveXYTies = 1;
                }
            } else {
                tiedXPairs += sum(consecutiveXTies - 1);
                consecutiveXTies = 1;
                tiedXYPairs += sum(consecutiveXYTies - 1);
                consecutiveXYTies = 1;
            }
            prev = curr;
        }
        tiedXPairs += sum(consecutiveXTies - 1);
        tiedXYPairs += sum(consecutiveXYTies - 1);


        long swaps = 0;
        @SuppressWarnings(""unchecked"")
        Pair<Double, Double>[] pairsDestination = new Pair[n];
        for (int segmentSize = 1; segmentSize < n; segmentSize <<= 1) {
            for (int offset = 0; offset < n; offset += 2 * segmentSize) {
                int i = offset;
                final int iEnd = FastMath.min(i + segmentSize, n);
                int j = iEnd;
                final int jEnd = FastMath.min(j + segmentSize, n);


                int copyLocation = offset;
                while (i < iEnd || j < jEnd) {
                    if (i < iEnd) {
                        if (j < jEnd) {
                            if (pairs[i].getSecond().compareTo(pairs[j].getSecond()) <= 0) {
                                pairsDestination[copyLocation] = pairs[i];
                                i++;
                            } else {
                                pairsDestination[copyLocation] = pairs[j];
                                j++;
                                swaps += iEnd - i;
                            }
                        } else {
                            pairsDestination[copyLocation] = pairs[i];
                            i++;
                        }
                    } else {
                        pairsDestination[copyLocation] = pairs[j];
                        j++;
                    }
                    copyLocation++;
                }
            }
            final Pair<Double, Double>[] pairsTemp = pairs;
            pairs = pairsDestination;
            pairsDestination = pairsTemp;
        }


        long tiedYPairs = 0;
        long consecutiveYTies = 1;
        prev = pairs[0];
        for (int i = 1; i < n; i++) {
            final Pair<Double, Double> curr = pairs[i];
            if (curr.getSecond().equals(prev.getSecond())) {
                consecutiveYTies++;
            } else {
                tiedYPairs += sum(consecutiveYTies - 1);
                consecutiveYTies = 1;
            }
            prev = curr;
        }
        tiedYPairs += sum(consecutiveYTies - 1);


        final long concordantMinusDiscordant = numPairs - tiedXPairs - tiedYPairs + tiedXYPairs - 2 * swaps;
        final double nonTiedPairsMultiplied = (numPairs - tiedXPairs) * (double) (numPairs - tiedYPairs);
        return concordantMinusDiscordant / FastMath.sqrt(nonTiedPairsMultiplied);
    }",1,12121
"	private void findObjectsToPack(@NonNull ProgressMonitor countingMonitor,
			@NonNull ObjectWalk walker, @NonNull Set<? extends ObjectId> want,
			@NonNull Set<? extends ObjectId> have,
			@NonNull Set<? extends ObjectId> noBitmaps) throws IOException {
		final long countingStart = System.currentTimeMillis();
		beginPhase(PackingPhase.COUNTING, countingMonitor, ProgressMonitor.UNKNOWN);


		stats.interestingObjects = Collections.unmodifiableSet(new HashSet<ObjectId>(want));
		stats.uninterestingObjects = Collections.unmodifiableSet(new HashSet<ObjectId>(have));
		excludeFromBitmapSelection = noBitmaps;


		canBuildBitmaps = config.isBuildBitmaps()
				&& !shallowPack
				&& have.isEmpty()
				&& (excludeInPacks == null || excludeInPacks.length == 0);
		if (!shallowPack && useBitmaps) {
			BitmapIndex bitmapIndex = reader.getBitmapIndex();
			if (bitmapIndex != null) {
				BitmapWalker bitmapWalker = new BitmapWalker(
						walker, bitmapIndex, countingMonitor);
				findObjectsToPackUsingBitmaps(bitmapWalker, want, have);
				endPhase(countingMonitor);
				stats.timeCounting = System.currentTimeMillis() - countingStart;
				stats.bitmapIndexMisses = bitmapWalker.getCountOfBitmapIndexMisses();
				return;
			}
		}


		List<ObjectId> all = new ArrayList<>(want.size() + have.size());
		all.addAll(want);
		all.addAll(have);


		final RevFlag include = walker.newFlag(""include""); //$NON-NLS-1$
		final RevFlag added = walker.newFlag(""added""); //$NON-NLS-1$


		walker.carry(include);


		int haveEst = have.size();
		if (have.isEmpty()) {
			walker.sort(RevSort.COMMIT_TIME_DESC);
		} else {
			walker.sort(RevSort.TOPO);
			if (thin)
				walker.sort(RevSort.BOUNDARY, true);
		}


		List<RevObject> wantObjs = new ArrayList<>(want.size());
		List<RevObject> haveObjs = new ArrayList<>(haveEst);
		List<RevTag> wantTags = new ArrayList<>(want.size());


		// Retrieve the RevWalk's versions of ""want"" and ""have"" objects to
		// maintain any state previously set in the RevWalk.
		AsyncRevObjectQueue q = walker.parseAny(all, true);
		try {
			for (;;) {
				try {
					RevObject o = q.next();
					if (o == null)
						break;
					if (have.contains(o))
						haveObjs.add(o);
					if (want.contains(o)) {
						o.add(include);
						wantObjs.add(o);
						if (o instanceof RevTag)
							wantTags.add((RevTag) o);
					}
				} catch (MissingObjectException e) {
					if (ignoreMissingUninteresting
							&& have.contains(e.getObjectId()))
						continue;
					throw e;
				}
			}
		} finally {
			q.release();
		}


		if (!wantTags.isEmpty()) {
			all = new ArrayList<>(wantTags.size());
			for (RevTag tag : wantTags)
				all.add(tag.getObject());
			q = walker.parseAny(all, true);
			try {
				while (q.next() != null) {
					// Just need to pop the queue item to parse the object.
				}
			} finally {
				q.release();
			}
		}


		if (walker instanceof DepthWalk.ObjectWalk) {
			DepthWalk.ObjectWalk depthWalk = (DepthWalk.ObjectWalk) walker;
			for (RevObject obj : wantObjs) {
				depthWalk.markRoot(obj);
			}
			// Mark the tree objects associated with ""have"" commits as
			// uninteresting to avoid writing redundant blobs. A normal RevWalk
			// lazily propagates the ""uninteresting"" state from a commit to its
			// tree during the walk, but DepthWalks can terminate early so
			// preemptively propagate that state here.
			for (RevObject obj : haveObjs) {
				if (obj instanceof RevCommit) {
					RevTree t = ((RevCommit) obj).getTree();
					depthWalk.markUninteresting(t);
				}
			}


			if (unshallowObjects != null) {
				for (ObjectId id : unshallowObjects) {
					depthWalk.markUnshallow(walker.parseAny(id));
				}
			}
		} else {
			for (RevObject obj : wantObjs)
				walker.markStart(obj);
		}
		for (RevObject obj : haveObjs)
			walker.markUninteresting(obj);


		final int maxBases = config.getDeltaSearchWindowSize();
		Set<RevTree> baseTrees = new HashSet<>();
		BlockList<RevCommit> commits = new BlockList<>();
		Set<ObjectId> roots = new HashSet<>();
		RevCommit c;
		while ((c = walker.next()) != null) {
			if (exclude(c))
				continue;
			if (c.has(RevFlag.UNINTERESTING)) {
				if (baseTrees.size() <= maxBases)
					baseTrees.add(c.getTree());
				continue;
			}


			commits.add(c);
			if (c.getParentCount() == 0) {
				roots.add(c.copy());
			}
			countingMonitor.update(1);
		}
		stats.rootCommits = Collections.unmodifiableSet(roots);


		if (shallowPack) {
			for (RevCommit cmit : commits) {
				addObject(cmit, 0);
			}
		} else {
			int commitCnt = 0;
			boolean putTagTargets = false;
			for (RevCommit cmit : commits) {
				if (!cmit.has(added)) {
					cmit.add(added);
					addObject(cmit, 0);
					commitCnt++;
				}


				for (int i = 0; i < cmit.getParentCount(); i++) {
					RevCommit p = cmit.getParent(i);
					if (!p.has(added) && !p.has(RevFlag.UNINTERESTING)
							&& !exclude(p)) {
						p.add(added);
						addObject(p, 0);
						commitCnt++;
					}
				}


				if (!putTagTargets && 4096 < commitCnt) {
					for (ObjectId id : tagTargets) {
						RevObject obj = walker.lookupOrNull(id);
						if (obj instanceof RevCommit
								&& obj.has(include)
								&& !obj.has(RevFlag.UNINTERESTING)
								&& !obj.has(added)) {
							obj.add(added);
							addObject(obj, 0);
						}
					}
					putTagTargets = true;
				}
			}
		}
		commits = null;


		if (thin && !baseTrees.isEmpty()) {
			BaseSearch bases = new BaseSearch(countingMonitor, baseTrees, //
					objectsMap, edgeObjects, reader);
			RevObject o;
			while ((o = walker.nextObject()) != null) {
				if (o.has(RevFlag.UNINTERESTING))
					continue;
				if (exclude(o))
					continue;


				int pathHash = walker.getPathHashCode();
				byte[] pathBuf = walker.getPathBuffer();
				int pathLen = walker.getPathLength();
				bases.addBase(o.getType(), pathBuf, pathLen, pathHash);
				filterAndAddObject(o, o.getType(), pathHash, want);
				countingMonitor.update(1);
			}
		} else {
			RevObject o;
			while ((o = walker.nextObject()) != null) {
				if (o.has(RevFlag.UNINTERESTING))
					continue;
				if (exclude(o))
					continue;
				filterAndAddObject(o, o.getType(), walker.getPathHashCode(), want);
				countingMonitor.update(1);
			}
		}


		for (CachedPack pack : cachedPacks)
			countingMonitor.update((int) pack.getObjectCount());
		endPhase(countingMonitor);
		stats.timeCounting = System.currentTimeMillis() - countingStart;
		stats.bitmapIndexMisses = -1;
	}",1,12336
"  long recoverDrf(OplogEntryIdSet deletedIds, boolean alreadyRecoveredOnce, boolean latestOplog) {
    File drfFile = this.drf.f;
    if (drfFile == null) {
      this.haveRecoveredDrf = true;
      return 0L;
    }
    lockCompactor();
    try {
      if (this.haveRecoveredDrf && !getHasDeletes())
        return 0L; // do this while holding lock
      if (!this.haveRecoveredDrf) {
        this.haveRecoveredDrf = true;
      }
      logger.info(""Recovering {} {} for disk store {}."",
          new Object[] {toString(), drfFile.getAbsolutePath(), getParent().getName()});
      this.recoverDelEntryId = DiskStoreImpl.INVALID_ID;
      boolean readLastRecord = true;
      CountingDataInputStream dis = null;
      try {
        int recordCount = 0;
        boolean foundDiskStoreRecord = false;
        FileInputStream fis = null;
        try {
          fis = new FileInputStream(drfFile);
          dis = new CountingDataInputStream(new BufferedInputStream(fis, 32 * 1024),
              drfFile.length());
          boolean endOfLog = false;
          while (!endOfLog) {
            if (dis.atEndOfFile()) {
              endOfLog = true;
              break;
            }
            readLastRecord = false;
            byte opCode = dis.readByte();
            if (logger.isTraceEnabled(LogMarker.PERSIST_RECOVERY_VERBOSE)) {
              logger.trace(LogMarker.PERSIST_RECOVERY_VERBOSE, ""drf byte={} location={}"", opCode,
                  Long.toHexString(dis.getCount()));
            }
            switch (opCode) {
              case OPLOG_EOF_ID:
                // we are at the end of the oplog. So we need to back up one byte
                dis.decrementCount();
                endOfLog = true;
                break;
              case OPLOG_DEL_ENTRY_1ID:
              case OPLOG_DEL_ENTRY_2ID:
              case OPLOG_DEL_ENTRY_3ID:
              case OPLOG_DEL_ENTRY_4ID:
              case OPLOG_DEL_ENTRY_5ID:
              case OPLOG_DEL_ENTRY_6ID:
              case OPLOG_DEL_ENTRY_7ID:
              case OPLOG_DEL_ENTRY_8ID:
                readDelEntry(dis, opCode, deletedIds, parent);
                recordCount++;
                break;
              case OPLOG_DISK_STORE_ID:
                readDiskStoreRecord(dis, this.drf.f);
                foundDiskStoreRecord = true;
                recordCount++;
                break;
              case OPLOG_MAGIC_SEQ_ID:
                readOplogMagicSeqRecord(dis, this.drf.f, OPLOG_TYPE.DRF);
                break;
              case OPLOG_GEMFIRE_VERSION:
                readGemfireVersionRecord(dis, this.drf.f);
                recordCount++;
                break;


              case OPLOG_RVV:
                long idx = dis.getCount();
                readRVVRecord(dis, this.drf.f, true, latestOplog);
                recordCount++;
                break;


              default:
                throw new DiskAccessException(
                    String.format(""Unknown opCode %s found in disk operation log."",
                        opCode),
                    getParent());
            }
            readLastRecord = true;
            // @todo
            // if (rgn.isDestroyed()) {
            // break;
            // }
          } // while
        } finally {
          if (dis != null) {
            dis.close();
          }
          if (fis != null) {
            fis.close();
          }
        }
        if (!foundDiskStoreRecord && recordCount > 0) {
          throw new DiskAccessException(
              ""The oplog file \"""" + this.drf.f + ""\"" does not belong to the init file \""""
                  + getParent().getInitFile() + ""\"". Drf did not contain a disk store id."",
              getParent());
        }
      } catch (EOFException ignore) {
        // ignore since a partial record write can be caused by a crash
      } catch (IOException ex) {
        getParent().getCancelCriterion().checkCancelInProgress(ex);
        throw new DiskAccessException(
            String.format(""Failed to read file during recovery from %s"",
                drfFile.getPath()),
            ex, getParent());
      } catch (CancelException e) {
        if (logger.isDebugEnabled()) {
          logger.debug(""Oplog::readOplog:Error in recovery as Cache was closed"", e);
        }
      } catch (RegionDestroyedException e) {
        if (logger.isDebugEnabled()) {
          logger.debug(""Oplog::readOplog:Error in recovery as Region was destroyed"", e);
        }
      }
      // Add the Oplog size to the Directory Holder which owns this oplog,
      // so that available space is correctly calculated & stats updated.
      long byteCount = 0;
      if (!readLastRecord) {
        // this means that there was a crash
        // and hence we should not continue to read
        // the next oplog
        this.crashed = true;
        if (dis != null) {
          byteCount = dis.getFileLength();
        }
      } else {
        if (dis != null) {
          byteCount = dis.getCount();
        }
      }
      if (!alreadyRecoveredOnce) {
        setRecoveredDrfSize(byteCount);
        this.dirHolder.incrementTotalOplogSize(byteCount);
      }
      return byteCount;
    } finally {
      unlockCompactor();
    }
  }",1,12380
"  private TtmlRegion parseRegionAttributes(
      XmlPullParser xmlParser, CellResolution cellResolution, TtsExtent ttsExtent) {
    String regionId = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_ID);
    if (regionId == null) {
      return null;
    }


    float position;
    float line;


    String regionOrigin = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_TTS_ORIGIN);
    if (regionOrigin != null) {
      Matcher originPercentageMatcher = PERCENTAGE_COORDINATES.matcher(regionOrigin);
      Matcher originPixelMatcher = PIXEL_COORDINATES.matcher(regionOrigin);
      if (originPercentageMatcher.matches()) {
        try {
          position = Float.parseFloat(originPercentageMatcher.group(1)) / 100f;
          line = Float.parseFloat(originPercentageMatcher.group(2)) / 100f;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed origin: "" + regionOrigin);
          return null;
        }
      } else if (originPixelMatcher.matches()) {
        if (ttsExtent == null) {
          Log.w(TAG, ""Ignoring region with missing tts:extent: "" + regionOrigin);
          return null;
        }
        try {
          int width = Integer.parseInt(originPixelMatcher.group(1));
          int height = Integer.parseInt(originPixelMatcher.group(2));
          // Convert pixel values to fractions.
          position = width / (float) ttsExtent.width;
          line = height / (float) ttsExtent.height;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed origin: "" + regionOrigin);
          return null;
        }
      } else {
        Log.w(TAG, ""Ignoring region with unsupported origin: "" + regionOrigin);
        return null;
      }
    } else {
      Log.w(TAG, ""Ignoring region without an origin"");
      return null;
      // TODO: Should default to top left as below in this case, but need to fix
      // https://github.com/google/ExoPlayer/issues/2953 first.
      // Origin is omitted. Default to top left.
      // position = 0;
      // line = 0;
    }


    float width;
    float height;
    String regionExtent = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_TTS_EXTENT);
    if (regionExtent != null) {
      Matcher extentPercentageMatcher = PERCENTAGE_COORDINATES.matcher(regionExtent);
      Matcher extentPixelMatcher = PIXEL_COORDINATES.matcher(regionExtent);
      if (extentPercentageMatcher.matches()) {
        try {
          width = Float.parseFloat(extentPercentageMatcher.group(1)) / 100f;
          height = Float.parseFloat(extentPercentageMatcher.group(2)) / 100f;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed extent: "" + regionOrigin);
          return null;
        }
      } else if (extentPixelMatcher.matches()) {
        if (ttsExtent == null) {
          Log.w(TAG, ""Ignoring region with missing tts:extent: "" + regionOrigin);
          return null;
        }
        try {
          int extentWidth = Integer.parseInt(extentPixelMatcher.group(1));
          int extentHeight = Integer.parseInt(extentPixelMatcher.group(2));
          // Convert pixel values to fractions.
          width = extentWidth / (float) ttsExtent.width;
          height = extentHeight / (float) ttsExtent.height;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed extent: "" + regionOrigin);
          return null;
        }
      } else {
        Log.w(TAG, ""Ignoring region with unsupported extent: "" + regionOrigin);
        return null;
      }
    } else {
      Log.w(TAG, ""Ignoring region without an extent"");
      return null;
      // TODO: Should default to extent of parent as below in this case, but need to fix
      // https://github.com/google/ExoPlayer/issues/2953 first.
      // Extent is omitted. Default to extent of parent.
      // width = 1;
      // height = 1;
    }


    @Cue.AnchorType int lineAnchor = Cue.ANCHOR_TYPE_START;
    String displayAlign = XmlPullParserUtil.getAttributeValue(xmlParser,
        TtmlNode.ATTR_TTS_DISPLAY_ALIGN);
    if (displayAlign != null) {
      switch (Util.toLowerInvariant(displayAlign)) {
        case ""center"":
          lineAnchor = Cue.ANCHOR_TYPE_MIDDLE;
          line += height / 2;
          break;
        case ""after"":
          lineAnchor = Cue.ANCHOR_TYPE_END;
          line += height;
          break;
        default:
          // Default ""before"" case. Do nothing.
          break;
      }
    }


    float regionTextHeight = 1.0f / cellResolution.rows;
    return new TtmlRegion(
        regionId,
        position,
        line,
        /* lineType= */ Cue.LINE_TYPE_FRACTION,
        lineAnchor,
        width,
        /* textSizeType= */ Cue.TEXT_SIZE_TYPE_FRACTIONAL_IGNORE_PADDING,
        /* textSize= */ regionTextHeight);
  }",1,12434
"  public int compareTo(FactPartition o) {
    int colComp = this.partCol.compareTo(o.partCol);
    if (colComp == 0) {
      int partComp = 0;
      if (this.partSpec != null) {
        if (o.partSpec == null) {
          partComp = 1;
        } else {
          partComp = this.partSpec.compareTo(o.partSpec);
        }
      } else {
        if (o.partSpec != null) {
          partComp = -1;
        } else {
          partComp = 0;
        }
      }
      if (partComp == 0) {
        int upComp = 0;
        if (this.period != null && o.period != null) {
          upComp = this.period.compareTo(o.period);
        } else if (this.period == null && o.period == null) {
          upComp = 0;
        } else if (this.period == null) {
          upComp = -1;
        } else {
          upComp = 1;
        }
        if (upComp == 0) {
          if (this.containingPart != null) {
            if (o.containingPart == null) {
              return 1;
            }
            return this.containingPart.compareTo(o.containingPart);
          } else {
            if (o.containingPart != null) {
              return -1;
            } else {
              return 0;
            }
          }
        }
        return upComp;
      }
      return partComp;
    }
    return colComp;
  }",1,12470
"	@Override
	public ListCompositeContentProvider getContentProvider(EObject object, EStructuralFeature feature, EList<EObject>list) {
		if (contentProvider==null) {
			contentProvider = new ListCompositeContentProvider(this, object, feature, list) {
				@Override
				public Object[] getElements(Object inputElement) {
					
					Object elements[] = super.getElements(inputElement);
					List<Property> props = null;
					ModelExtensionDescriptor med = null;
					ExtendedPropertiesAdapter<?> adapter = ExtendedPropertiesAdapter.adapt(activity);
					if (adapter!=null) {
						// look for it in the property adapter first
						med = adapter.getProperty(ModelExtensionDescriptor.class);
					}


					if (med==null) {
						// not found? get the Custom Task ID from the Task object
						String id = CustomElementFeatureContainer.findId(activity);
						if (id!=null) {
							// and look it up in the Target Runtime's list of
							// Custom Task Descriptors
					    	TargetRuntime rt = TargetRuntime.getRuntime(activity);
					    	med = rt.getCustomTask(id);
						}
					}
					if (med!=null) {
						if (JbpmIoParametersListComposite.this.isInput)
							props = med.getProperties(""ioSpecification/dataInputs/name""); //$NON-NLS-1$
						else
							props = med.getProperties(""ioSpecification/dataOutputs/name""); //$NON-NLS-1$
					}
					
					List<Object> filtered = new ArrayList<Object>();
					for (Object e : elements) {
						boolean skip = false;
						EStructuralFeature f = ((EObject)e).eClass().getEStructuralFeature(""name""); //$NON-NLS-1$
						if (f!=null) {
							Object elementName = (String) ((EObject)e).eGet(f);
							if (props!=null) {
								for (Property p : props) {
									Object propName = p.getFirstStringValue();
									if (elementName!=null && propName!=null && elementName.equals(propName)) {
										skip = true;
										break;
									}
								}
							}
							if (activity instanceof SendTask) {
								if (""Message"".equals(elementName)) {
									skip = true;
								}
							}
							else if (activity instanceof ReceiveTask) {
								if (""Message"".equals(elementName)) {
									skip = true;
								}
//								else if (""MessageId"".equals(elementName)) {
//									skip = true;
//								}
							}
							else if (activity instanceof ServiceTask) {
								if (""Parameter"".equals(elementName)) {
									skip = true;
								}
								else if (""Result"".equals(elementName)) {
									skip = true;
								}
								// TODO: these should be automatically added by the ""Service Task"" tab...
//								else if (""Interface"".equals(elementName)) {
//									skip = true;
//								}
//								else if (""Operation"".equals(elementName)) {
//									skip = true;
//								}
//								else if (""ParameterType"".equals(elementName)) {
//									skip = true;
//								}
							}
						}
						if (!skip)
							filtered.add(e);
					}
					return filtered.toArray();
				}
			};
		}
		return contentProvider;
	}",1,12494
"  private void validateArrayStep(String arrStep)
    throws QueryException
  {
    boolean wildAllowed  = true;    // * is allowed initially
    boolean digitAllowed = true;    // Digit is allowed as next char
    boolean commaAllowed = false;   // Comma is allowed as next char


    boolean afterDigit    = false;  // Last non-space was a digit
    boolean toAllowed     = false;  // Any space after digit allows ""to""
    boolean afterTo       = false;  // After ""to"" expecting range end
    boolean toInProgress  = false;  // Prior char was 't' in ""to""
    boolean spaceRequired = false;  // A whitespace is required (after ""to"")
    boolean digitRequired = false;  // Digit required after comma or ""to""


    for (int i = 1; i < arrStep.length() - 1; ++i)
    {
      char currentChar = arrStep.charAt(i);


      if (currentChar == '*')
      {
        if (!wildAllowed)
          throwArrayException(arrStep);


        wildAllowed  = false;  // We've seen the only allowed wildcard
        digitAllowed = false;  // Only whitespace is allowed afterward
      }
      else if (currentChar == ',')
      {
        if (!commaAllowed)
          throwArrayException(arrStep);


        commaAllowed  = false;
        toAllowed     = false;
        afterDigit    = false;
        afterTo       = false;
        digitRequired = true;  // Next non-space must be a digit
      }
      else if (""0123456789"".indexOf(currentChar) >= 0)
      {
        if (!digitAllowed)
          throwArrayException(arrStep);


        wildAllowed   = false; // Wildcard no longer allowed
        commaAllowed  = true;
        afterDigit    = true;
        digitRequired = false;
      }
      else if ("" \t\n\r"".indexOf(currentChar) >= 0)
      {
        // Whitespace not allowed when parsing ""to""
        if (toInProgress)
          throwArrayException(arrStep);


        if (afterDigit)
        {
          // Last non-space was a digit - next non-space is ""to"" or comma
          digitAllowed = false;
          toAllowed    = !afterTo;
          commaAllowed = true;
        }
        else if (spaceRequired)
        {
          // This is the whitespace required after ""to""
          digitAllowed  = true;
          spaceRequired = false;
          digitRequired = true;  // At least one digit must follow
        }
      }
      else if (currentChar == 't')
      {
        if (!toAllowed)
          throwArrayException(arrStep);


        toInProgress = true;  // Next char must be the 'o' in ""to""
        commaAllowed = false;
        afterDigit   = false;
      }
      else if (currentChar == 'o')
      {
        if (!toInProgress)
          throwArrayException(arrStep);


        toInProgress  = false;
        toAllowed     = false;
        afterTo       = true;
        spaceRequired = true;  // ""to"" must be followed by whitespace
      }
      else
      {
        // Invalid character
        throwArrayException(arrStep);
      }
    }


    // Empty array or only whitespace found
    if (wildAllowed)
      throwArrayException(arrStep);


    // Incomplete ""to"" or comma sequence at end of subscript
    if (toInProgress || spaceRequired || digitRequired)
      throwArrayException(arrStep);
  }",1,12568
"        @Override
        public void addOptionValues(List<OptionValue> optionValues, Map<String, Object> context, Delegator delegator) {
            // first expand any conditions that need expanding based on the current context
            EntityCondition findCondition = null;
            if (UtilValidate.isNotEmpty(this.constraintList)) {
                List<EntityCondition> expandedConditionList = new LinkedList<>();
                for (EntityFinderUtil.Condition condition : constraintList) {
                    ModelEntity modelEntity = delegator.getModelEntity(this.entityName);
                    if (modelEntity == null) {
                        throw new IllegalArgumentException(""Error in entity-options: could not find entity ["" + this.entityName
                                + ""]"");
                    }
                    EntityCondition createdCondition = condition.createCondition(context, modelEntity,
                            delegator.getModelFieldTypeReader(modelEntity));
                    if (createdCondition != null) {
                        expandedConditionList.add(createdCondition);
                    }
                }
                findCondition = EntityCondition.makeCondition(expandedConditionList);
            }


            try {
                Locale locale = UtilMisc.ensureLocale(context.get(""locale""));
                ModelEntity modelEntity = delegator.getModelEntity(this.entityName);
                Boolean localizedOrderBy = UtilValidate.isNotEmpty(this.orderByList)
                        && ModelUtil.isPotentialLocalizedFields(modelEntity, this.orderByList);


                List<GenericValue> values = null;
                if (!localizedOrderBy) {
                    values = delegator.findList(this.entityName, findCondition, null, this.orderByList, null, this.cache);
                } else {
                    //if entity has localized label
                    values = delegator.findList(this.entityName, findCondition, null, null, null, this.cache);
                    values = EntityUtil.localizedOrderBy(values, this.orderByList, locale);
                }


                // filter-by-date if requested
                if (""true"".equals(this.filterByDate)) {
                    values = EntityUtil.filterByDate(values, true);
                } else if (!""false"".equals(this.filterByDate)) {
                    // not explicitly true or false, check to see if has fromDate and thruDate, if so do the filter
                    if (modelEntity != null && modelEntity.isField(""fromDate"") && modelEntity.isField(""thruDate"")) {
                        values = EntityUtil.filterByDate(values, true);
                    }
                }


                for (GenericValue value : values) {
                    // add key and description with string expansion, ie expanding ${} stuff, passing locale explicitly to expand value string because it won't be found in the Entity
                    MapStack<String> localContext = MapStack.create(context);
                    // Rendering code might try to modify the GenericEntity instance,
                    // so we make a copy of it.
                    Map<String, Object> genericEntityClone = UtilGenerics.cast(value.clone());
                    localContext.push(genericEntityClone);


                    // expand with the new localContext, which is locale aware
                    String optionDesc = this.description.expandString(localContext, locale);


                    Object keyFieldObject = value.get(this.getKeyFieldName());
                    if (keyFieldObject == null) {
                        throw new IllegalArgumentException(
                                ""The entity-options identifier (from key-name attribute, or default to the field name) [""
                                        + this.getKeyFieldName() + ""], may not be a valid key field name for the entity [""
                                        + this.entityName + ""]."");
                    }
                    String keyFieldValue = keyFieldObject.toString();
                    optionValues.add(new OptionValue(keyFieldValue, optionDesc));
                }
            } catch (GenericEntityException e) {
                Debug.logError(e, ""Error getting entity options in form"", module);
            }
        }",1,12658
"  @SuppressWarnings(""unchecked"")
  protected Map<byte[], List<Path>>[] handleBulkLoad(List<TableName> sTableList)
          throws IOException {
    Map<byte[], List<Path>>[] mapForSrc = new Map[sTableList.size()];
    List<String> activeFiles = new ArrayList<>();
    List<String> archiveFiles = new ArrayList<>();
    Pair<Map<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>>, List<byte[]>> pair =
            backupManager.readBulkloadRows(sTableList);
    Map<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>> map = pair.getFirst();
    FileSystem tgtFs;
    try {
      tgtFs = FileSystem.get(new URI(backupInfo.getBackupRootDir()), conf);
    } catch (URISyntaxException use) {
      throw new IOException(""Unable to get FileSystem"", use);
    }
    Path rootdir = FSUtils.getRootDir(conf);
    Path tgtRoot = new Path(new Path(backupInfo.getBackupRootDir()), backupId);


    for (Map.Entry<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>> tblEntry :
      map.entrySet()) {
      TableName srcTable = tblEntry.getKey();


      int srcIdx = getIndex(srcTable, sTableList);
      if (srcIdx < 0) {
        LOG.warn(""Couldn't find "" + srcTable + "" in source table List"");
        continue;
      }
      if (mapForSrc[srcIdx] == null) {
        mapForSrc[srcIdx] = new TreeMap<>(Bytes.BYTES_COMPARATOR);
      }
      Path tblDir = FSUtils.getTableDir(rootdir, srcTable);
      Path tgtTable = new Path(new Path(tgtRoot, srcTable.getNamespaceAsString()),
          srcTable.getQualifierAsString());
      for (Map.Entry<String,Map<String,List<Pair<String, Boolean>>>> regionEntry :
        tblEntry.getValue().entrySet()){
        String regionName = regionEntry.getKey();
        Path regionDir = new Path(tblDir, regionName);
        // map from family to List of hfiles
        for (Map.Entry<String,List<Pair<String, Boolean>>> famEntry :
          regionEntry.getValue().entrySet()) {
          String fam = famEntry.getKey();
          Path famDir = new Path(regionDir, fam);
          List<Path> files;
          if (!mapForSrc[srcIdx].containsKey(Bytes.toBytes(fam))) {
            files = new ArrayList<>();
            mapForSrc[srcIdx].put(Bytes.toBytes(fam), files);
          } else {
            files = mapForSrc[srcIdx].get(Bytes.toBytes(fam));
          }
          Path archiveDir = HFileArchiveUtil.getStoreArchivePath(conf, srcTable, regionName, fam);
          String tblName = srcTable.getQualifierAsString();
          Path tgtFam = new Path(new Path(tgtTable, regionName), fam);
          if (!tgtFs.mkdirs(tgtFam)) {
            throw new IOException(""couldn't create "" + tgtFam);
          }
          for (Pair<String, Boolean> fileWithState : famEntry.getValue()) {
            String file = fileWithState.getFirst();
            int idx = file.lastIndexOf(""/"");
            String filename = file;
            if (idx > 0) {
              filename = file.substring(idx+1);
            }
            Path p = new Path(famDir, filename);
            Path tgt = new Path(tgtFam, filename);
            Path archive = new Path(archiveDir, filename);
            if (fs.exists(p)) {
              if (LOG.isTraceEnabled()) {
                LOG.trace(""found bulk hfile "" + file + "" in "" + famDir + "" for "" + tblName);
              }
              if (LOG.isTraceEnabled()) {
                LOG.trace(""copying "" + p + "" to "" + tgt);
              }
              activeFiles.add(p.toString());
            } else if (fs.exists(archive)){
              LOG.debug(""copying archive "" + archive + "" to "" + tgt);
              archiveFiles.add(archive.toString());
            }
            files.add(tgt);
          }
        }
      }
    }


    copyBulkLoadedFiles(activeFiles, archiveFiles);
    backupManager.deleteBulkLoadedRows(pair.getSecond());
    return mapForSrc;
  }",1,12716
"	private void processInfoOutput(final BufferedReader stdout) {
		Matcher matcher;


		final MainControllerElement tempRoot = new MainControllerElement(""Temporal root"", this);
		readFullLineOnly(stdout);
		if (fastLine == null) {
			return;
		}
		matcher = MC_STATE_PATTERN.matcher(fastLine);
		if (matcher.matches()) {
			final String mcStateName = matcher.group(1);
			tempRoot.setStateInfo(new InformationElement(""State: "" + mcStateName));
			readFullLineOnly(stdout);


			suspectedLastState = getMCStateFromName(mcStateName);
		} else {
			fastLine = null;
			return;
		}
		if (fastLine != null && "" host information:"".equals(fastLine)) {
			readFullLineOnly(stdout);
		} else {
			fastLine = null;
			return;
		}
		if (fastLine != null) {
			if (fastLine.startsWith(""  -"")) {
				// host list
				while (fastLine != null && fastLine.startsWith(""  -"")) {
					processInfoOutputHC(stdout, tempRoot);
				}
			} else if (""  no HCs are connected"".equals(fastLine)) {
				readFullLineOnly(stdout);
			}
		} else {
			fastLine = null;
			return;
		}


		if (fastLine != null && PAUSE_PATTERN.matcher(fastLine).matches()) {
			tempRoot.setPauseInfo(new InformationElement(fastLine.trim()));
			readFullLineOnly(stdout);
		} else {
			fastLine = null;
			return;
		}
		if (fastLine != null && CONSOLE_LOGGING_PATTERN.matcher(fastLine).matches()) {
			tempRoot.setConsoleLoggingInfo(new InformationElement(fastLine.trim()));
		} else {
			fastLine = null;
			return;
		}
		if (mainControllerRoot != null) {
			mainControllerRoot.children().clear();
			mainControllerRoot.transferData(tempRoot);
		}


	}",1,12722
"    @Override
    public boolean isValidSyntax( Object value )
    {
        String strValue;


        if ( value == null )
        {
            if ( LOG.isDebugEnabled() )
            {
                LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, ""null"" ) );
            }
            
            return false;
        }


        if ( value instanceof String )
        {
            strValue = ( String ) value;
        }
        else if ( value instanceof byte[] )
        {
            strValue = Strings.utf8ToString( ( byte[] ) value );
        }
        else
        {
            strValue = value.toString();
        }


        // We must have at least '(cp)', '(xr)' or '(ca)'
        if ( strValue.length() < 4 )
        {
            if ( LOG.isDebugEnabled() )
            {
                LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, value ) );
            }
            
            return false;
        }


        // Check the opening and closing parenthesis
        if ( ( strValue.charAt( 0 ) != '(' )
            || ( strValue.charAt( strValue.length() - 1 ) != ')' ) )
        {
            if ( LOG.isDebugEnabled() )
            {
                LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, value ) );
            }
            
            return false;
        }


        Set<String> keywords = new HashSet<>();
        int len = strValue.length() - 1;
        boolean needKeyword = true;


        // 
        for ( int i = 1; i < len; /* */)
        {
            // Skip spaces
            while ( ( i < len ) && ( strValue.charAt( i ) == ' ' ) )
            {
                i++;
            }


            int pos = i;


            // Search for a keyword
            while ( ( i < len ) && Chars.isAlphaASCII( strValue, pos ) )
            {
                pos++;
            }


            if ( pos == i )
            {
                // No keyword : error
                if ( LOG.isDebugEnabled() )
                {
                    LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, value ) );
                }
                
                return false;
            }


            String keyword = strValue.substring( i, pos );
            i = pos;


            if ( !DSE_BITS.contains( keyword ) )
            {
                // Unknown keyword
                if ( LOG.isDebugEnabled() )
                {
                    LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, value ) );
                }
                
                return false;
            }


            // Check that the keyword has not been met
            if ( keywords.contains( keyword ) )
            {
                if ( LOG.isDebugEnabled() )
                {
                    LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, value ) );
                }
                
                return false;
            }


            keywords.add( keyword );
            needKeyword = false;


            // Skip spaces
            while ( ( i < len ) && ( strValue.charAt( i ) == ' ' ) )
            {
                i++;
            }


            // Do we have another keyword ?
            if ( ( i < len ) && ( strValue.charAt( i ) == '$' ) )
            {
                // yes
                i++;
                needKeyword = true;
            }
        }


        // We are done
        if ( LOG.isDebugEnabled() )
        {
            if ( needKeyword )
            {
                LOG.debug( I18n.err( I18n.ERR_13210_SYNTAX_INVALID, value ) );
            }
            else
            {
                LOG.debug( I18n.msg( I18n.MSG_13701_SYNTAX_VALID, value ) );
            }
        }


        return !needKeyword;
    }",1,12750
"    public void validateDepositDetailForUpdate(final JsonElement element, final FromJsonHelper fromApiJsonHelper,
            final DataValidatorBuilder baseDataValidator) {
        if (fromApiJsonHelper.parameterExists(nameParamName, element)) {
            final String name = fromApiJsonHelper.extractStringNamed(nameParamName, element);
            baseDataValidator.reset().parameter(nameParamName).value(name).notBlank().notExceedingLengthOf(100);
        }


        if (fromApiJsonHelper.parameterExists(shortNameParamName, element)) {
            final String shortName = fromApiJsonHelper.extractStringNamed(shortNameParamName, element);
            baseDataValidator.reset().parameter(shortNameParamName).value(shortName).notBlank().notExceedingLengthOf(4);
        }


        if (fromApiJsonHelper.parameterExists(descriptionParamName, element)) {
            final String description = fromApiJsonHelper.extractStringNamed(descriptionParamName, element);
            baseDataValidator.reset().parameter(descriptionParamName).value(description).notBlank().notExceedingLengthOf(500);
        }


        if (fromApiJsonHelper.parameterExists(currencyCodeParamName, element)) {
            final String currencyCode = fromApiJsonHelper.extractStringNamed(currencyCodeParamName, element);
            baseDataValidator.reset().parameter(currencyCodeParamName).value(currencyCode).notBlank();
        }


        if (fromApiJsonHelper.parameterExists(digitsAfterDecimalParamName, element)) {
            final Integer digitsAfterDecimal = fromApiJsonHelper.extractIntegerSansLocaleNamed(digitsAfterDecimalParamName, element);
            baseDataValidator.reset().parameter(digitsAfterDecimalParamName).value(digitsAfterDecimal).notNull().inMinMaxRange(0, 6);
        }


        if (fromApiJsonHelper.parameterExists(inMultiplesOfParamName, element)) {
            final Integer inMultiplesOf = fromApiJsonHelper.extractIntegerNamed(inMultiplesOfParamName, element, Locale.getDefault());
            baseDataValidator.reset().parameter(inMultiplesOfParamName).value(inMultiplesOf).ignoreIfNull().integerZeroOrGreater();
        }


        if (fromApiJsonHelper.parameterExists(nominalAnnualInterestRateParamName, element)) {
            final BigDecimal interestRate = fromApiJsonHelper.extractBigDecimalWithLocaleNamed(nominalAnnualInterestRateParamName, element);
            baseDataValidator.reset().parameter(nominalAnnualInterestRateParamName).value(interestRate).notNull().zeroOrPositiveAmount();
        }


        if (fromApiJsonHelper.parameterExists(interestCompoundingPeriodTypeParamName, element)) {
            final Integer interestCompoundingPeriodType = fromApiJsonHelper.extractIntegerSansLocaleNamed(
                    interestCompoundingPeriodTypeParamName, element);
            baseDataValidator.reset().parameter(interestCompoundingPeriodTypeParamName).value(interestCompoundingPeriodType).notNull()
                    .isOneOfTheseValues(SavingsCompoundingInterestPeriodType.integerValues());
        }


        if (fromApiJsonHelper.parameterExists(interestCalculationTypeParamName, element)) {
            final Integer interestCalculationType = fromApiJsonHelper.extractIntegerSansLocaleNamed(interestCalculationTypeParamName,
                    element);
            baseDataValidator.reset().parameter(interestCalculationTypeParamName).value(interestCalculationType).notNull()
                    .inMinMaxRange(1, 2);
        }


        if (fromApiJsonHelper.parameterExists(interestCalculationDaysInYearTypeParamName, element)) {
            final Integer interestCalculationDaysInYearType = fromApiJsonHelper.extractIntegerSansLocaleNamed(
                    interestCalculationDaysInYearTypeParamName, element);
            baseDataValidator.reset().parameter(interestCalculationDaysInYearTypeParamName).value(interestCalculationDaysInYearType)
                    .notNull().isOneOfTheseValues(360, 365);
        }


        if (fromApiJsonHelper.parameterExists(minRequiredOpeningBalanceParamName, element)) {
            final BigDecimal minOpeningBalance = fromApiJsonHelper.extractBigDecimalWithLocaleNamed(minRequiredOpeningBalanceParamName,
                    element);
            baseDataValidator.reset().parameter(minRequiredOpeningBalanceParamName).value(minOpeningBalance).ignoreIfNull()
                    .zeroOrPositiveAmount();
        }


        if (fromApiJsonHelper.parameterExists(lockinPeriodFrequencyParamName, element)) {
            final Integer lockinPeriodFrequency = fromApiJsonHelper.extractIntegerWithLocaleNamed(lockinPeriodFrequencyParamName, element);
            baseDataValidator.reset().parameter(lockinPeriodFrequencyParamName).value(lockinPeriodFrequency).ignoreIfNull()
                    .integerZeroOrGreater();
        }


        if (fromApiJsonHelper.parameterExists(lockinPeriodFrequencyTypeParamName, element)) {
            final Integer lockinPeriodFrequencyType = fromApiJsonHelper.extractIntegerSansLocaleNamed(lockinPeriodFrequencyTypeParamName,
                    element);
            baseDataValidator.reset().parameter(lockinPeriodFrequencyTypeParamName).value(lockinPeriodFrequencyType).inMinMaxRange(0, 3);
        }


        if (fromApiJsonHelper.parameterExists(withdrawalFeeForTransfersParamName, element)) {
            final Boolean isWithdrawalFeeApplicableForTransfers = fromApiJsonHelper.extractBooleanNamed(withdrawalFeeForTransfersParamName,
                    element);
            baseDataValidator.reset().parameter(withdrawalFeeForTransfersParamName).value(isWithdrawalFeeApplicableForTransfers)
                    .ignoreIfNull().validateForBooleanValue();
        }


        if (fromApiJsonHelper.parameterExists(feeAmountParamName, element)) {
            final BigDecimal annualFeeAmount = fromApiJsonHelper.extractBigDecimalWithLocaleNamed(feeAmountParamName, element);
            baseDataValidator.reset().parameter(feeAmountParamName).value(annualFeeAmount).ignoreIfNull().zeroOrPositiveAmount();
        }


        if (fromApiJsonHelper.parameterExists(feeOnMonthDayParamName, element)) {
            final MonthDay monthDayOfAnnualFee = fromApiJsonHelper.extractMonthDayNamed(feeOnMonthDayParamName, element);
            baseDataValidator.reset().parameter(feeOnMonthDayParamName).value(monthDayOfAnnualFee).ignoreIfNull();
        }


        if (this.fromApiJsonHelper.parameterExists(minBalanceForInterestCalculationParamName, element)) {
            final BigDecimal minBalanceForInterestCalculation = this.fromApiJsonHelper.extractBigDecimalWithLocaleNamed(
                    minBalanceForInterestCalculationParamName, element);
            baseDataValidator.reset().parameter(minBalanceForInterestCalculationParamName).value(minBalanceForInterestCalculation)
                    .ignoreIfNull().zeroOrPositiveAmount();
        }


        final Long savingsControlAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_CONTROL.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_CONTROL.getValue()).value(savingsControlAccountId)
                .ignoreIfNull().integerGreaterThanZero();


        final Long savingsReferenceAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_REFERENCE.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_REFERENCE.getValue())
                .value(savingsReferenceAccountId).ignoreIfNull().integerGreaterThanZero();


        final Long transfersInSuspenseAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.TRANSFERS_SUSPENSE.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.TRANSFERS_SUSPENSE.getValue())
                .value(transfersInSuspenseAccountId).ignoreIfNull().integerGreaterThanZero();


        final Long interestOnSavingsAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INTEREST_ON_SAVINGS.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INTEREST_ON_SAVINGS.getValue())
                .value(interestOnSavingsAccountId).ignoreIfNull().integerGreaterThanZero();


        final Long incomeFromFeeId = fromApiJsonHelper.extractLongNamed(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_FEES.getValue(),
                element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_FEES.getValue()).value(incomeFromFeeId)
                .ignoreIfNull().integerGreaterThanZero();


        final Long incomeFromPenaltyId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_PENALTIES.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_PENALTIES.getValue()).value(incomeFromPenaltyId)
                .ignoreIfNull().integerGreaterThanZero();


        validatePaymentChannelFundSourceMappings(fromApiJsonHelper, baseDataValidator, element);
        validateChargeToIncomeAccountMappings(fromApiJsonHelper, baseDataValidator, element);
        validateTaxWithHoldingParams(baseDataValidator, element, false);
    }",1,12755
"    @SuppressWarnings(""try"")
    private void doRun(Map<Method, CEntryPointData> entryPoints, Method mainEntryPoint,
                    JavaMainSupport javaMainSupport, String imageName, AbstractBootImage.NativeImageKind k,
                    SubstitutionProcessor harnessSubstitutions,
                    ForkJoinPool compilationExecutor, ForkJoinPool analysisExecutor) {
        List<HostedMethod> hostedEntryPoints = new ArrayList<>();


        OptionValues options = HostedOptionValues.singleton();
        SnippetReflectionProvider originalSnippetReflection = GraalAccess.getOriginalSnippetReflection();
        try (DebugContext debug = DebugContext.create(options, new GraalDebugHandlersFactory(originalSnippetReflection))) {
            setupNativeImage(imageName, options, entryPoints, javaMainSupport, harnessSubstitutions, analysisExecutor, originalSnippetReflection, debug);


            boolean returnAfterAnalysis = runPointsToAnalysis(imageName, options, debug);
            if (returnAfterAnalysis) {
                return;
            }


            NativeImageHeap heap;
            HostedMethod mainEntryPointHostedStub;
            HostedMetaAccess hMetaAccess;
            SharedRuntimeConfigurationBuilder runtime;
            try (StopTimer t = new Timer(imageName, ""universe"").start()) {
                hUniverse = new HostedUniverse(bigbang);
                hMetaAccess = new HostedMetaAccess(hUniverse, bigbang.getMetaAccess());


                new UniverseBuilder(aUniverse, bigbang.getMetaAccess(), hUniverse, hMetaAccess, HostedConfiguration.instance().createStaticAnalysisResultsBuilder(bigbang, hUniverse),
                                bigbang.getUnsupportedFeatures()).build(debug);


                runtime = new HostedRuntimeConfigurationBuilder(options, bigbang.getHostVM(), hUniverse, hMetaAccess, bigbang.getProviders()).build();
                registerGraphBuilderPlugins(featureHandler, runtime.getRuntimeConfig(), (HostedProviders) runtime.getRuntimeConfig().getProviders(), bigbang.getMetaAccess(), aUniverse,
                                hMetaAccess, hUniverse,
                                nativeLibraries, loader, false, true, bigbang.getAnnotationSubstitutionProcessor(), new SubstrateClassInitializationPlugin((SVMHost) aUniverse.hostVM()),
                                bigbang.getHostVM().getClassInitializationSupport());


                if (NativeImageOptions.PrintUniverse.getValue()) {
                    printTypes();
                }


                /* Find the entry point methods in the hosted world. */
                for (AnalysisMethod m : aUniverse.getMethods()) {
                    if (m.isEntryPoint()) {
                        HostedMethod found = hUniverse.lookup(m);
                        assert found != null;
                        hostedEntryPoints.add(found);
                    }
                }
                /* Find main entry point */
                if (mainEntryPoint != null) {
                    AnalysisMethod analysisStub = CEntryPointCallStubSupport.singleton().getStubForMethod(mainEntryPoint);
                    mainEntryPointHostedStub = (HostedMethod) hMetaAccess.getUniverse().lookup(analysisStub);
                    assert hostedEntryPoints.contains(mainEntryPointHostedStub);
                } else {
                    mainEntryPointHostedStub = null;
                }
                if (hostedEntryPoints.size() == 0) {
                    throw UserError.abort(""Warning: no entry points found, i.e., no method annotated with @"" + CEntryPoint.class.getSimpleName());
                }


                heap = new NativeImageHeap(aUniverse, hUniverse, hMetaAccess);


                BeforeCompilationAccessImpl config = new BeforeCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.beforeCompilation(config));


                bigbang.getUnsupportedFeatures().report(bigbang);
            } catch (UnsupportedFeatureException ufe) {
                throw UserError.abort(ufe.getMessage());
            }


            recordMethodsWithStackValues();
            recordRestrictHeapAccessCallees(aUniverse.getMethods());


            /*
             * After this point, all TypeFlow (and therefore also TypeState) objects are unreachable
             * and can be garbage collected. This is important to keep the overall memory footprint
             * low. However, this also means we no longer have complete call chain information. Only
             * the summarized information stored in the StaticAnalysisResult objects is available
             * after this point.
             */
            bigbang.cleanupAfterAnalysis();


            NativeImageCodeCache codeCache;
            CompileQueue compileQueue;
            try (StopTimer t = new Timer(imageName, ""compile"").start()) {
                compileQueue = HostedConfiguration.instance().createCompileQueue(debug, featureHandler, hUniverse, runtime, DeoptTester.enabled(), bigbang.getProviders().getSnippetReflection(),
                                compilationExecutor);
                compileQueue.finish(debug);


                /* release memory taken by graphs for the image writing */
                hUniverse.getMethods().forEach(HostedMethod::clear);


                codeCache = NativeImageCodeCacheFactory.get().newCodeCache(compileQueue, heap);
                codeCache.layoutConstants();
                codeCache.layoutMethods(debug, imageName);


                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.afterCompilation(config));
            }


            try (Indent indent = debug.logAndIndent(""create native image"")) {
                try (DebugContext.Scope buildScope = debug.scope(""CreateBootImage"")) {
                    try (StopTimer t = new Timer(imageName, ""image"").start()) {


                        // Start building the model of the native image heap.
                        heap.addInitialObjects();
                        // Then build the model of the code cache, which can
                        // add objects to the native image heap.
                        codeCache.addConstantsToHeap();
                        // Finish building the model of the native image heap.
                        heap.addTrailingObjects();


                        AfterHeapLayoutAccessImpl config = new AfterHeapLayoutAccessImpl(featureHandler, loader, hMetaAccess, debug);
                        featureHandler.forEachFeature(feature -> feature.afterHeapLayout(config));


                        this.image = AbstractBootImage.create(k, hUniverse, hMetaAccess, nativeLibraries, heap, codeCache, hostedEntryPoints, mainEntryPointHostedStub, loader.getClassLoader());
                        image.build(debug);
                        if (NativeImageOptions.PrintUniverse.getValue()) {
                            /*
                             * This debug output must be printed _after_ and not _during_ image
                             * building, because it adds some PrintStream objects to static fields,
                             * which disrupts the heap.
                             */
                            codeCache.printCompilationResults();
                        }
                    }
                }
            }


            BeforeImageWriteAccessImpl beforeConfig = new BeforeImageWriteAccessImpl(featureHandler, loader, imageName, image,
                            runtime.getRuntimeConfig(), aUniverse, hUniverse, optionProvider, hMetaAccess, debug);
            featureHandler.forEachFeature(feature -> feature.beforeImageWrite(beforeConfig));


            try (StopTimer t = new Timer(imageName, ""write"").start()) {
                /*
                 * This will write the debug info too -- i.e. we may be writing more than one file,
                 * if the debug info is in a separate file. We need to push writing the file to the
                 * image implementation, because whether the debug info and image share a file or
                 * not is an implementation detail of the image.
                 */
                Path tmpDir = tempDirectory();
                Path imagePath = image.write(debug, generatedFiles(HostedOptionValues.singleton()), tmpDir, imageName, beforeConfig).getOutputFile();


                AfterImageWriteAccessImpl afterConfig = new AfterImageWriteAccessImpl(featureHandler, loader, hUniverse, imagePath, tmpDir, image.getBootImageKind(), debug);
                featureHandler.forEachFeature(feature -> feature.afterImageWrite(afterConfig));
            }
        }
    }",1,12782
"  private TtmlRegion parseRegionAttributes(
      XmlPullParser xmlParser, CellResolution cellResolution, TtsExtent ttsExtent) {
    String regionId = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_ID);
    if (regionId == null) {
      return null;
    }


    float position;
    float line;


    String regionOrigin = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_TTS_ORIGIN);
    if (regionOrigin != null) {
      Matcher originPercentageMatcher = PERCENTAGE_COORDINATES.matcher(regionOrigin);
      Matcher originPixelMatcher = PIXEL_COORDINATES.matcher(regionOrigin);
      if (originPercentageMatcher.matches()) {
        try {
          position = Float.parseFloat(originPercentageMatcher.group(1)) / 100f;
          line = Float.parseFloat(originPercentageMatcher.group(2)) / 100f;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed origin: "" + regionOrigin);
          return null;
        }
      } else if (originPixelMatcher.matches()) {
        if (ttsExtent == null) {
          Log.w(TAG, ""Ignoring region with missing tts:extent: "" + regionOrigin);
          return null;
        }
        try {
          int width = Integer.parseInt(originPixelMatcher.group(1));
          int height = Integer.parseInt(originPixelMatcher.group(2));
          // Convert pixel values to fractions.
          position = width / (float) ttsExtent.width;
          line = height / (float) ttsExtent.height;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed origin: "" + regionOrigin);
          return null;
        }
      } else {
        Log.w(TAG, ""Ignoring region with unsupported origin: "" + regionOrigin);
        return null;
      }
    } else {
      Log.w(TAG, ""Ignoring region without an origin"");
      return null;
      // TODO: Should default to top left as below in this case, but need to fix
      // https://github.com/google/ExoPlayer/issues/2953 first.
      // Origin is omitted. Default to top left.
      // position = 0;
      // line = 0;
    }


    float width;
    float height;
    String regionExtent = XmlPullParserUtil.getAttributeValue(xmlParser, TtmlNode.ATTR_TTS_EXTENT);
    if (regionExtent != null) {
      Matcher extentPercentageMatcher = PERCENTAGE_COORDINATES.matcher(regionExtent);
      Matcher extentPixelMatcher = PIXEL_COORDINATES.matcher(regionExtent);
      if (extentPercentageMatcher.matches()) {
        try {
          width = Float.parseFloat(extentPercentageMatcher.group(1)) / 100f;
          height = Float.parseFloat(extentPercentageMatcher.group(2)) / 100f;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed extent: "" + regionOrigin);
          return null;
        }
      } else if (extentPixelMatcher.matches()) {
        if (ttsExtent == null) {
          Log.w(TAG, ""Ignoring region with missing tts:extent: "" + regionOrigin);
          return null;
        }
        try {
          int extentWidth = Integer.parseInt(extentPixelMatcher.group(1));
          int extentHeight = Integer.parseInt(extentPixelMatcher.group(2));
          // Convert pixel values to fractions.
          width = extentWidth / (float) ttsExtent.width;
          height = extentHeight / (float) ttsExtent.height;
        } catch (NumberFormatException e) {
          Log.w(TAG, ""Ignoring region with malformed extent: "" + regionOrigin);
          return null;
        }
      } else {
        Log.w(TAG, ""Ignoring region with unsupported extent: "" + regionOrigin);
        return null;
      }
    } else {
      Log.w(TAG, ""Ignoring region without an extent"");
      return null;
      // TODO: Should default to extent of parent as below in this case, but need to fix
      // https://github.com/google/ExoPlayer/issues/2953 first.
      // Extent is omitted. Default to extent of parent.
      // width = 1;
      // height = 1;
    }


    @Cue.AnchorType int lineAnchor = Cue.ANCHOR_TYPE_START;
    String displayAlign = XmlPullParserUtil.getAttributeValue(xmlParser,
        TtmlNode.ATTR_TTS_DISPLAY_ALIGN);
    if (displayAlign != null) {
      switch (Util.toLowerInvariant(displayAlign)) {
        case ""center"":
          lineAnchor = Cue.ANCHOR_TYPE_MIDDLE;
          line += height / 2;
          break;
        case ""after"":
          lineAnchor = Cue.ANCHOR_TYPE_END;
          line += height;
          break;
        default:
          // Default ""before"" case. Do nothing.
          break;
      }
    }


    float regionTextHeight = 1.0f / cellResolution.rows;
    return new TtmlRegion(
        regionId,
        position,
        line,
        /* lineType= */ Cue.LINE_TYPE_FRACTION,
        lineAnchor,
        width,
        /* textSizeType= */ Cue.TEXT_SIZE_TYPE_FRACTIONAL_IGNORE_PADDING,
        /* textSize= */ regionTextHeight);
  }",1,13223
"    @Override public Iterator<Row> getRows(Session ses, SearchRow first, SearchRow last) {
        List<Row> rows = new ArrayList<>();


        Collection<ClusterNode> nodes;


        SqlSystemViewColumnCondition idCond = conditionForColumn(""NODE_ID"", first, last);


        if (idCond.isEquality()) {
            try {
                UUID nodeId = uuidFromValue(idCond.valueForEquality());


                ClusterNode node = nodeId == null ? null : ctx.discovery().node(nodeId);


                if (node != null)
                    nodes = Collections.singleton(node);
                else
                    nodes = Collections.emptySet();
            }
            catch (Exception e) {
                nodes = Collections.emptySet();
            }
        }
        else
            nodes = F.concat(false, ctx.discovery().allNodes(), ctx.discovery().daemonNodes());


        for (ClusterNode node : nodes) {
            if (node != null) {
                ClusterMetrics metrics = node.metrics();


                rows.add(
                    createRow(
                        ses,
                        node.id(),
                        valueTimestampFromMillis(metrics.getLastUpdateTime()),
                        metrics.getMaximumActiveJobs(),
                        metrics.getCurrentActiveJobs(),
                        metrics.getAverageActiveJobs(),
                        metrics.getMaximumWaitingJobs(),
                        metrics.getCurrentWaitingJobs(),
                        metrics.getAverageWaitingJobs(),
                        metrics.getMaximumRejectedJobs(),
                        metrics.getCurrentRejectedJobs(),
                        metrics.getAverageRejectedJobs(),
                        metrics.getTotalRejectedJobs(),
                        metrics.getMaximumCancelledJobs(),
                        metrics.getCurrentCancelledJobs(),
                        metrics.getAverageCancelledJobs(),
                        metrics.getTotalCancelledJobs(),
                        metrics.getMaximumJobWaitTime(),
                        metrics.getCurrentJobWaitTime(),
                        (long)metrics.getAverageJobWaitTime(),
                        metrics.getMaximumJobExecuteTime(),
                        metrics.getCurrentJobExecuteTime(),
                        (long)metrics.getAverageJobExecuteTime(),
                        metrics.getTotalJobsExecutionTime(),
                        metrics.getTotalExecutedJobs(),
                        metrics.getTotalExecutedTasks(),
                        metrics.getTotalBusyTime(),
                        metrics.getTotalIdleTime(),
                        metrics.getCurrentIdleTime(),
                        metrics.getBusyTimePercentage(),
                        metrics.getIdleTimePercentage(),
                        metrics.getTotalCpus(),
                        metrics.getCurrentCpuLoad(),
                        metrics.getAverageCpuLoad(),
                        metrics.getCurrentGcCpuLoad(),
                        metrics.getHeapMemoryInitialized(),
                        metrics.getHeapMemoryUsed(),
                        metrics.getHeapMemoryCommitted(),
                        metrics.getHeapMemoryMaximum(),
                        metrics.getHeapMemoryTotal(),
                        metrics.getNonHeapMemoryInitialized(),
                        metrics.getNonHeapMemoryUsed(),
                        metrics.getNonHeapMemoryCommitted(),
                        metrics.getNonHeapMemoryMaximum(),
                        metrics.getNonHeapMemoryTotal(),
                        metrics.getUpTime(),
                        valueTimestampFromMillis(metrics.getStartTime()),
                        valueTimestampFromMillis(metrics.getNodeStartTime()),
                        metrics.getLastDataVersion(),
                        metrics.getCurrentThreadCount(),
                        metrics.getMaximumThreadCount(),
                        metrics.getTotalStartedThreadCount(),
                        metrics.getCurrentDaemonThreadCount(),
                        metrics.getSentMessagesCount(),
                        metrics.getSentBytesCount(),
                        metrics.getReceivedMessagesCount(),
                        metrics.getReceivedBytesCount(),
                        metrics.getOutboundMessagesQueueSize()
                    )
                );
            }
        }


        return rows.iterator();
    }",1,13348
"    @SuppressWarnings(""try"")
    private void doRun(Map<Method, CEntryPointData> entryPoints, Method mainEntryPoint,
                    JavaMainSupport javaMainSupport, String imageName, AbstractBootImage.NativeImageKind k,
                    SubstitutionProcessor harnessSubstitutions,
                    ForkJoinPool compilationExecutor, ForkJoinPool analysisExecutor) {
        List<HostedMethod> hostedEntryPoints = new ArrayList<>();


        OptionValues options = HostedOptionValues.singleton();
        SnippetReflectionProvider originalSnippetReflection = GraalAccess.getOriginalSnippetReflection();
        try (DebugContext debug = DebugContext.create(options, new GraalDebugHandlersFactory(originalSnippetReflection))) {
            setupNativeImage(imageName, options, entryPoints, javaMainSupport, harnessSubstitutions, analysisExecutor, originalSnippetReflection, debug);


            boolean returnAfterAnalysis = runPointsToAnalysis(imageName, options, debug);
            if (returnAfterAnalysis) {
                return;
            }


            NativeImageHeap heap;
            HostedMethod mainEntryPointHostedStub;
            HostedMetaAccess hMetaAccess;
            SharedRuntimeConfigurationBuilder runtime;
            try (StopTimer t = new Timer(imageName, ""universe"").start()) {
                hUniverse = new HostedUniverse(bigbang);
                hMetaAccess = new HostedMetaAccess(hUniverse, bigbang.getMetaAccess());


                new UniverseBuilder(aUniverse, bigbang.getMetaAccess(), hUniverse, hMetaAccess, HostedConfiguration.instance().createStaticAnalysisResultsBuilder(bigbang, hUniverse),
                                bigbang.getUnsupportedFeatures()).build(debug);


                runtime = new HostedRuntimeConfigurationBuilder(options, bigbang.getHostVM(), hUniverse, hMetaAccess, bigbang.getProviders()).build();
                registerGraphBuilderPlugins(featureHandler, runtime.getRuntimeConfig(), (HostedProviders) runtime.getRuntimeConfig().getProviders(), bigbang.getMetaAccess(), aUniverse,
                                hMetaAccess, hUniverse,
                                nativeLibraries, loader, false, true, bigbang.getAnnotationSubstitutionProcessor(), new SubstrateClassInitializationPlugin((SVMHost) aUniverse.hostVM()),
                                bigbang.getHostVM().getClassInitializationSupport());


                if (NativeImageOptions.PrintUniverse.getValue()) {
                    printTypes();
                }


                /* Find the entry point methods in the hosted world. */
                for (AnalysisMethod m : aUniverse.getMethods()) {
                    if (m.isEntryPoint()) {
                        HostedMethod found = hUniverse.lookup(m);
                        assert found != null;
                        hostedEntryPoints.add(found);
                    }
                }
                /* Find main entry point */
                if (mainEntryPoint != null) {
                    AnalysisMethod analysisStub = CEntryPointCallStubSupport.singleton().getStubForMethod(mainEntryPoint);
                    mainEntryPointHostedStub = (HostedMethod) hMetaAccess.getUniverse().lookup(analysisStub);
                    assert hostedEntryPoints.contains(mainEntryPointHostedStub);
                } else {
                    mainEntryPointHostedStub = null;
                }
                if (hostedEntryPoints.size() == 0) {
                    throw UserError.abort(""Warning: no entry points found, i.e., no method annotated with @"" + CEntryPoint.class.getSimpleName());
                }


                heap = new NativeImageHeap(aUniverse, hUniverse, hMetaAccess);


                BeforeCompilationAccessImpl config = new BeforeCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.beforeCompilation(config));


                bigbang.getUnsupportedFeatures().report(bigbang);
            } catch (UnsupportedFeatureException ufe) {
                throw UserError.abort(ufe.getMessage());
            }


            recordMethodsWithStackValues();
            recordRestrictHeapAccessCallees(aUniverse.getMethods());


            /*
             * After this point, all TypeFlow (and therefore also TypeState) objects are unreachable
             * and can be garbage collected. This is important to keep the overall memory footprint
             * low. However, this also means we no longer have complete call chain information. Only
             * the summarized information stored in the StaticAnalysisResult objects is available
             * after this point.
             */
            bigbang.cleanupAfterAnalysis();


            NativeImageCodeCache codeCache;
            CompileQueue compileQueue;
            try (StopTimer t = new Timer(imageName, ""compile"").start()) {
                compileQueue = HostedConfiguration.instance().createCompileQueue(debug, featureHandler, hUniverse, runtime, DeoptTester.enabled(), bigbang.getProviders().getSnippetReflection(),
                                compilationExecutor);
                compileQueue.finish(debug);


                /* release memory taken by graphs for the image writing */
                hUniverse.getMethods().forEach(HostedMethod::clear);


                codeCache = NativeImageCodeCacheFactory.get().newCodeCache(compileQueue, heap);
                codeCache.layoutConstants();
                codeCache.layoutMethods(debug, imageName);


                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
                featureHandler.forEachFeature(feature -> feature.afterCompilation(config));
            }


            try (Indent indent = debug.logAndIndent(""create native image"")) {
                try (DebugContext.Scope buildScope = debug.scope(""CreateBootImage"")) {
                    try (StopTimer t = new Timer(imageName, ""image"").start()) {


                        // Start building the model of the native image heap.
                        heap.addInitialObjects();
                        // Then build the model of the code cache, which can
                        // add objects to the native image heap.
                        codeCache.addConstantsToHeap();
                        // Finish building the model of the native image heap.
                        heap.addTrailingObjects();


                        AfterHeapLayoutAccessImpl config = new AfterHeapLayoutAccessImpl(featureHandler, loader, hMetaAccess, debug);
                        featureHandler.forEachFeature(feature -> feature.afterHeapLayout(config));


                        this.image = AbstractBootImage.create(k, hUniverse, hMetaAccess, nativeLibraries, heap, codeCache, hostedEntryPoints, mainEntryPointHostedStub, loader.getClassLoader());
                        image.build(debug);
                        if (NativeImageOptions.PrintUniverse.getValue()) {
                            /*
                             * This debug output must be printed _after_ and not _during_ image
                             * building, because it adds some PrintStream objects to static fields,
                             * which disrupts the heap.
                             */
                            codeCache.printCompilationResults();
                        }
                    }
                }
            }


            BeforeImageWriteAccessImpl beforeConfig = new BeforeImageWriteAccessImpl(featureHandler, loader, imageName, image,
                            runtime.getRuntimeConfig(), aUniverse, hUniverse, optionProvider, hMetaAccess, debug);
            featureHandler.forEachFeature(feature -> feature.beforeImageWrite(beforeConfig));


            try (StopTimer t = new Timer(imageName, ""write"").start()) {
                /*
                 * This will write the debug info too -- i.e. we may be writing more than one file,
                 * if the debug info is in a separate file. We need to push writing the file to the
                 * image implementation, because whether the debug info and image share a file or
                 * not is an implementation detail of the image.
                 */
                Path tmpDir = tempDirectory();
                Path imagePath = image.write(debug, generatedFiles(HostedOptionValues.singleton()), tmpDir, imageName, beforeConfig).getOutputFile();


                AfterImageWriteAccessImpl afterConfig = new AfterImageWriteAccessImpl(featureHandler, loader, hUniverse, imagePath, tmpDir, image.getBootImageKind(), debug);
                featureHandler.forEachFeature(feature -> feature.afterImageWrite(afterConfig));
            }
        }
    }",1,13493
"   private static byte[] encodeBase64(byte[] binaryData, boolean isChunked)
   {
      int lengthDataBits = binaryData.length * EIGHTBIT;
      int fewerThan24bits = lengthDataBits % TWENTYFOURBITGROUP;
      int numberTriplets = lengthDataBits / TWENTYFOURBITGROUP;
      byte encodedData[] = null;
      int encodedDataLength = 0;
      int nbrChunks = 0;


      if (fewerThan24bits != 0)
      {
         //data not divisible by 24 bit
         encodedDataLength = (numberTriplets + 1) * 4;
      }
      else
      {
         // 16 or 8 bit
         encodedDataLength = numberTriplets * 4;
      }


      // If the output is to be ""chunked"" into 76 character sections,
      // for compliance with RFC 2045 MIME, then it is important to
      // allow for extra length to account for the separator(s)
      if (isChunked)
      {


         nbrChunks =
                 (CHUNK_SEPARATOR.length == 0
                 ? 0
                 : (int)Math.ceil((float)encodedDataLength / CHUNK_SIZE));
         encodedDataLength += nbrChunks * CHUNK_SEPARATOR.length;
      }


      encodedData = new byte[encodedDataLength];


      byte k = 0, l = 0, b1 = 0, b2 = 0, b3 = 0;


      int encodedIndex = 0;
      int dataIndex = 0;
      int i = 0;
      int nextSeparatorIndex = CHUNK_SIZE;
      int chunksSoFar = 0;


      //log.debug(""number of triplets = "" + numberTriplets);
      for (i = 0; i < numberTriplets; i++)
      {
         dataIndex = i * 3;
         b1 = binaryData[dataIndex];
         b2 = binaryData[dataIndex + 1];
         b3 = binaryData[dataIndex + 2];


         //log.debug(""b1= "" + b1 +"", b2= "" + b2 + "", b3= "" + b3);


         l = (byte)(b2 & 0x0f);
         k = (byte)(b1 & 0x03);


         byte val1 =
                 ((b1 & SIGN) == 0)
                 ? (byte)(b1 >> 2)
                 : (byte)((b1) >> 2 ^ 0xc0);
         byte val2 =
                 ((b2 & SIGN) == 0)
                 ? (byte)(b2 >> 4)
                 : (byte)((b2) >> 4 ^ 0xf0);
         byte val3 =
                 ((b3 & SIGN) == 0)
                 ? (byte)(b3 >> 6)
                 : (byte)((b3) >> 6 ^ 0xfc);


         encodedData[encodedIndex] = lookUpBase64Alphabet[val1];
         //log.debug( ""val2 = "" + val2 );
         //log.debug( ""k4   = "" + (k<<4) );
         //log.debug(  ""vak  = "" + (val2 | (k<<4)) );
         encodedData[encodedIndex + 1] =
                 lookUpBase64Alphabet[val2 | (k << 4)];
         encodedData[encodedIndex + 2] =
                 lookUpBase64Alphabet[(l << 2) | val3];
         encodedData[encodedIndex + 3] = lookUpBase64Alphabet[b3 & 0x3f];


         encodedIndex += 4;


         // If we are chunking, let's put a chunk separator down.
         if (isChunked)
         {
            // this assumes that CHUNK_SIZE % 4 == 0
            if (encodedIndex == nextSeparatorIndex)
            {
               System.arraycopy(
                       CHUNK_SEPARATOR,
                       0,
                       encodedData,
                       encodedIndex,
                       CHUNK_SEPARATOR.length);
               chunksSoFar++;
               nextSeparatorIndex =
                       (CHUNK_SIZE * (chunksSoFar + 1))
                       + (chunksSoFar * CHUNK_SEPARATOR.length);
               encodedIndex += CHUNK_SEPARATOR.length;
            }
         }
      }


      // form integral number of 6-bit groups
      dataIndex = i * 3;


      if (fewerThan24bits == EIGHTBIT)
      {
         b1 = binaryData[dataIndex];
         k = (byte)(b1 & 0x03);
         //log.debug(""b1="" + b1);
         //log.debug(""b1<<2 = "" + (b1>>2) );
         byte val1 =
                 ((b1 & SIGN) == 0)
                 ? (byte)(b1 >> 2)
                 : (byte)((b1) >> 2 ^ 0xc0);
         encodedData[encodedIndex] = lookUpBase64Alphabet[val1];
         encodedData[encodedIndex + 1] = lookUpBase64Alphabet[k << 4];
         encodedData[encodedIndex + 2] = PAD;
         encodedData[encodedIndex + 3] = PAD;
      }
      else if (fewerThan24bits == SIXTEENBIT)
      {


         b1 = binaryData[dataIndex];
         b2 = binaryData[dataIndex + 1];
         l = (byte)(b2 & 0x0f);
         k = (byte)(b1 & 0x03);


         byte val1 =
                 ((b1 & SIGN) == 0)
                 ? (byte)(b1 >> 2)
                 : (byte)((b1) >> 2 ^ 0xc0);
         byte val2 =
                 ((b2 & SIGN) == 0)
                 ? (byte)(b2 >> 4)
                 : (byte)((b2) >> 4 ^ 0xf0);


         encodedData[encodedIndex] = lookUpBase64Alphabet[val1];
         encodedData[encodedIndex + 1] =
                 lookUpBase64Alphabet[val2 | (k << 4)];
         encodedData[encodedIndex + 2] = lookUpBase64Alphabet[l << 2];
         encodedData[encodedIndex + 3] = PAD;
      }


      if (isChunked)
      {
         // we also add a separator to the end of the final chunk.
         if (chunksSoFar < nbrChunks)
         {
            System.arraycopy(
                    CHUNK_SEPARATOR,
                    0,
                    encodedData,
                    encodedDataLength - CHUNK_SEPARATOR.length,
                    CHUNK_SEPARATOR.length);
         }
      }


      return encodedData;
   }",1,13507
"    protected void refreshInternal(Collection objs, OpCallbacks call) {
    	if (objs == null || objs.isEmpty())
    		return;
        List<Exception> exceps = null;
        try {
            // collect instances that need a refresh
            Collection<OpenJPAStateManager> load = null;
            StateManagerImpl sm;
            Object obj;
            for (Iterator<?> itr = objs.iterator(); itr.hasNext();) {
                obj = itr.next();
                if (obj == null)
                    continue;


                try {
                    sm = getStateManagerImpl(obj, true);
                    if ((processArgument(OpCallbacks.OP_REFRESH, obj, sm, call)
                        & OpCallbacks.ACT_RUN) == 0)
                        continue;


                    if (sm != null) {
                        if (sm.isDetached())
                            throw newDetachedException(obj, ""refresh"");
                        else if (sm.beforeRefresh(true)) {
                        	if (load == null)
                        		load = new ArrayList<>(objs.size());
                            load.add(sm);
                        }
                        int level = _fc.getReadLockLevel();
                        int timeout = _fc.getLockTimeout();
                        _lm.refreshLock(sm, level, timeout, null);
                        sm.readLocked(level, level);
                    } else if (assertPersistenceCapable(obj).pcIsDetached()
                        == Boolean.TRUE)
                        throw newDetachedException(obj, ""refresh"");
                } catch (OpenJPAException ke) {
                    exceps = add(exceps, ke);
                }
            }


            // refresh all
            if (load != null) {
                Collection<Object> failed = _store.loadAll(load, null,
                    StoreManager.FORCE_LOAD_REFRESH, _fc, null);
                if (failed != null && !failed.isEmpty())
                    exceps = add(exceps, newObjectNotFoundException(failed));


                // perform post-refresh transitions and make sure all fetch
                // group fields are loaded
                for (Iterator<OpenJPAStateManager> itr = load.iterator(); itr.hasNext();) {
                    sm = (StateManagerImpl) itr.next();
                    if (failed != null && failed.contains(sm.getId()))
                        continue;


                    try {
                        sm.afterRefresh();
                        sm.load(_fc, StateManagerImpl.LOAD_FGS, null, null,
                            false);
                    } catch (OpenJPAException ke) {
                        exceps = add(exceps, ke);
                    }
                }
            }


            // now invoke postRefresh on all the instances
            for (Iterator<?> itr = objs.iterator(); itr.hasNext();) {
                try {
                    sm = getStateManagerImpl(itr.next(), true);
                    if (sm != null && !sm.isDetached())
                        fireLifecycleEvent(sm.getManagedInstance(), null,
                            sm.getMetaData(), LifecycleEvent.AFTER_REFRESH);
                } catch (OpenJPAException ke) {
                    exceps = add(exceps, ke);
                }
            }
        } catch (OpenJPAException ke) {
            throw ke;
        } catch (RuntimeException re) {
            throw new GeneralException(re);
        }
        throwNestedExceptions(exceps, false);
    }",1,13621
"                private boolean r_prelude() {
            int among_var;
            int v_1;
            int v_2;
            int v_3;
            int v_4;
            int v_5;
                    // (, line 34
                    // test, line 35
                    v_1 = cursor;
                    // repeat, line 35
                    replab0: while(true)
                    {
                        v_2 = cursor;
                        lab1: do {
                            // (, line 35
                            // [, line 36
                            bra = cursor;
                            // substring, line 36
                            among_var = find_among(a_0, 7);
                            if (among_var == 0)
                            {
                                break lab1;
                            }
                            // ], line 36
                            ket = cursor;
                            switch(among_var) {
                                case 0:
                                    break lab1;
                                case 1:
                                    // (, line 37
                                    // <-, line 37
                                    slice_from(""\u00E0"");
                                    break;
                                case 2:
                                    // (, line 38
                                    // <-, line 38
                                    slice_from(""\u00E8"");
                                    break;
                                case 3:
                                    // (, line 39
                                    // <-, line 39
                                    slice_from(""\u00EC"");
                                    break;
                                case 4:
                                    // (, line 40
                                    // <-, line 40
                                    slice_from(""\u00F2"");
                                    break;
                                case 5:
                                    // (, line 41
                                    // <-, line 41
                                    slice_from(""\u00F9"");
                                    break;
                                case 6:
                                    // (, line 42
                                    // <-, line 42
                                    slice_from(""qU"");
                                    break;
                                case 7:
                                    // (, line 43
                                    // next, line 43
                                    if (cursor >= limit)
                                    {
                                        break lab1;
                                    }
                                    cursor++;
                                    break;
                            }
                            continue replab0;
                        } while (false);
                        cursor = v_2;
                        break replab0;
                    }
                    cursor = v_1;
                    // repeat, line 46
                    replab2: while(true)
                    {
                        v_3 = cursor;
                        lab3: do {
                            // goto, line 46
                            golab4: while(true)
                            {
                                v_4 = cursor;
                                lab5: do {
                                    // (, line 46
                                    if (!(in_grouping(g_v, 97, 249)))
                                    {
                                        break lab5;
                                    }
                                    // [, line 47
                                    bra = cursor;
                                    // or, line 47
                                    lab6: do {
                                        v_5 = cursor;
                                        lab7: do {
                                            // (, line 47
                                            // literal, line 47
                                            if (!(eq_s(1, ""u"")))
                                            {
                                                break lab7;
                                            }
                                            // ], line 47
                                            ket = cursor;
                                            if (!(in_grouping(g_v, 97, 249)))
                                            {
                                                break lab7;
                                            }
                                            // <-, line 47
                                            slice_from(""U"");
                                            break lab6;
                                        } while (false);
                                        cursor = v_5;
                                        // (, line 48
                                        // literal, line 48
                                        if (!(eq_s(1, ""i"")))
                                        {
                                            break lab5;
                                        }
                                        // ], line 48
                                        ket = cursor;
                                        if (!(in_grouping(g_v, 97, 249)))
                                        {
                                            break lab5;
                                        }
                                        // <-, line 48
                                        slice_from(""I"");
                                    } while (false);
                                    cursor = v_4;
                                    break golab4;
                                } while (false);
                                cursor = v_4;
                                if (cursor >= limit)
                                {
                                    break lab3;
                                }
                                cursor++;
                            }
                            continue replab2;
                        } while (false);
                        cursor = v_3;
                        break replab2;
                    }
                    return true;
                }",1,13720
"  @SuppressWarnings(""unchecked"")
  protected Map<byte[], List<Path>>[] handleBulkLoad(List<TableName> sTableList)
          throws IOException {
    Map<byte[], List<Path>>[] mapForSrc = new Map[sTableList.size()];
    List<String> activeFiles = new ArrayList<>();
    List<String> archiveFiles = new ArrayList<>();
    Pair<Map<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>>, List<byte[]>> pair =
            backupManager.readBulkloadRows(sTableList);
    Map<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>> map = pair.getFirst();
    FileSystem tgtFs;
    try {
      tgtFs = FileSystem.get(new URI(backupInfo.getBackupRootDir()), conf);
    } catch (URISyntaxException use) {
      throw new IOException(""Unable to get FileSystem"", use);
    }
    Path rootdir = FSUtils.getRootDir(conf);
    Path tgtRoot = new Path(new Path(backupInfo.getBackupRootDir()), backupId);


    for (Map.Entry<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>> tblEntry :
      map.entrySet()) {
      TableName srcTable = tblEntry.getKey();


      int srcIdx = getIndex(srcTable, sTableList);
      if (srcIdx < 0) {
        LOG.warn(""Couldn't find "" + srcTable + "" in source table List"");
        continue;
      }
      if (mapForSrc[srcIdx] == null) {
        mapForSrc[srcIdx] = new TreeMap<>(Bytes.BYTES_COMPARATOR);
      }
      Path tblDir = FSUtils.getTableDir(rootdir, srcTable);
      Path tgtTable = new Path(new Path(tgtRoot, srcTable.getNamespaceAsString()),
          srcTable.getQualifierAsString());
      for (Map.Entry<String,Map<String,List<Pair<String, Boolean>>>> regionEntry :
        tblEntry.getValue().entrySet()){
        String regionName = regionEntry.getKey();
        Path regionDir = new Path(tblDir, regionName);
        // map from family to List of hfiles
        for (Map.Entry<String,List<Pair<String, Boolean>>> famEntry :
          regionEntry.getValue().entrySet()) {
          String fam = famEntry.getKey();
          Path famDir = new Path(regionDir, fam);
          List<Path> files;
          if (!mapForSrc[srcIdx].containsKey(Bytes.toBytes(fam))) {
            files = new ArrayList<>();
            mapForSrc[srcIdx].put(Bytes.toBytes(fam), files);
          } else {
            files = mapForSrc[srcIdx].get(Bytes.toBytes(fam));
          }
          Path archiveDir = HFileArchiveUtil.getStoreArchivePath(conf, srcTable, regionName, fam);
          String tblName = srcTable.getQualifierAsString();
          Path tgtFam = new Path(new Path(tgtTable, regionName), fam);
          if (!tgtFs.mkdirs(tgtFam)) {
            throw new IOException(""couldn't create "" + tgtFam);
          }
          for (Pair<String, Boolean> fileWithState : famEntry.getValue()) {
            String file = fileWithState.getFirst();
            int idx = file.lastIndexOf(""/"");
            String filename = file;
            if (idx > 0) {
              filename = file.substring(idx+1);
            }
            Path p = new Path(famDir, filename);
            Path tgt = new Path(tgtFam, filename);
            Path archive = new Path(archiveDir, filename);
            if (fs.exists(p)) {
              if (LOG.isTraceEnabled()) {
                LOG.trace(""found bulk hfile "" + file + "" in "" + famDir + "" for "" + tblName);
              }
              if (LOG.isTraceEnabled()) {
                LOG.trace(""copying "" + p + "" to "" + tgt);
              }
              activeFiles.add(p.toString());
            } else if (fs.exists(archive)){
              LOG.debug(""copying archive "" + archive + "" to "" + tgt);
              archiveFiles.add(archive.toString());
            }
            files.add(tgt);
          }
        }
      }
    }


    copyBulkLoadedFiles(activeFiles, archiveFiles);
    backupManager.deleteBulkLoadedRows(pair.getSecond());
    return mapForSrc;
  }",1,13747
"  @SuppressWarnings(value = ""unchecked"")
  private void performCommonProcessing(Operation currentOperation, KuduExecutionContext kuduExecutionContext)
  {
    currentOperation.setExternalConsistencyMode(kuduExecutionContext.getExternalConsistencyMode());
    Long propagatedTimeStamp = kuduExecutionContext.getPropagatedTimestamp();
    if ( propagatedTimeStamp != null) { // set propagation timestamp only if enabled
      currentOperation.setPropagatedTimestamp(propagatedTimeStamp);
    }
    PartialRow partialRow = currentOperation.getRow();
    Object payload = kuduExecutionContext.getPayload();
    Set<String> doNotWriteColumns = kuduExecutionContext.getDoNotWriteColumns();
    if (doNotWriteColumns == null) {
      doNotWriteColumns = new HashSet<>();
    }
    for (String columnName: kuduColumnBasedGetters.keySet()) {
      if ( doNotWriteColumns.contains(columnName)) {
        continue;
      }
      ColumnSchema columnSchema = allColumnDefs.get(columnName);
      Type dataType = columnSchema.getType();
      try {
        switch (dataType) {
          case STRING:
            PojoUtils.Getter<Object, String> stringGetter = ((PojoUtils.Getter<Object, String>)kuduColumnBasedGetters
                .get(columnName));
            if (stringGetter != null) {
              final String stringValue = stringGetter.get(payload);
              if (stringValue != null) {
                partialRow.addString(columnName, stringValue);
              }
            }
            break;
          case BINARY:
            PojoUtils.Getter<Object, ByteBuffer> byteBufferGetter = ((PojoUtils.Getter<Object, ByteBuffer>)
                kuduColumnBasedGetters.get(columnName));
            if (byteBufferGetter != null) {
              final ByteBuffer byteBufferValue = byteBufferGetter.get(payload);
              if (byteBufferValue != null) {
                partialRow.addBinary(columnName, byteBufferValue);
              }
            }
            break;
          case BOOL:
            PojoUtils.GetterBoolean<Object> boolGetter = ((PojoUtils.GetterBoolean<Object>)kuduColumnBasedGetters.get(
                columnName));
            if (boolGetter != null) {
              final boolean boolValue = boolGetter.get(payload);
              partialRow.addBoolean(columnName, boolValue);
            }
            break;
          case DOUBLE:
            PojoUtils.GetterDouble<Object> doubleGetter = ((PojoUtils.GetterDouble<Object>)kuduColumnBasedGetters.get(
                columnName));
            if (doubleGetter != null) {
              final double doubleValue = doubleGetter.get(payload);
              partialRow.addDouble(columnName, doubleValue);
            }
            break;
          case FLOAT:
            PojoUtils.GetterFloat<Object> floatGetter = ((PojoUtils.GetterFloat<Object>)kuduColumnBasedGetters.get(
                columnName));
            if (floatGetter != null) {
              final float floatValue = floatGetter.get(payload);
              partialRow.addFloat(columnName, floatValue);
            }
            break;
          case INT8:
            PojoUtils.GetterByte<Object> byteGetter = ((PojoUtils.GetterByte<Object>)kuduColumnBasedGetters.get(
                columnName));
            if (byteGetter != null) {
              final byte byteValue = byteGetter.get(payload);
              partialRow.addByte(columnName, byteValue);
            }
            break;
          case INT16:
            PojoUtils.GetterShort<Object> shortGetter = ((PojoUtils.GetterShort<Object>)kuduColumnBasedGetters.get(
                columnName));
            if (shortGetter != null) {
              final short shortValue = shortGetter.get(payload);
              partialRow.addShort(columnName, shortValue);
            }
            break;
          case INT32:
            PojoUtils.GetterInt<Object> intGetter = ((PojoUtils.GetterInt<Object>)
                kuduColumnBasedGetters.get(columnName));
            if (intGetter != null) {
              final int intValue = intGetter.get(payload);
              partialRow.addInt(columnName, intValue);
            }
            break;
          case INT64:
          case UNIXTIME_MICROS:
            PojoUtils.GetterLong<Object> longGetter = ((PojoUtils.GetterLong<Object>)kuduColumnBasedGetters.get(
                columnName));
            if (longGetter != null) {
              final long longValue = longGetter.get(payload);
              partialRow.addLong(columnName, longValue);
            }
            break;
          default:
            LOG.error(columnName + "" is not of the supported data type"");
            throw new UnsupportedOperationException(""Kudu does not support data type for column "" + columnName);
        }
      } catch ( Exception ex ) {
        LOG.error("" Exception while fetching the value of "" + columnName + "" because "" + ex.getMessage());
        partialRow.setNull(columnName);
      }
    }
    try {
      kuduSession.apply(currentOperation);
    } catch (KuduException e) {
      throw new RuntimeException(""Could not execute operation because "" + e.getMessage(), e);
    }
  }",1,14596
"    @Override
    public void onTrigger(final ProcessContext context, final ProcessSession session) {
        List<FlowFile> flowFiles = session.get(context.getProperty(BATCH_SIZE).evaluateAttributeExpressions().asInteger());
        if (flowFiles == null || flowFiles.size() == 0) {
            return;
        }


        Map<ItemKeys, FlowFile> keysToFlowFileMap = new HashMap<>();


        final String table = context.getProperty(TABLE).evaluateAttributeExpressions().getValue();


        final String hashKeyName = context.getProperty(HASH_KEY_NAME).evaluateAttributeExpressions().getValue();
        final String hashKeyValueType = context.getProperty(HASH_KEY_VALUE_TYPE).getValue();
        final String rangeKeyName = context.getProperty(RANGE_KEY_NAME).evaluateAttributeExpressions().getValue();
        final String rangeKeyValueType = context.getProperty(RANGE_KEY_VALUE_TYPE).getValue();
        final String jsonDocument = context.getProperty(JSON_DOCUMENT).evaluateAttributeExpressions().getValue();
        final String charset = context.getProperty(DOCUMENT_CHARSET).evaluateAttributeExpressions().getValue();


        TableWriteItems tableWriteItems = new TableWriteItems(table);


        for (FlowFile flowFile : flowFiles) {
            final Object hashKeyValue = getValue(context, HASH_KEY_VALUE_TYPE, HASH_KEY_VALUE, flowFile);
            final Object rangeKeyValue = getValue(context, RANGE_KEY_VALUE_TYPE, RANGE_KEY_VALUE, flowFile);


            if (!isHashKeyValueConsistent(hashKeyName, hashKeyValue, session, flowFile)) {
                continue;
            }


            if (!isRangeKeyValueConsistent(rangeKeyName, rangeKeyValue, session, flowFile)) {
                continue;
            }


            if (!isDataValid(flowFile, jsonDocument)) {
                flowFile = session.putAttribute(flowFile, AWS_DYNAMO_DB_ITEM_SIZE_ERROR, ""Max size of item + attribute should be 400kb but was "" + flowFile.getSize() + jsonDocument.length());
                session.transfer(flowFile, REL_FAILURE);
                continue;
            }


            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            session.exportTo(flowFile, baos);


            try {
                if (rangeKeyValue == null || StringUtils.isBlank(rangeKeyValue.toString())) {
                    tableWriteItems.addItemToPut(new Item().withKeyComponent(hashKeyName, hashKeyValue)
                        .withJSON(jsonDocument, IOUtils.toString(baos.toByteArray(), charset)));
                } else {
                    tableWriteItems.addItemToPut(new Item().withKeyComponent(hashKeyName, hashKeyValue)
                        .withKeyComponent(rangeKeyName, rangeKeyValue)
                        .withJSON(jsonDocument, IOUtils.toString(baos.toByteArray(), charset)));
                }
            } catch (IOException ioe) {
                getLogger().error(""IOException while creating put item : "" + ioe.getMessage());
                flowFile = session.putAttribute(flowFile, DYNAMODB_ITEM_IO_ERROR, ioe.getMessage());
                session.transfer(flowFile, REL_FAILURE);
            }
            keysToFlowFileMap.put(new ItemKeys(hashKeyValue, rangeKeyValue), flowFile);
        }


        if (keysToFlowFileMap.isEmpty()) {
            return;
        }


        final DynamoDB dynamoDB = getDynamoDB();


        try {
            BatchWriteItemOutcome outcome = dynamoDB.batchWriteItem(tableWriteItems);


            handleUnprocessedItems(session, keysToFlowFileMap, table, hashKeyName, hashKeyValueType, rangeKeyName,
                rangeKeyValueType, outcome);


            // Handle any remaining flowfiles
            for (FlowFile flowFile : keysToFlowFileMap.values()) {
                getLogger().debug(""Successful posted items to dynamodb : "" + table);
                session.transfer(flowFile, REL_SUCCESS);
            }
        } catch (AmazonServiceException exception) {
            getLogger().error(""Could not process flowFiles due to service exception : "" + exception.getMessage());
            List<FlowFile> failedFlowFiles = processServiceException(session, flowFiles, exception);
            session.transfer(failedFlowFiles, REL_FAILURE);
        } catch (AmazonClientException exception) {
            getLogger().error(""Could not process flowFiles due to client exception : "" + exception.getMessage());
            List<FlowFile> failedFlowFiles = processClientException(session, flowFiles, exception);
            session.transfer(failedFlowFiles, REL_FAILURE);
        } catch (Exception exception) {
            getLogger().error(""Could not process flowFiles due to exception : "" + exception.getMessage());
            List<FlowFile> failedFlowFiles = processException(session, flowFiles, exception);
            session.transfer(failedFlowFiles, REL_FAILURE);
        }
    }",1,14652
"    public void validateDepositDetailForUpdate(final JsonElement element, final FromJsonHelper fromApiJsonHelper,
            final DataValidatorBuilder baseDataValidator) {
        if (fromApiJsonHelper.parameterExists(nameParamName, element)) {
            final String name = fromApiJsonHelper.extractStringNamed(nameParamName, element);
            baseDataValidator.reset().parameter(nameParamName).value(name).notBlank().notExceedingLengthOf(100);
        }


        if (fromApiJsonHelper.parameterExists(shortNameParamName, element)) {
            final String shortName = fromApiJsonHelper.extractStringNamed(shortNameParamName, element);
            baseDataValidator.reset().parameter(shortNameParamName).value(shortName).notBlank().notExceedingLengthOf(4);
        }


        if (fromApiJsonHelper.parameterExists(descriptionParamName, element)) {
            final String description = fromApiJsonHelper.extractStringNamed(descriptionParamName, element);
            baseDataValidator.reset().parameter(descriptionParamName).value(description).notBlank().notExceedingLengthOf(500);
        }


        if (fromApiJsonHelper.parameterExists(currencyCodeParamName, element)) {
            final String currencyCode = fromApiJsonHelper.extractStringNamed(currencyCodeParamName, element);
            baseDataValidator.reset().parameter(currencyCodeParamName).value(currencyCode).notBlank();
        }


        if (fromApiJsonHelper.parameterExists(digitsAfterDecimalParamName, element)) {
            final Integer digitsAfterDecimal = fromApiJsonHelper.extractIntegerSansLocaleNamed(digitsAfterDecimalParamName, element);
            baseDataValidator.reset().parameter(digitsAfterDecimalParamName).value(digitsAfterDecimal).notNull().inMinMaxRange(0, 6);
        }


        if (fromApiJsonHelper.parameterExists(inMultiplesOfParamName, element)) {
            final Integer inMultiplesOf = fromApiJsonHelper.extractIntegerNamed(inMultiplesOfParamName, element, Locale.getDefault());
            baseDataValidator.reset().parameter(inMultiplesOfParamName).value(inMultiplesOf).ignoreIfNull().integerZeroOrGreater();
        }


        if (fromApiJsonHelper.parameterExists(nominalAnnualInterestRateParamName, element)) {
            final BigDecimal interestRate = fromApiJsonHelper.extractBigDecimalWithLocaleNamed(nominalAnnualInterestRateParamName, element);
            baseDataValidator.reset().parameter(nominalAnnualInterestRateParamName).value(interestRate).notNull().zeroOrPositiveAmount();
        }


        if (fromApiJsonHelper.parameterExists(interestCompoundingPeriodTypeParamName, element)) {
            final Integer interestCompoundingPeriodType = fromApiJsonHelper.extractIntegerSansLocaleNamed(
                    interestCompoundingPeriodTypeParamName, element);
            baseDataValidator.reset().parameter(interestCompoundingPeriodTypeParamName).value(interestCompoundingPeriodType).notNull()
                    .isOneOfTheseValues(SavingsCompoundingInterestPeriodType.integerValues());
        }


        if (fromApiJsonHelper.parameterExists(interestCalculationTypeParamName, element)) {
            final Integer interestCalculationType = fromApiJsonHelper.extractIntegerSansLocaleNamed(interestCalculationTypeParamName,
                    element);
            baseDataValidator.reset().parameter(interestCalculationTypeParamName).value(interestCalculationType).notNull()
                    .inMinMaxRange(1, 2);
        }


        if (fromApiJsonHelper.parameterExists(interestCalculationDaysInYearTypeParamName, element)) {
            final Integer interestCalculationDaysInYearType = fromApiJsonHelper.extractIntegerSansLocaleNamed(
                    interestCalculationDaysInYearTypeParamName, element);
            baseDataValidator.reset().parameter(interestCalculationDaysInYearTypeParamName).value(interestCalculationDaysInYearType)
                    .notNull().isOneOfTheseValues(360, 365);
        }


        if (fromApiJsonHelper.parameterExists(minRequiredOpeningBalanceParamName, element)) {
            final BigDecimal minOpeningBalance = fromApiJsonHelper.extractBigDecimalWithLocaleNamed(minRequiredOpeningBalanceParamName,
                    element);
            baseDataValidator.reset().parameter(minRequiredOpeningBalanceParamName).value(minOpeningBalance).ignoreIfNull()
                    .zeroOrPositiveAmount();
        }


        if (fromApiJsonHelper.parameterExists(lockinPeriodFrequencyParamName, element)) {
            final Integer lockinPeriodFrequency = fromApiJsonHelper.extractIntegerWithLocaleNamed(lockinPeriodFrequencyParamName, element);
            baseDataValidator.reset().parameter(lockinPeriodFrequencyParamName).value(lockinPeriodFrequency).ignoreIfNull()
                    .integerZeroOrGreater();
        }


        if (fromApiJsonHelper.parameterExists(lockinPeriodFrequencyTypeParamName, element)) {
            final Integer lockinPeriodFrequencyType = fromApiJsonHelper.extractIntegerSansLocaleNamed(lockinPeriodFrequencyTypeParamName,
                    element);
            baseDataValidator.reset().parameter(lockinPeriodFrequencyTypeParamName).value(lockinPeriodFrequencyType).inMinMaxRange(0, 3);
        }


        if (fromApiJsonHelper.parameterExists(withdrawalFeeForTransfersParamName, element)) {
            final Boolean isWithdrawalFeeApplicableForTransfers = fromApiJsonHelper.extractBooleanNamed(withdrawalFeeForTransfersParamName,
                    element);
            baseDataValidator.reset().parameter(withdrawalFeeForTransfersParamName).value(isWithdrawalFeeApplicableForTransfers)
                    .ignoreIfNull().validateForBooleanValue();
        }


        if (fromApiJsonHelper.parameterExists(feeAmountParamName, element)) {
            final BigDecimal annualFeeAmount = fromApiJsonHelper.extractBigDecimalWithLocaleNamed(feeAmountParamName, element);
            baseDataValidator.reset().parameter(feeAmountParamName).value(annualFeeAmount).ignoreIfNull().zeroOrPositiveAmount();
        }


        if (fromApiJsonHelper.parameterExists(feeOnMonthDayParamName, element)) {
            final MonthDay monthDayOfAnnualFee = fromApiJsonHelper.extractMonthDayNamed(feeOnMonthDayParamName, element);
            baseDataValidator.reset().parameter(feeOnMonthDayParamName).value(monthDayOfAnnualFee).ignoreIfNull();
        }


        if (this.fromApiJsonHelper.parameterExists(minBalanceForInterestCalculationParamName, element)) {
            final BigDecimal minBalanceForInterestCalculation = this.fromApiJsonHelper.extractBigDecimalWithLocaleNamed(
                    minBalanceForInterestCalculationParamName, element);
            baseDataValidator.reset().parameter(minBalanceForInterestCalculationParamName).value(minBalanceForInterestCalculation)
                    .ignoreIfNull().zeroOrPositiveAmount();
        }


        final Long savingsControlAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_CONTROL.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_CONTROL.getValue()).value(savingsControlAccountId)
                .ignoreIfNull().integerGreaterThanZero();


        final Long savingsReferenceAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_REFERENCE.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.SAVINGS_REFERENCE.getValue())
                .value(savingsReferenceAccountId).ignoreIfNull().integerGreaterThanZero();


        final Long transfersInSuspenseAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.TRANSFERS_SUSPENSE.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.TRANSFERS_SUSPENSE.getValue())
                .value(transfersInSuspenseAccountId).ignoreIfNull().integerGreaterThanZero();


        final Long interestOnSavingsAccountId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INTEREST_ON_SAVINGS.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INTEREST_ON_SAVINGS.getValue())
                .value(interestOnSavingsAccountId).ignoreIfNull().integerGreaterThanZero();


        final Long incomeFromFeeId = fromApiJsonHelper.extractLongNamed(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_FEES.getValue(),
                element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_FEES.getValue()).value(incomeFromFeeId)
                .ignoreIfNull().integerGreaterThanZero();


        final Long incomeFromPenaltyId = fromApiJsonHelper.extractLongNamed(
                SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_PENALTIES.getValue(), element);
        baseDataValidator.reset().parameter(SAVINGS_PRODUCT_ACCOUNTING_PARAMS.INCOME_FROM_PENALTIES.getValue()).value(incomeFromPenaltyId)
                .ignoreIfNull().integerGreaterThanZero();


        validatePaymentChannelFundSourceMappings(fromApiJsonHelper, baseDataValidator, element);
        validateChargeToIncomeAccountMappings(fromApiJsonHelper, baseDataValidator, element);
        validateTaxWithHoldingParams(baseDataValidator, element, false);
    }",1,14666
"protected AbstractDocument(Map<String, Object> properties) {
    Objects.requireNonNull(properties, ""properties map is required"");
    this.properties = properties;
  }",0,
"public Void put(String key, Object value) {
    properties.put(key, value);
    return null;
  }",0,
"public Object get(String key) {
    return properties.get(key);
  }",0,
"public <T> Stream<T> children(String key, Function<Map<String, Object>, T> constructor) {
    return Stream.ofNullable(get(key))
        .filter(Objects::nonNull)
        .map(el -> (List<Map<String, Object>>) el)
        .findAny()
        .stream()
        .flatMap(Collection::stream)
        .map(constructor);
  }",0,
"public String toString() {
    var builder = new StringBuilder();
    builder.append(getClass().getName()).append(""["");
    properties.forEach((key, value) -> builder.append(""["").append(key).append("" : "").append(value)
        .append(""]""));
    builder.append(""]"");
    return builder.toString();
  }",0,
"public void createKingdom(final KingdomFactory factory) {
    setKing(factory.createKing());
    setCastle(factory.createCastle());
    setArmy(factory.createArmy());
  }",0,
"King getKing(final KingdomFactory factory) {
    return factory.createKing();
  }",0,
"public King getKing() {
    return king;
  }",0,
"public static KingdomFactory makeFactory(KingdomType type) {
      switch (type) {
        case ELF:
          return new ElfKingdomFactory();
        case ORC:
          return new OrcKingdomFactory();
        default:
          throw new IllegalArgumentException(""KingdomType not supported."");
      }
    }",0,
"public static void main(String[] args) {

    var app = new App();

    LOGGER.info(""Elf Kingdom"");
    app.createKingdom(FactoryMaker.makeFactory(KingdomType.ELF));
    LOGGER.info(app.getArmy().getDescription());
    LOGGER.info(app.getCastle().getDescription());
    LOGGER.info(app.getKing().getDescription());

    LOGGER.info(""Orc Kingdom"");
    app.createKingdom(FactoryMaker.makeFactory(KingdomType.ORC));
    LOGGER.info(app.getArmy().getDescription());
    LOGGER.info(app.getCastle().getDescription());
    LOGGER.info(app.getKing().getDescription());
  }",0,
"public void setUp() {
    elfFactory = FactoryMaker.makeFactory(KingdomType.ELF);
    orcFactory = FactoryMaker.makeFactory(KingdomType.ORC);
  }",0,
"public void king() {
    final var elfKing = app.getKing(elfFactory);
    assertTrue(elfKing instanceof ElfKing);
    assertEquals(ElfKing.DESCRIPTION, elfKing.getDescription());
    final var orcKing = app.getKing(orcFactory);
    assertTrue(orcKing instanceof OrcKing);
    assertEquals(OrcKing.DESCRIPTION, orcKing.getDescription());
  }",0,
"public void castle() {
    final var elfCastle = app.getCastle(elfFactory);
    assertTrue(elfCastle instanceof ElfCastle);
    assertEquals(ElfCastle.DESCRIPTION, elfCastle.getDescription());
    final var orcCastle = app.getCastle(orcFactory);
    assertTrue(orcCastle instanceof OrcCastle);
    assertEquals(OrcCastle.DESCRIPTION, orcCastle.getDescription());
  }",0,
"public void army() {
    final var elfArmy = app.getArmy(elfFactory);
    assertTrue(elfArmy instanceof ElfArmy);
    assertEquals(ElfArmy.DESCRIPTION, elfArmy.getDescription());
    final var orcArmy = app.getArmy(orcFactory);
    assertTrue(orcArmy instanceof OrcArmy);
    assertEquals(OrcArmy.DESCRIPTION, orcArmy.getDescription());
  }",0,
"public void createElfKingdom() {
    app.createKingdom(elfFactory);
    final var king = app.getKing();
    final var castle = app.getCastle();
    final var army = app.getArmy();
    assertTrue(king instanceof ElfKing);
    assertEquals(ElfKing.DESCRIPTION, king.getDescription());
    assertTrue(castle instanceof ElfCastle);
    assertEquals(ElfCastle.DESCRIPTION, castle.getDescription());
    assertTrue(army instanceof ElfArmy);
    assertEquals(ElfArmy.DESCRIPTION, army.getDescription());
  }",0,
"public void createOrcKingdom() {
    app.createKingdom(orcFactory);
    final var king = app.getKing();
    final var castle = app.getCastle();
    final var army = app.getArmy();
    assertTrue(king instanceof OrcKing);
    assertEquals(OrcKing.DESCRIPTION, king.getDescription());
    assertTrue(castle instanceof OrcCastle);
    assertEquals(OrcCastle.DESCRIPTION, castle.getDescription());
    assertTrue(army instanceof OrcArmy);
    assertEquals(OrcArmy.DESCRIPTION, army.getDescription());
  }",0,
"public void test() {
    App.main(new String[]{});
  }",0,
"public static void main(String[] args) {
    var conUnix = new ConfigureForUnixVisitor();
    var conDos = new ConfigureForDosVisitor();

    var zoom = new Zoom();
    var hayes = new Hayes();

    hayes.accept(conDos); // Hayes modem with Dos configurator
    zoom.accept(conDos); // Zoom modem with Dos configurator
    hayes.accept(conUnix); // Hayes modem with Unix configurator
    zoom.accept(conUnix); // Zoom modem with Unix configurator   
  }",0,
"public void visit(Hayes hayes) {
    LOGGER.info(hayes + "" used with Dos configurator."");
  }",0,
"public void visit(Zoom zoom) {
    LOGGER.info(zoom + "" used with Dos configurator."");
  }",0,
"public void accept(ModemVisitor modemVisitor) {
    if (modemVisitor instanceof HayesVisitor) {
      ((HayesVisitor) modemVisitor).visit(this);
    } else {
      LOGGER.info(""Only HayesVisitor is allowed to visit Hayes modem"");
    }

  }",0,
"public void accept(ModemVisitor modemVisitor) {
    if (modemVisitor instanceof ZoomVisitor) {
      ((ZoomVisitor) modemVisitor).visit(this);
    } else {
      LOGGER.info(""Only ZoomVisitor is allowed to visit Zoom modem"");
    }
  }",0,
"public void test() {
    App.main(new String[]{});
  }",0,
"public void testVisitForZoom() {    
    var conDos = new ConfigureForDosVisitor();
    var zoom = new Zoom();
    
    conDos.visit(zoom);
    
    assertThat(logger.getLoggingEvents())
        .extracting(""level"", ""message"")
        .contains(tuple(INFO, zoom + "" used with Dos configurator.""));
  ",0,
"public void testVisitForHayes() {
    var conDos = new ConfigureForDosVisitor();
    var hayes = new Hayes();
    
    conDos.visit(hayes);
    
    assertThat(logger.getLoggingEvents())
        .extracting(""level"", ""message"")
        .contains(tuple(INFO, hayes + "" used with Dos configurator.""));
  }",0,
"public void testVisitForZoom() {
    var conUnix = new ConfigureForUnixVisitor();
    var zoom = new Zoom();
    
    conUnix.visit(zoom);
    
    assertThat(LOGGER.getLoggingEvents())
        .extracting(""level"", ""message"")
        .contains(tuple(INFO, zoom + "" used with Unix configurator.""));
  }",0,
"public void clearLoggers() {
    TestLoggerFactory.clear();
  }",0,
"public void testAcceptForDos() {  
    var hayes = new Hayes();
    var mockVisitor = mock(ConfigureForDosVisitor.class);
    
    hayes.accept(mockVisitor);
    verify((HayesVisitor)mockVisitor).visit(eq(hayes));
  }",0,
"public void testAcceptForUnix() {    
    var hayes = new Hayes();
    var mockVisitor = mock(ConfigureForUnixVisitor.class);
    
    hayes.accept(mockVisitor);
    
    verifyZeroInteractions(mockVisitor);
  }",0,
"public void testAcceptForDos() {  
    var zoom = new Zoom();
    var mockVisitor = mock(ConfigureForDosVisitor.class);
    
    zoom.accept(mockVisitor);
    verify((ZoomVisitor)mockVisitor).visit(eq(zoom));
  }",0,
"public void testAcceptForUnix() {
    var zoom = new Zoom();
    var mockVisitor = mock(ConfigureForUnixVisitor.class);
    
    zoom.accept(mockVisitor);
    verify((ZoomVisitor)mockVisitor).visit(eq(zoom));
  }",0,
"public void setup() {
    beans = new HashMap<>();

    var fishingBoatAdapter = spy(new FishingBoatAdapter());
    beans.put(FISHING_BEAN, fishingBoatAdapter);

    var captain = new Captain();
    captain.setRowingBoat((FishingBoatAdapter) beans.get(FISHING_BEAN));
    beans.put(ROWING_BEAN, captain);
  }",0,
"public void testAdapter() {
    var captain = (Captain) beans.get(ROWING_BEAN);

    // when captain moves
    captain.row();

    // the captain internally calls the battleship object to move
    var adapter = (RowingBoat) beans.get(FISHING_BEAN);
    verify(adapter).row();
  }",0,
"public static void main(final String[] args) {
    // The captain can only operate rowing boats but with adapter he is able to
    // use fishing boats as well
    var captain = new Captain(new FishingBoatAdapter());
    captain.row();
  }",0,
"void sail() {
    LOGGER.info(""The fishing boat is sailing"");
  }",0,
"public Product getProduct() {

    var product = new Product();
    var productTitle = informationClient.getProductTitle();
    var productInventory = inventoryClient.getProductInventories();

    //Fallback to error message
    product.setTitle(requireNonNullElse(productTitle, ""Error: Fetching Product Title Failed""));

    //Fallback to default error inventory
    product.setProductInventories(requireNonNullElse(productInventory, -1));

    return product;
  }",0,
"public String getProductTitle() {
    var request = HttpRequest.newBuilder()
        .GET()
        .uri(URI.create(""http://localhost:51515/information""))
        .build();
    var client = HttpClient.newHttpClient();
    try {
      var httpResponse = client.send(request, HttpResponse.BodyHandlers.ofString());
      return httpResponse.body();
    } catch (IOException ioe) {
      LOGGER.error(""IOException Occurred"", ioe);
    } catch (InterruptedException ie) {
      LOGGER.error(""InterruptedException Occurred"", ie);
    }
    return null;
  }
}",0,
"public Integer getProductInventories() {
    var response = """";

    var request = HttpRequest.newBuilder()
        .GET()
        .uri(URI.create(""http://localhost:51516/inventories""))
        .build();
    var client = HttpClient.newHttpClient();
    try {
      var httpResponse = client.send(request, HttpResponse.BodyHandlers.ofString());
      response = httpResponse.body();
    } catch (IOException ioe) {
      LOGGER.error(""IOException Occurred"", ioe);
    } catch (InterruptedException ie) {
      LOGGER.error(""InterruptedException Occurred"", ie);
    }
    if ("""".equalsIgnoreCase(response)) {
      return null;
    } else {
      return Integer.parseInt(response);
    }
  }",0,
"public void testGetProduct() {
    var title = ""The Product Title."";
    var inventories = 5;

    when(informationClient.getProductTitle()).thenReturn(title);
    when(inventoryClient.getProductInventories()).thenReturn(inventories);

    var testProduct = aggregator.getProduct();

    assertEquals(title, testProduct.getTitle());
    assertEquals(inventories, testProduct.getProductInventories());
  }",0,
"public void shouldGetProductTitle() {
    var infoController = new InformationController();
    var title = infoController.getProductTitle();
    assertEquals(""The Product Title."", title);
  }",0,
"public void testGetProductInventories() {
    var inventoryController = new InventoryController();
    var numberOfInventories = inventoryController.getProductInventories();
    assertEquals(5, numberOfInventories);
  }",0,
